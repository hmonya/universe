{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wHVWuQ4byieo",
        "outputId": "d72a7683-8a62-4433-edb1-0f380232bce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n",
            "--2024-10-13 19:13:12--  https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76120962 (73M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py38_4.1 100%[===================>]  72.59M   256MB/s    in 0.3s    \n",
            "\n",
            "2024-10-13 19:13:13 (256 MB/s) - ‘Miniconda3-py38_4.12.0-Linux-x86_64.sh’ saved [76120962/76120962]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py38h06a4308_2\n",
            "    - cffi==1.15.0=py38hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py38h7f8727e_0\n",
            "    - conda==4.12.0=py38h06a4308_0\n",
            "    - cryptography==36.0.0=py38h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.13=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py38h27cfd23_0\n",
            "    - setuptools==61.2.0=py38h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py38h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py38hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py38h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py38h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py38h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.13-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py38h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py38h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.9.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    brotli-python-1.0.9        |   py38h6a678d5_8         356 KB\n",
            "    ca-certificates-2024.9.24  |       h06a4308_0         130 KB\n",
            "    certifi-2024.8.30          |   py38h06a4308_0         162 KB\n",
            "    cffi-1.17.1                |   py38h1fdaa30_0         253 KB\n",
            "    charset-normalizer-3.3.2   |     pyhd3eb1b0_0          44 KB\n",
            "    conda-package-handling-2.3.0|   py38h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py38h06a4308_0          27 KB\n",
            "    cryptography-43.0.0        |   py38hdda0065_0         2.2 MB\n",
            "    idna-3.7                   |   py38h06a4308_0         113 KB\n",
            "    ld_impl_linux-64-2.40      |       h12ee557_0         710 KB\n",
            "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
            "    ncurses-6.4                |       h6a678d5_0         914 KB\n",
            "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
            "    pip-24.2                   |   py38h06a4308_0         2.2 MB\n",
            "    pycosat-0.6.6              |   py38h5eee18b_1          93 KB\n",
            "    pyopenssl-24.2.1           |   py38h06a4308_0          96 KB\n",
            "    python-3.8.20              |       he870216_0        23.8 MB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    requests-2.32.3            |   py38h06a4308_0         100 KB\n",
            "    setuptools-75.1.0          |   py38h06a4308_0         1.7 MB\n",
            "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    urllib3-2.2.3              |   py38h06a4308_0         181 KB\n",
            "    wheel-0.44.0               |   py38h06a4308_0         108 KB\n",
            "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    zstandard-0.23.0           |   py38h2c38b39_0         432 KB\n",
            "    zstd-1.5.6                 |       hc292b87_0         664 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        56.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py38h6a678d5_8\n",
            "  conda-package-str~ pkgs/main/linux-64::conda-package-streaming-0.10.0-py38h06a4308_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1\n",
            "  zstandard          pkgs/main/linux-64::zstandard-0.23.0-py38h2c38b39_0\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.6-hc292b87_0\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  six-1.16.0-pyhd3eb1b0_1\n",
            "  tqdm-4.63.0-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu\n",
            "  ca-certificates                      2022.3.29-h06a4308_1 --> 2024.9.24-h06a4308_0\n",
            "  certifi                          2021.10.8-py38h06a4308_2 --> 2024.8.30-py38h06a4308_0\n",
            "  cffi                                1.15.0-py38hd667e15_1 --> 1.17.1-py38h1fdaa30_0\n",
            "  charset-normalizer                     2.0.4-pyhd3eb1b0_0 --> 3.3.2-pyhd3eb1b0_0\n",
            "  conda-package-han~                   1.8.1-py38h7f8727e_0 --> 2.3.0-py38h06a4308_0\n",
            "  cryptography                        36.0.0-py38h9ce1e76_0 --> 43.0.0-py38hdda0065_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0~ --> pkgs/main/linux-64::idna-3.7-py38h06a4308_0\n",
            "  ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.40-h12ee557_0\n",
            "  libffi                                     3.3-he6710b0_2 --> 3.4.4-h6a678d5_1\n",
            "  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.4-h6a678d5_0\n",
            "  openssl                                 1.1.1n-h7f8727e_0 --> 3.0.15-h5eee18b_0\n",
            "  pip                                 21.2.4-py38h06a4308_0 --> 24.2-py38h06a4308_0\n",
            "  pycosat                              0.6.3-py38h7b6447c_1 --> 0.6.6-py38h5eee18b_1\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-py~ --> pkgs/main/linux-64::pyopenssl-24.2.1-py38h06a4308_0\n",
            "  python                                  3.8.13-h12debd9_0 --> 3.8.20-he870216_0\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyh~ --> pkgs/main/linux-64::requests-2.32.3-py38h06a4308_0\n",
            "  setuptools                          61.2.0-py38h06a4308_0 --> 75.1.0-py38h06a4308_0\n",
            "  sqlite                                  3.38.2-hc218d9a_0 --> 3.45.3-h5eee18b_0\n",
            "  tk                                      8.6.11-h1ccaba5_0 --> 8.6.14-h39e8969_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd~ --> pkgs/main/linux-64::urllib3-2.2.3-py38h06a4308_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3e~ --> pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0\n",
            "  xz                                       5.2.5-h7b6447c_0 --> 5.4.6-h5eee18b_1\n",
            "  zlib                                    1.2.12-h7f8727e_1 --> 1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "zstd-1.5.6           | 664 KB    | : 100% 1.0/1 [00:00<00:00,  5.76it/s]\n",
            "brotli-python-1.0.9  | 356 KB    | : 100% 1.0/1 [00:00<00:00,  7.19it/s]\n",
            "requests-2.32.3      | 100 KB    | : 100% 1.0/1 [00:00<00:00,  7.34it/s]\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.76it/s]\n",
            "conda-package-stream | 27 KB     | : 100% 1.0/1 [00:00<00:00,  7.51it/s]\n",
            "python-3.8.20        | 23.8 MB   | : 100% 1.0/1 [00:00<00:00,  1.34it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.83it/s]\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  5.98it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  6.73it/s]\n",
            "idna-3.7             | 113 KB    | : 100% 1.0/1 [00:00<00:00,  7.10it/s]\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:00<00:00,  7.82it/s]\n",
            "urllib3-2.2.3        | 181 KB    | : 100% 1.0/1 [00:00<00:00,  7.08it/s]\n",
            "conda-package-handli | 269 KB    | : 100% 1.0/1 [00:00<00:00,  6.99it/s]\n",
            "certifi-2024.8.30    | 162 KB    | : 100% 1.0/1 [00:00<00:00,  7.25it/s]\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00,  4.08it/s]\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:00<00:00,  7.32it/s]\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.93it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  2.93it/s]\n",
            "openssl-3.0.15       | 5.2 MB    | : 100% 1.0/1 [00:00<00:00,  4.27it/s]\n",
            "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.47it/s]\n",
            "cryptography-43.0.0  | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  4.81it/s]\n",
            "ld_impl_linux-64-2.4 | 710 KB    | : 100% 1.0/1 [00:00<00:00,  6.88it/s]\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:00<00:00,  4.94it/s]\n",
            "libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  5.61it/s]\n",
            "pyopenssl-24.2.1     | 96 KB     | : 100% 1.0/1 [00:00<00:00,  6.26it/s]\n",
            "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  6.78it/s]\n",
            "ca-certificates-2024 | 130 KB    | : 100% 1.0/1 [00:00<00:00,  6.66it/s]\n",
            "zstandard-0.23.0     | 432 KB    | : 100% 1.0/1 [00:00<00:00,  6.29it/s]\n",
            "cffi-1.17.1          | 253 KB    | : 100% 1.0/1 [00:00<00:00,  6.23it/s]\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  6.15it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.15it/s]               \n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  6.81it/s]\n",
            "charset-normalizer-3 | 44 KB     | : 100% 1.0/1 [00:00<00:00,  7.08it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.9.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        39.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.9.24-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1\n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "python-3.6.13        | 32.5 MB   | : 100% 1.0/1 [00:04<00:00,  5.00s/it]               \n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00, 17.81it/s]\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  8.31it/s]\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.95it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  7.73it/s]\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "!conda create -n myenv python=3.6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "git clone https://github.com/ml5js/training-charRNN\n",
        "pip install -r training-charRNN/requirements.txt\n",
        "wget https://raw.githubusercontent.com/hmonya/universe/refs/heads/main/pg74571.txt\n",
        "python3 training-charRNN/train.py --data_path pg74571.txt \\\n",
        "--rnn_size 128 \\\n",
        "--num_layers 2 \\\n",
        "--seq_length 50 \\\n",
        "--batch_size 50 \\\n",
        "--num_epochs 10 \\\n",
        "--save_checkpoints ./checkpoints \\\n",
        "--save_model ./models\n",
        "zip -r model.zip models/pg74571"
      ],
      "metadata": {
        "id": "6vokE3BvzJqe",
        "outputId": "500226e4-8176-4777-9327-29fc8bffeea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'training-charRNN'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 105 (delta 31), reused 28 (delta 28), pack-reused 68 (from 1)\u001b[K\n",
            "Receiving objects: 100% (105/105), 33.50 KiB | 11.17 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Collecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 89 kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.15.4->-r training-charRNN/requirements.txt (line 1)) (0.37.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 55.3 MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.16.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 63.3 MB/s \n",
            "\u001b[?25hCollecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 26.3 MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r training-charRNN/requirements.txt (line 1)) (58.0.4)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 69.4 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: gast, termcolor\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=c3d3897f62f34fe569ba8cd52ac975e4479149265f3aff1c19a31d0bf924e8e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=f16a0c768643f5351f65e43be3c322a90917980938eb39893420cd3cea2eaf48\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built gast termcolor\n",
            "Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, dataclasses, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow\n",
            "Successfully installed absl-py-1.4.0 astor-0.8.1 cached-property-1.5.2 dataclasses-0.8 gast-0.2.2 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.19.6 six-1.16.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 termcolor-1.1.0 typing-extensions-4.1.1 werkzeug-2.0.3 wrapt-1.16.0 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "--2024-10-13 19:20:28--  https://raw.githubusercontent.com/hmonya/universe/refs/heads/main/pg74571.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 707691 (691K) [text/plain]\n",
            "Saving to: ‘pg74571.txt’\n",
            "\n",
            "pg74571.txt         100%[===================>] 691.10K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-10-13 19:20:28 (119 MB/s) - ‘pg74571.txt’ saved [707691/707691]\n",
            "\n",
            "WARNING:tensorflow:From training-charRNN/train.py:29: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From training-charRNN/train.py:29: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n",
            "Here we go! Reading text file...\n",
            "0/2810 (epoch 0), train_loss = 5.075, time/batch = 0.704\n",
            "Model saved to ./checkpoints/pg74571/pg74571!\n",
            "1/2810 (epoch 0), train_loss = 5.046, time/batch = 0.166\n",
            "2/2810 (epoch 0), train_loss = 4.974, time/batch = 0.165\n",
            "3/2810 (epoch 0), train_loss = 4.752, time/batch = 0.139\n",
            "4/2810 (epoch 0), train_loss = 4.279, time/batch = 0.148\n",
            "5/2810 (epoch 0), train_loss = 3.876, time/batch = 0.146\n",
            "6/2810 (epoch 0), train_loss = 3.676, time/batch = 0.157\n",
            "7/2810 (epoch 0), train_loss = 3.530, time/batch = 0.166\n",
            "8/2810 (epoch 0), train_loss = 3.428, time/batch = 0.165\n",
            "9/2810 (epoch 0), train_loss = 3.372, time/batch = 0.135\n",
            "10/2810 (epoch 0), train_loss = 3.307, time/batch = 0.235\n",
            "11/2810 (epoch 0), train_loss = 3.263, time/batch = 0.233\n",
            "12/2810 (epoch 0), train_loss = 3.229, time/batch = 0.223\n",
            "13/2810 (epoch 0), train_loss = 3.243, time/batch = 0.264\n",
            "14/2810 (epoch 0), train_loss = 3.277, time/batch = 0.241\n",
            "15/2810 (epoch 0), train_loss = 3.239, time/batch = 0.257\n",
            "16/2810 (epoch 0), train_loss = 3.185, time/batch = 0.257\n",
            "17/2810 (epoch 0), train_loss = 3.252, time/batch = 0.268\n",
            "18/2810 (epoch 0), train_loss = 3.200, time/batch = 0.255\n",
            "19/2810 (epoch 0), train_loss = 3.194, time/batch = 0.263\n",
            "20/2810 (epoch 0), train_loss = 3.242, time/batch = 0.259\n",
            "21/2810 (epoch 0), train_loss = 3.247, time/batch = 0.275\n",
            "22/2810 (epoch 0), train_loss = 3.189, time/batch = 0.228\n",
            "23/2810 (epoch 0), train_loss = 3.166, time/batch = 0.144\n",
            "24/2810 (epoch 0), train_loss = 3.129, time/batch = 0.135\n",
            "25/2810 (epoch 0), train_loss = 3.175, time/batch = 0.141\n",
            "26/2810 (epoch 0), train_loss = 3.200, time/batch = 0.149\n",
            "27/2810 (epoch 0), train_loss = 3.158, time/batch = 0.161\n",
            "28/2810 (epoch 0), train_loss = 3.151, time/batch = 0.145\n",
            "29/2810 (epoch 0), train_loss = 3.267, time/batch = 0.202\n",
            "30/2810 (epoch 0), train_loss = 3.120, time/batch = 0.164\n",
            "31/2810 (epoch 0), train_loss = 3.133, time/batch = 0.141\n",
            "32/2810 (epoch 0), train_loss = 3.170, time/batch = 0.135\n",
            "33/2810 (epoch 0), train_loss = 3.180, time/batch = 0.148\n",
            "34/2810 (epoch 0), train_loss = 3.208, time/batch = 0.161\n",
            "35/2810 (epoch 0), train_loss = 3.168, time/batch = 0.141\n",
            "36/2810 (epoch 0), train_loss = 3.155, time/batch = 0.145\n",
            "37/2810 (epoch 0), train_loss = 3.139, time/batch = 0.157\n",
            "38/2810 (epoch 0), train_loss = 3.136, time/batch = 0.136\n",
            "39/2810 (epoch 0), train_loss = 3.161, time/batch = 0.145\n",
            "40/2810 (epoch 0), train_loss = 3.158, time/batch = 0.155\n",
            "41/2810 (epoch 0), train_loss = 3.121, time/batch = 0.162\n",
            "42/2810 (epoch 0), train_loss = 3.148, time/batch = 0.141\n",
            "43/2810 (epoch 0), train_loss = 3.108, time/batch = 0.151\n",
            "44/2810 (epoch 0), train_loss = 3.150, time/batch = 0.140\n",
            "45/2810 (epoch 0), train_loss = 3.132, time/batch = 0.144\n",
            "46/2810 (epoch 0), train_loss = 3.103, time/batch = 0.145\n",
            "47/2810 (epoch 0), train_loss = 3.088, time/batch = 0.155\n",
            "48/2810 (epoch 0), train_loss = 3.190, time/batch = 0.156\n",
            "49/2810 (epoch 0), train_loss = 3.156, time/batch = 0.145\n",
            "50/2810 (epoch 0), train_loss = 3.180, time/batch = 0.149\n",
            "51/2810 (epoch 0), train_loss = 3.218, time/batch = 0.143\n",
            "52/2810 (epoch 0), train_loss = 3.193, time/batch = 0.141\n",
            "53/2810 (epoch 0), train_loss = 3.173, time/batch = 0.157\n",
            "54/2810 (epoch 0), train_loss = 3.177, time/batch = 0.146\n",
            "55/2810 (epoch 0), train_loss = 3.133, time/batch = 0.170\n",
            "56/2810 (epoch 0), train_loss = 3.142, time/batch = 0.153\n",
            "57/2810 (epoch 0), train_loss = 3.087, time/batch = 0.147\n",
            "58/2810 (epoch 0), train_loss = 3.112, time/batch = 0.150\n",
            "59/2810 (epoch 0), train_loss = 3.061, time/batch = 0.151\n",
            "60/2810 (epoch 0), train_loss = 3.124, time/batch = 0.156\n",
            "61/2810 (epoch 0), train_loss = 3.143, time/batch = 0.148\n",
            "62/2810 (epoch 0), train_loss = 3.174, time/batch = 0.149\n",
            "63/2810 (epoch 0), train_loss = 3.158, time/batch = 0.156\n",
            "64/2810 (epoch 0), train_loss = 3.159, time/batch = 0.141\n",
            "65/2810 (epoch 0), train_loss = 3.218, time/batch = 0.134\n",
            "66/2810 (epoch 0), train_loss = 3.068, time/batch = 0.152\n",
            "67/2810 (epoch 0), train_loss = 3.157, time/batch = 0.147\n",
            "68/2810 (epoch 0), train_loss = 3.160, time/batch = 0.148\n",
            "69/2810 (epoch 0), train_loss = 3.174, time/batch = 0.181\n",
            "70/2810 (epoch 0), train_loss = 3.185, time/batch = 0.147\n",
            "71/2810 (epoch 0), train_loss = 3.161, time/batch = 0.157\n",
            "72/2810 (epoch 0), train_loss = 3.114, time/batch = 0.146\n",
            "73/2810 (epoch 0), train_loss = 3.154, time/batch = 0.165\n",
            "74/2810 (epoch 0), train_loss = 3.132, time/batch = 0.156\n",
            "75/2810 (epoch 0), train_loss = 3.141, time/batch = 0.167\n",
            "76/2810 (epoch 0), train_loss = 3.124, time/batch = 0.151\n",
            "77/2810 (epoch 0), train_loss = 3.120, time/batch = 0.156\n",
            "78/2810 (epoch 0), train_loss = 3.152, time/batch = 0.143\n",
            "79/2810 (epoch 0), train_loss = 3.150, time/batch = 0.150\n",
            "80/2810 (epoch 0), train_loss = 3.098, time/batch = 0.148\n",
            "81/2810 (epoch 0), train_loss = 3.073, time/batch = 0.156\n",
            "82/2810 (epoch 0), train_loss = 3.083, time/batch = 0.164\n",
            "83/2810 (epoch 0), train_loss = 3.080, time/batch = 0.149\n",
            "84/2810 (epoch 0), train_loss = 3.048, time/batch = 0.139\n",
            "85/2810 (epoch 0), train_loss = 3.098, time/batch = 0.143\n",
            "86/2810 (epoch 0), train_loss = 3.129, time/batch = 0.156\n",
            "87/2810 (epoch 0), train_loss = 3.140, time/batch = 0.141\n",
            "88/2810 (epoch 0), train_loss = 3.104, time/batch = 0.147\n",
            "89/2810 (epoch 0), train_loss = 3.099, time/batch = 0.230\n",
            "90/2810 (epoch 0), train_loss = 3.090, time/batch = 0.242\n",
            "91/2810 (epoch 0), train_loss = 3.073, time/batch = 0.238\n",
            "92/2810 (epoch 0), train_loss = 3.081, time/batch = 0.269\n",
            "93/2810 (epoch 0), train_loss = 3.171, time/batch = 0.273\n",
            "94/2810 (epoch 0), train_loss = 3.124, time/batch = 0.263\n",
            "95/2810 (epoch 0), train_loss = 3.182, time/batch = 0.257\n",
            "96/2810 (epoch 0), train_loss = 3.067, time/batch = 0.245\n",
            "97/2810 (epoch 0), train_loss = 3.017, time/batch = 0.283\n",
            "98/2810 (epoch 0), train_loss = 3.030, time/batch = 0.243\n",
            "99/2810 (epoch 0), train_loss = 3.031, time/batch = 0.286\n",
            "100/2810 (epoch 0), train_loss = 3.055, time/batch = 0.265\n",
            "101/2810 (epoch 0), train_loss = 3.067, time/batch = 0.219\n",
            "102/2810 (epoch 0), train_loss = 3.074, time/batch = 0.156\n",
            "103/2810 (epoch 0), train_loss = 2.967, time/batch = 0.153\n",
            "104/2810 (epoch 0), train_loss = 3.006, time/batch = 0.150\n",
            "105/2810 (epoch 0), train_loss = 2.957, time/batch = 0.153\n",
            "106/2810 (epoch 0), train_loss = 3.013, time/batch = 0.150\n",
            "107/2810 (epoch 0), train_loss = 2.992, time/batch = 0.152\n",
            "108/2810 (epoch 0), train_loss = 3.150, time/batch = 0.178\n",
            "109/2810 (epoch 0), train_loss = 2.989, time/batch = 0.143\n",
            "110/2810 (epoch 0), train_loss = 2.971, time/batch = 0.153\n",
            "111/2810 (epoch 0), train_loss = 2.910, time/batch = 0.146\n",
            "112/2810 (epoch 0), train_loss = 2.914, time/batch = 0.162\n",
            "113/2810 (epoch 0), train_loss = 2.922, time/batch = 0.149\n",
            "114/2810 (epoch 0), train_loss = 2.974, time/batch = 0.153\n",
            "115/2810 (epoch 0), train_loss = 2.948, time/batch = 0.170\n",
            "116/2810 (epoch 0), train_loss = 2.926, time/batch = 0.156\n",
            "117/2810 (epoch 0), train_loss = 2.869, time/batch = 0.153\n",
            "118/2810 (epoch 0), train_loss = 2.911, time/batch = 0.146\n",
            "119/2810 (epoch 0), train_loss = 2.971, time/batch = 0.143\n",
            "120/2810 (epoch 0), train_loss = 2.916, time/batch = 0.162\n",
            "121/2810 (epoch 0), train_loss = 2.879, time/batch = 0.145\n",
            "122/2810 (epoch 0), train_loss = 2.873, time/batch = 0.168\n",
            "123/2810 (epoch 0), train_loss = 2.871, time/batch = 0.150\n",
            "124/2810 (epoch 0), train_loss = 2.839, time/batch = 0.159\n",
            "125/2810 (epoch 0), train_loss = 2.823, time/batch = 0.152\n",
            "126/2810 (epoch 0), train_loss = 2.811, time/batch = 0.158\n",
            "127/2810 (epoch 0), train_loss = 2.796, time/batch = 0.155\n",
            "128/2810 (epoch 0), train_loss = 2.859, time/batch = 0.181\n",
            "129/2810 (epoch 0), train_loss = 2.758, time/batch = 0.175\n",
            "130/2810 (epoch 0), train_loss = 2.799, time/batch = 0.151\n",
            "131/2810 (epoch 0), train_loss = 2.784, time/batch = 0.144\n",
            "132/2810 (epoch 0), train_loss = 2.761, time/batch = 0.155\n",
            "133/2810 (epoch 0), train_loss = 2.793, time/batch = 0.149\n",
            "134/2810 (epoch 0), train_loss = 2.776, time/batch = 0.150\n",
            "135/2810 (epoch 0), train_loss = 2.768, time/batch = 0.176\n",
            "136/2810 (epoch 0), train_loss = 2.880, time/batch = 0.144\n",
            "137/2810 (epoch 0), train_loss = 2.757, time/batch = 0.150\n",
            "138/2810 (epoch 0), train_loss = 2.753, time/batch = 0.159\n",
            "139/2810 (epoch 0), train_loss = 2.785, time/batch = 0.166\n",
            "140/2810 (epoch 0), train_loss = 2.776, time/batch = 0.156\n",
            "141/2810 (epoch 0), train_loss = 2.723, time/batch = 0.170\n",
            "142/2810 (epoch 0), train_loss = 2.828, time/batch = 0.167\n",
            "143/2810 (epoch 0), train_loss = 2.816, time/batch = 0.159\n",
            "144/2810 (epoch 0), train_loss = 2.724, time/batch = 0.154\n",
            "145/2810 (epoch 0), train_loss = 2.681, time/batch = 0.161\n",
            "146/2810 (epoch 0), train_loss = 2.730, time/batch = 0.152\n",
            "147/2810 (epoch 0), train_loss = 2.704, time/batch = 0.157\n",
            "148/2810 (epoch 0), train_loss = 2.717, time/batch = 0.175\n",
            "149/2810 (epoch 0), train_loss = 2.639, time/batch = 0.150\n",
            "150/2810 (epoch 0), train_loss = 2.681, time/batch = 0.157\n",
            "151/2810 (epoch 0), train_loss = 2.686, time/batch = 0.151\n",
            "152/2810 (epoch 0), train_loss = 2.629, time/batch = 0.155\n",
            "153/2810 (epoch 0), train_loss = 2.684, time/batch = 0.156\n",
            "154/2810 (epoch 0), train_loss = 2.666, time/batch = 0.155\n",
            "155/2810 (epoch 0), train_loss = 2.617, time/batch = 0.167\n",
            "156/2810 (epoch 0), train_loss = 2.686, time/batch = 0.153\n",
            "157/2810 (epoch 0), train_loss = 2.702, time/batch = 0.150\n",
            "158/2810 (epoch 0), train_loss = 2.697, time/batch = 0.153\n",
            "159/2810 (epoch 0), train_loss = 2.696, time/batch = 0.135\n",
            "160/2810 (epoch 0), train_loss = 2.666, time/batch = 0.159\n",
            "161/2810 (epoch 0), train_loss = 2.664, time/batch = 0.141\n",
            "162/2810 (epoch 0), train_loss = 2.690, time/batch = 0.167\n",
            "163/2810 (epoch 0), train_loss = 2.646, time/batch = 0.147\n",
            "164/2810 (epoch 0), train_loss = 2.754, time/batch = 0.141\n",
            "165/2810 (epoch 0), train_loss = 2.537, time/batch = 0.194\n",
            "166/2810 (epoch 0), train_loss = 2.588, time/batch = 0.262\n",
            "167/2810 (epoch 0), train_loss = 2.635, time/batch = 0.275\n",
            "168/2810 (epoch 0), train_loss = 2.564, time/batch = 0.255\n",
            "169/2810 (epoch 0), train_loss = 2.599, time/batch = 0.261\n",
            "170/2810 (epoch 0), train_loss = 2.615, time/batch = 0.262\n",
            "171/2810 (epoch 0), train_loss = 2.618, time/batch = 0.273\n",
            "172/2810 (epoch 0), train_loss = 2.562, time/batch = 0.257\n",
            "173/2810 (epoch 0), train_loss = 2.646, time/batch = 0.256\n",
            "174/2810 (epoch 0), train_loss = 2.588, time/batch = 0.271\n",
            "175/2810 (epoch 0), train_loss = 2.561, time/batch = 0.277\n",
            "176/2810 (epoch 0), train_loss = 2.533, time/batch = 0.267\n",
            "177/2810 (epoch 0), train_loss = 2.532, time/batch = 0.285\n",
            "178/2810 (epoch 0), train_loss = 2.545, time/batch = 0.154\n",
            "179/2810 (epoch 0), train_loss = 2.546, time/batch = 0.154\n",
            "180/2810 (epoch 0), train_loss = 2.480, time/batch = 0.153\n",
            "181/2810 (epoch 0), train_loss = 2.542, time/batch = 0.157\n",
            "182/2810 (epoch 0), train_loss = 2.553, time/batch = 0.145\n",
            "183/2810 (epoch 0), train_loss = 2.593, time/batch = 0.152\n",
            "184/2810 (epoch 0), train_loss = 2.624, time/batch = 0.156\n",
            "185/2810 (epoch 0), train_loss = 2.512, time/batch = 0.147\n",
            "186/2810 (epoch 0), train_loss = 2.467, time/batch = 0.144\n",
            "187/2810 (epoch 0), train_loss = 2.459, time/batch = 0.174\n",
            "188/2810 (epoch 0), train_loss = 2.557, time/batch = 0.148\n",
            "189/2810 (epoch 0), train_loss = 2.497, time/batch = 0.147\n",
            "190/2810 (epoch 0), train_loss = 2.541, time/batch = 0.156\n",
            "191/2810 (epoch 0), train_loss = 2.524, time/batch = 0.161\n",
            "192/2810 (epoch 0), train_loss = 2.559, time/batch = 0.163\n",
            "193/2810 (epoch 0), train_loss = 2.455, time/batch = 0.155\n",
            "194/2810 (epoch 0), train_loss = 2.481, time/batch = 0.168\n",
            "195/2810 (epoch 0), train_loss = 2.482, time/batch = 0.160\n",
            "196/2810 (epoch 0), train_loss = 2.603, time/batch = 0.154\n",
            "197/2810 (epoch 0), train_loss = 2.435, time/batch = 0.156\n",
            "198/2810 (epoch 0), train_loss = 2.541, time/batch = 0.166\n",
            "199/2810 (epoch 0), train_loss = 2.458, time/batch = 0.152\n",
            "200/2810 (epoch 0), train_loss = 2.518, time/batch = 0.180\n",
            "201/2810 (epoch 0), train_loss = 2.488, time/batch = 0.162\n",
            "202/2810 (epoch 0), train_loss = 2.497, time/batch = 0.144\n",
            "203/2810 (epoch 0), train_loss = 2.486, time/batch = 0.155\n",
            "204/2810 (epoch 0), train_loss = 2.523, time/batch = 0.146\n",
            "205/2810 (epoch 0), train_loss = 2.579, time/batch = 0.157\n",
            "206/2810 (epoch 0), train_loss = 2.483, time/batch = 0.145\n",
            "207/2810 (epoch 0), train_loss = 2.423, time/batch = 0.159\n",
            "208/2810 (epoch 0), train_loss = 2.438, time/batch = 0.144\n",
            "209/2810 (epoch 0), train_loss = 2.454, time/batch = 0.205\n",
            "210/2810 (epoch 0), train_loss = 2.497, time/batch = 0.159\n",
            "211/2810 (epoch 0), train_loss = 2.481, time/batch = 0.163\n",
            "212/2810 (epoch 0), train_loss = 2.450, time/batch = 0.152\n",
            "213/2810 (epoch 0), train_loss = 2.541, time/batch = 0.173\n",
            "214/2810 (epoch 0), train_loss = 2.424, time/batch = 0.163\n",
            "215/2810 (epoch 0), train_loss = 2.456, time/batch = 0.151\n",
            "216/2810 (epoch 0), train_loss = 2.432, time/batch = 0.149\n",
            "217/2810 (epoch 0), train_loss = 2.488, time/batch = 0.156\n",
            "218/2810 (epoch 0), train_loss = 2.461, time/batch = 0.145\n",
            "219/2810 (epoch 0), train_loss = 2.461, time/batch = 0.148\n",
            "220/2810 (epoch 0), train_loss = 2.413, time/batch = 0.166\n",
            "221/2810 (epoch 0), train_loss = 2.398, time/batch = 0.146\n",
            "222/2810 (epoch 0), train_loss = 2.423, time/batch = 0.153\n",
            "223/2810 (epoch 0), train_loss = 2.398, time/batch = 0.161\n",
            "224/2810 (epoch 0), train_loss = 2.369, time/batch = 0.156\n",
            "225/2810 (epoch 0), train_loss = 2.425, time/batch = 0.151\n",
            "226/2810 (epoch 0), train_loss = 2.380, time/batch = 0.151\n",
            "227/2810 (epoch 0), train_loss = 2.394, time/batch = 0.170\n",
            "228/2810 (epoch 0), train_loss = 2.435, time/batch = 0.148\n",
            "229/2810 (epoch 0), train_loss = 2.495, time/batch = 0.164\n",
            "230/2810 (epoch 0), train_loss = 2.416, time/batch = 0.164\n",
            "231/2810 (epoch 0), train_loss = 2.462, time/batch = 0.156\n",
            "232/2810 (epoch 0), train_loss = 2.467, time/batch = 0.162\n",
            "233/2810 (epoch 0), train_loss = 2.459, time/batch = 0.175\n",
            "234/2810 (epoch 0), train_loss = 2.377, time/batch = 0.149\n",
            "235/2810 (epoch 0), train_loss = 2.363, time/batch = 0.156\n",
            "236/2810 (epoch 0), train_loss = 2.417, time/batch = 0.157\n",
            "237/2810 (epoch 0), train_loss = 2.408, time/batch = 0.159\n",
            "238/2810 (epoch 0), train_loss = 2.476, time/batch = 0.146\n",
            "239/2810 (epoch 0), train_loss = 2.350, time/batch = 0.144\n",
            "240/2810 (epoch 0), train_loss = 2.377, time/batch = 0.169\n",
            "241/2810 (epoch 0), train_loss = 2.486, time/batch = 0.173\n",
            "242/2810 (epoch 0), train_loss = 2.400, time/batch = 0.266\n",
            "243/2810 (epoch 0), train_loss = 2.415, time/batch = 0.277\n",
            "244/2810 (epoch 0), train_loss = 2.411, time/batch = 0.272\n",
            "245/2810 (epoch 0), train_loss = 2.405, time/batch = 0.273\n",
            "246/2810 (epoch 0), train_loss = 2.400, time/batch = 0.262\n",
            "247/2810 (epoch 0), train_loss = 2.424, time/batch = 0.287\n",
            "248/2810 (epoch 0), train_loss = 2.355, time/batch = 0.293\n",
            "249/2810 (epoch 0), train_loss = 2.372, time/batch = 0.255\n",
            "250/2810 (epoch 0), train_loss = 2.321, time/batch = 0.268\n",
            "251/2810 (epoch 0), train_loss = 2.381, time/batch = 0.295\n",
            "252/2810 (epoch 0), train_loss = 2.351, time/batch = 0.301\n",
            "253/2810 (epoch 0), train_loss = 2.410, time/batch = 0.274\n",
            "254/2810 (epoch 0), train_loss = 2.359, time/batch = 0.155\n",
            "255/2810 (epoch 0), train_loss = 2.360, time/batch = 0.149\n",
            "256/2810 (epoch 0), train_loss = 2.332, time/batch = 0.145\n",
            "257/2810 (epoch 0), train_loss = 2.344, time/batch = 0.146\n",
            "258/2810 (epoch 0), train_loss = 2.316, time/batch = 0.171\n",
            "259/2810 (epoch 0), train_loss = 2.357, time/batch = 0.154\n",
            "260/2810 (epoch 0), train_loss = 2.352, time/batch = 0.158\n",
            "261/2810 (epoch 0), train_loss = 2.354, time/batch = 0.151\n",
            "262/2810 (epoch 0), train_loss = 2.274, time/batch = 0.150\n",
            "263/2810 (epoch 0), train_loss = 2.354, time/batch = 0.163\n",
            "264/2810 (epoch 0), train_loss = 2.429, time/batch = 0.147\n",
            "265/2810 (epoch 0), train_loss = 2.354, time/batch = 0.163\n",
            "266/2810 (epoch 0), train_loss = 2.319, time/batch = 0.150\n",
            "267/2810 (epoch 0), train_loss = 2.285, time/batch = 0.145\n",
            "268/2810 (epoch 0), train_loss = 2.322, time/batch = 0.144\n",
            "269/2810 (epoch 0), train_loss = 2.305, time/batch = 0.157\n",
            "270/2810 (epoch 0), train_loss = 2.308, time/batch = 0.155\n",
            "271/2810 (epoch 0), train_loss = 2.300, time/batch = 0.164\n",
            "272/2810 (epoch 0), train_loss = 2.334, time/batch = 0.150\n",
            "273/2810 (epoch 0), train_loss = 2.359, time/batch = 0.158\n",
            "274/2810 (epoch 0), train_loss = 2.369, time/batch = 0.151\n",
            "275/2810 (epoch 0), train_loss = 2.346, time/batch = 0.156\n",
            "276/2810 (epoch 0), train_loss = 2.317, time/batch = 0.156\n",
            "277/2810 (epoch 0), train_loss = 2.328, time/batch = 0.166\n",
            "278/2810 (epoch 0), train_loss = 2.273, time/batch = 0.176\n",
            "279/2810 (epoch 0), train_loss = 2.250, time/batch = 0.152\n",
            "280/2810 (epoch 0), train_loss = 2.403, time/batch = 0.156\n",
            "281/2810 (epoch 1), train_loss = 2.412, time/batch = 0.164\n",
            "282/2810 (epoch 1), train_loss = 2.363, time/batch = 0.163\n",
            "283/2810 (epoch 1), train_loss = 2.330, time/batch = 0.172\n",
            "284/2810 (epoch 1), train_loss = 2.377, time/batch = 0.153\n",
            "285/2810 (epoch 1), train_loss = 2.250, time/batch = 0.150\n",
            "286/2810 (epoch 1), train_loss = 2.277, time/batch = 0.150\n",
            "287/2810 (epoch 1), train_loss = 2.286, time/batch = 0.156\n",
            "288/2810 (epoch 1), train_loss = 2.288, time/batch = 0.157\n",
            "289/2810 (epoch 1), train_loss = 2.303, time/batch = 0.161\n",
            "290/2810 (epoch 1), train_loss = 2.240, time/batch = 0.164\n",
            "291/2810 (epoch 1), train_loss = 2.304, time/batch = 0.156\n",
            "292/2810 (epoch 1), train_loss = 2.290, time/batch = 0.151\n",
            "293/2810 (epoch 1), train_loss = 2.267, time/batch = 0.156\n",
            "294/2810 (epoch 1), train_loss = 2.315, time/batch = 0.143\n",
            "295/2810 (epoch 1), train_loss = 2.349, time/batch = 0.149\n",
            "296/2810 (epoch 1), train_loss = 2.304, time/batch = 0.147\n",
            "297/2810 (epoch 1), train_loss = 2.260, time/batch = 0.165\n",
            "298/2810 (epoch 1), train_loss = 2.359, time/batch = 0.161\n",
            "299/2810 (epoch 1), train_loss = 2.283, time/batch = 0.151\n",
            "300/2810 (epoch 1), train_loss = 2.314, time/batch = 0.154\n",
            "301/2810 (epoch 1), train_loss = 2.323, time/batch = 0.163\n",
            "302/2810 (epoch 1), train_loss = 2.322, time/batch = 0.158\n",
            "303/2810 (epoch 1), train_loss = 2.303, time/batch = 0.145\n",
            "304/2810 (epoch 1), train_loss = 2.262, time/batch = 0.154\n",
            "305/2810 (epoch 1), train_loss = 2.276, time/batch = 0.155\n",
            "306/2810 (epoch 1), train_loss = 2.288, time/batch = 0.149\n",
            "307/2810 (epoch 1), train_loss = 2.270, time/batch = 0.146\n",
            "308/2810 (epoch 1), train_loss = 2.254, time/batch = 0.151\n",
            "309/2810 (epoch 1), train_loss = 2.278, time/batch = 0.148\n",
            "310/2810 (epoch 1), train_loss = 2.333, time/batch = 0.175\n",
            "311/2810 (epoch 1), train_loss = 2.258, time/batch = 0.154\n",
            "312/2810 (epoch 1), train_loss = 2.244, time/batch = 0.155\n",
            "313/2810 (epoch 1), train_loss = 2.243, time/batch = 0.147\n",
            "314/2810 (epoch 1), train_loss = 2.322, time/batch = 0.161\n",
            "315/2810 (epoch 1), train_loss = 2.312, time/batch = 0.176\n",
            "316/2810 (epoch 1), train_loss = 2.267, time/batch = 0.157\n",
            "317/2810 (epoch 1), train_loss = 2.286, time/batch = 0.213\n",
            "318/2810 (epoch 1), train_loss = 2.265, time/batch = 0.250\n",
            "319/2810 (epoch 1), train_loss = 2.217, time/batch = 0.252\n",
            "320/2810 (epoch 1), train_loss = 2.282, time/batch = 0.287\n",
            "321/2810 (epoch 1), train_loss = 2.244, time/batch = 0.266\n",
            "322/2810 (epoch 1), train_loss = 2.221, time/batch = 0.266\n",
            "323/2810 (epoch 1), train_loss = 2.250, time/batch = 0.265\n",
            "324/2810 (epoch 1), train_loss = 2.229, time/batch = 0.268\n",
            "325/2810 (epoch 1), train_loss = 2.253, time/batch = 0.266\n",
            "326/2810 (epoch 1), train_loss = 2.234, time/batch = 0.229\n",
            "327/2810 (epoch 1), train_loss = 2.206, time/batch = 0.276\n",
            "328/2810 (epoch 1), train_loss = 2.205, time/batch = 0.286\n",
            "329/2810 (epoch 1), train_loss = 2.219, time/batch = 0.269\n",
            "330/2810 (epoch 1), train_loss = 2.223, time/batch = 0.157\n",
            "331/2810 (epoch 1), train_loss = 2.247, time/batch = 0.150\n",
            "332/2810 (epoch 1), train_loss = 2.267, time/batch = 0.145\n",
            "333/2810 (epoch 1), train_loss = 2.257, time/batch = 0.164\n",
            "334/2810 (epoch 1), train_loss = 2.243, time/batch = 0.158\n",
            "335/2810 (epoch 1), train_loss = 2.225, time/batch = 0.169\n",
            "336/2810 (epoch 1), train_loss = 2.248, time/batch = 0.153\n",
            "337/2810 (epoch 1), train_loss = 2.215, time/batch = 0.144\n",
            "338/2810 (epoch 1), train_loss = 2.217, time/batch = 0.161\n",
            "339/2810 (epoch 1), train_loss = 2.226, time/batch = 0.148\n",
            "340/2810 (epoch 1), train_loss = 2.155, time/batch = 0.139\n",
            "341/2810 (epoch 1), train_loss = 2.190, time/batch = 0.149\n",
            "342/2810 (epoch 1), train_loss = 2.171, time/batch = 0.162\n",
            "343/2810 (epoch 1), train_loss = 2.230, time/batch = 0.145\n",
            "344/2810 (epoch 1), train_loss = 2.239, time/batch = 0.153\n",
            "345/2810 (epoch 1), train_loss = 2.239, time/batch = 0.165\n",
            "346/2810 (epoch 1), train_loss = 2.263, time/batch = 0.153\n",
            "347/2810 (epoch 1), train_loss = 2.129, time/batch = 0.169\n",
            "348/2810 (epoch 1), train_loss = 2.208, time/batch = 0.153\n",
            "349/2810 (epoch 1), train_loss = 2.252, time/batch = 0.161\n",
            "350/2810 (epoch 1), train_loss = 2.216, time/batch = 0.155\n",
            "351/2810 (epoch 1), train_loss = 2.159, time/batch = 0.163\n",
            "352/2810 (epoch 1), train_loss = 2.241, time/batch = 0.160\n",
            "353/2810 (epoch 1), train_loss = 2.195, time/batch = 0.153\n",
            "354/2810 (epoch 1), train_loss = 2.190, time/batch = 0.153\n",
            "355/2810 (epoch 1), train_loss = 2.173, time/batch = 0.175\n",
            "356/2810 (epoch 1), train_loss = 2.199, time/batch = 0.160\n",
            "357/2810 (epoch 1), train_loss = 2.155, time/batch = 0.162\n",
            "358/2810 (epoch 1), train_loss = 2.169, time/batch = 0.152\n",
            "359/2810 (epoch 1), train_loss = 2.235, time/batch = 0.147\n",
            "360/2810 (epoch 1), train_loss = 2.225, time/batch = 0.145\n",
            "361/2810 (epoch 1), train_loss = 2.169, time/batch = 0.162\n",
            "362/2810 (epoch 1), train_loss = 2.138, time/batch = 0.177\n",
            "363/2810 (epoch 1), train_loss = 2.147, time/batch = 0.158\n",
            "364/2810 (epoch 1), train_loss = 2.135, time/batch = 0.163\n",
            "365/2810 (epoch 1), train_loss = 2.116, time/batch = 0.159\n",
            "366/2810 (epoch 1), train_loss = 2.157, time/batch = 0.151\n",
            "367/2810 (epoch 1), train_loss = 2.173, time/batch = 0.158\n",
            "368/2810 (epoch 1), train_loss = 2.213, time/batch = 0.165\n",
            "369/2810 (epoch 1), train_loss = 2.162, time/batch = 0.167\n",
            "370/2810 (epoch 1), train_loss = 2.171, time/batch = 0.157\n",
            "371/2810 (epoch 1), train_loss = 2.193, time/batch = 0.149\n",
            "372/2810 (epoch 1), train_loss = 2.169, time/batch = 0.161\n",
            "373/2810 (epoch 1), train_loss = 2.164, time/batch = 0.161\n",
            "374/2810 (epoch 1), train_loss = 2.269, time/batch = 0.157\n",
            "375/2810 (epoch 1), train_loss = 2.178, time/batch = 0.170\n",
            "376/2810 (epoch 1), train_loss = 2.234, time/batch = 0.157\n",
            "377/2810 (epoch 1), train_loss = 2.168, time/batch = 0.157\n",
            "378/2810 (epoch 1), train_loss = 2.094, time/batch = 0.160\n",
            "379/2810 (epoch 1), train_loss = 2.089, time/batch = 0.158\n",
            "380/2810 (epoch 1), train_loss = 2.144, time/batch = 0.152\n",
            "381/2810 (epoch 1), train_loss = 2.148, time/batch = 0.166\n",
            "382/2810 (epoch 1), train_loss = 2.188, time/batch = 0.157\n",
            "383/2810 (epoch 1), train_loss = 2.219, time/batch = 0.200\n",
            "384/2810 (epoch 1), train_loss = 2.157, time/batch = 0.150\n",
            "385/2810 (epoch 1), train_loss = 2.119, time/batch = 0.146\n",
            "386/2810 (epoch 1), train_loss = 2.079, time/batch = 0.151\n",
            "387/2810 (epoch 1), train_loss = 2.150, time/batch = 0.151\n",
            "388/2810 (epoch 1), train_loss = 2.182, time/batch = 0.169\n",
            "389/2810 (epoch 1), train_loss = 2.213, time/batch = 0.156\n",
            "390/2810 (epoch 1), train_loss = 2.125, time/batch = 0.148\n",
            "391/2810 (epoch 1), train_loss = 2.158, time/batch = 0.147\n",
            "392/2810 (epoch 1), train_loss = 2.051, time/batch = 0.150\n",
            "393/2810 (epoch 1), train_loss = 2.100, time/batch = 0.203\n",
            "394/2810 (epoch 1), train_loss = 2.107, time/batch = 0.284\n",
            "395/2810 (epoch 1), train_loss = 2.164, time/batch = 0.220\n",
            "396/2810 (epoch 1), train_loss = 2.130, time/batch = 0.243\n",
            "397/2810 (epoch 1), train_loss = 2.139, time/batch = 0.279\n",
            "398/2810 (epoch 1), train_loss = 2.112, time/batch = 0.255\n",
            "399/2810 (epoch 1), train_loss = 2.099, time/batch = 0.272\n",
            "400/2810 (epoch 1), train_loss = 2.155, time/batch = 0.263\n",
            "401/2810 (epoch 1), train_loss = 2.109, time/batch = 0.263\n",
            "402/2810 (epoch 1), train_loss = 2.119, time/batch = 0.297\n",
            "403/2810 (epoch 1), train_loss = 2.140, time/batch = 0.266\n",
            "404/2810 (epoch 1), train_loss = 2.119, time/batch = 0.271\n",
            "405/2810 (epoch 1), train_loss = 2.106, time/batch = 0.290\n",
            "406/2810 (epoch 1), train_loss = 2.089, time/batch = 0.170\n",
            "407/2810 (epoch 1), train_loss = 2.094, time/batch = 0.149\n",
            "408/2810 (epoch 1), train_loss = 2.113, time/batch = 0.154\n",
            "409/2810 (epoch 1), train_loss = 2.179, time/batch = 0.152\n",
            "410/2810 (epoch 1), train_loss = 2.076, time/batch = 0.158\n",
            "411/2810 (epoch 1), train_loss = 2.118, time/batch = 0.163\n",
            "412/2810 (epoch 1), train_loss = 2.129, time/batch = 0.156\n",
            "413/2810 (epoch 1), train_loss = 2.117, time/batch = 0.161\n",
            "414/2810 (epoch 1), train_loss = 2.113, time/batch = 0.145\n",
            "415/2810 (epoch 1), train_loss = 2.118, time/batch = 0.153\n",
            "416/2810 (epoch 1), train_loss = 2.123, time/batch = 0.146\n",
            "417/2810 (epoch 1), train_loss = 2.194, time/batch = 0.150\n",
            "418/2810 (epoch 1), train_loss = 2.143, time/batch = 0.159\n",
            "419/2810 (epoch 1), train_loss = 2.129, time/batch = 0.165\n",
            "420/2810 (epoch 1), train_loss = 2.155, time/batch = 0.151\n",
            "421/2810 (epoch 1), train_loss = 2.137, time/batch = 0.154\n",
            "422/2810 (epoch 1), train_loss = 2.106, time/batch = 0.146\n",
            "423/2810 (epoch 1), train_loss = 2.231, time/batch = 0.160\n",
            "424/2810 (epoch 1), train_loss = 2.207, time/batch = 0.149\n",
            "425/2810 (epoch 1), train_loss = 2.114, time/batch = 0.159\n",
            "426/2810 (epoch 1), train_loss = 2.068, time/batch = 0.183\n",
            "427/2810 (epoch 1), train_loss = 2.144, time/batch = 0.154\n",
            "428/2810 (epoch 1), train_loss = 2.148, time/batch = 0.152\n",
            "429/2810 (epoch 1), train_loss = 2.154, time/batch = 0.160\n",
            "430/2810 (epoch 1), train_loss = 2.120, time/batch = 0.154\n",
            "431/2810 (epoch 1), train_loss = 2.183, time/batch = 0.158\n",
            "432/2810 (epoch 1), train_loss = 2.104, time/batch = 0.154\n",
            "433/2810 (epoch 1), train_loss = 2.125, time/batch = 0.162\n",
            "434/2810 (epoch 1), train_loss = 2.163, time/batch = 0.149\n",
            "435/2810 (epoch 1), train_loss = 2.124, time/batch = 0.155\n",
            "436/2810 (epoch 1), train_loss = 2.092, time/batch = 0.148\n",
            "437/2810 (epoch 1), train_loss = 2.147, time/batch = 0.166\n",
            "438/2810 (epoch 1), train_loss = 2.100, time/batch = 0.156\n",
            "439/2810 (epoch 1), train_loss = 2.119, time/batch = 0.172\n",
            "440/2810 (epoch 1), train_loss = 2.153, time/batch = 0.150\n",
            "441/2810 (epoch 1), train_loss = 2.121, time/batch = 0.168\n",
            "442/2810 (epoch 1), train_loss = 2.139, time/batch = 0.148\n",
            "443/2810 (epoch 1), train_loss = 2.170, time/batch = 0.159\n",
            "444/2810 (epoch 1), train_loss = 2.108, time/batch = 0.154\n",
            "445/2810 (epoch 1), train_loss = 2.160, time/batch = 0.151\n",
            "446/2810 (epoch 1), train_loss = 2.031, time/batch = 0.162\n",
            "447/2810 (epoch 1), train_loss = 2.099, time/batch = 0.165\n",
            "448/2810 (epoch 1), train_loss = 2.097, time/batch = 0.148\n",
            "449/2810 (epoch 1), train_loss = 2.054, time/batch = 0.149\n",
            "450/2810 (epoch 1), train_loss = 2.090, time/batch = 0.163\n",
            "451/2810 (epoch 1), train_loss = 2.115, time/batch = 0.149\n",
            "452/2810 (epoch 1), train_loss = 2.054, time/batch = 0.169\n",
            "453/2810 (epoch 1), train_loss = 2.046, time/batch = 0.164\n",
            "454/2810 (epoch 1), train_loss = 2.139, time/batch = 0.141\n",
            "455/2810 (epoch 1), train_loss = 2.119, time/batch = 0.152\n",
            "456/2810 (epoch 1), train_loss = 2.093, time/batch = 0.150\n",
            "457/2810 (epoch 1), train_loss = 2.039, time/batch = 0.169\n",
            "458/2810 (epoch 1), train_loss = 2.065, time/batch = 0.152\n",
            "459/2810 (epoch 1), train_loss = 2.106, time/batch = 0.167\n",
            "460/2810 (epoch 1), train_loss = 2.106, time/batch = 0.168\n",
            "461/2810 (epoch 1), train_loss = 1.991, time/batch = 0.155\n",
            "462/2810 (epoch 1), train_loss = 2.101, time/batch = 0.149\n",
            "463/2810 (epoch 1), train_loss = 2.104, time/batch = 0.162\n",
            "464/2810 (epoch 1), train_loss = 2.101, time/batch = 0.153\n",
            "465/2810 (epoch 1), train_loss = 2.114, time/batch = 0.173\n",
            "466/2810 (epoch 1), train_loss = 1.988, time/batch = 0.153\n",
            "467/2810 (epoch 1), train_loss = 2.034, time/batch = 0.163\n",
            "468/2810 (epoch 1), train_loss = 2.065, time/batch = 0.145\n",
            "469/2810 (epoch 1), train_loss = 2.141, time/batch = 0.187\n",
            "470/2810 (epoch 1), train_loss = 2.048, time/batch = 0.274\n",
            "471/2810 (epoch 1), train_loss = 2.103, time/batch = 0.315\n",
            "472/2810 (epoch 1), train_loss = 2.082, time/batch = 0.270\n",
            "473/2810 (epoch 1), train_loss = 2.135, time/batch = 0.270\n",
            "474/2810 (epoch 1), train_loss = 2.019, time/batch = 0.262\n",
            "475/2810 (epoch 1), train_loss = 2.043, time/batch = 0.288\n",
            "476/2810 (epoch 1), train_loss = 2.041, time/batch = 0.291\n",
            "477/2810 (epoch 1), train_loss = 2.151, time/batch = 0.273\n",
            "478/2810 (epoch 1), train_loss = 1.984, time/batch = 0.245\n",
            "479/2810 (epoch 1), train_loss = 2.094, time/batch = 0.253\n",
            "480/2810 (epoch 1), train_loss = 2.022, time/batch = 0.280\n",
            "481/2810 (epoch 1), train_loss = 2.093, time/batch = 0.288\n",
            "482/2810 (epoch 1), train_loss = 2.062, time/batch = 0.159\n",
            "483/2810 (epoch 1), train_loss = 2.086, time/batch = 0.162\n",
            "484/2810 (epoch 1), train_loss = 2.072, time/batch = 0.146\n",
            "485/2810 (epoch 1), train_loss = 2.074, time/batch = 0.155\n",
            "486/2810 (epoch 1), train_loss = 2.115, time/batch = 0.155\n",
            "487/2810 (epoch 1), train_loss = 2.042, time/batch = 0.148\n",
            "488/2810 (epoch 1), train_loss = 1.997, time/batch = 0.139\n",
            "489/2810 (epoch 1), train_loss = 2.023, time/batch = 0.144\n",
            "490/2810 (epoch 1), train_loss = 2.044, time/batch = 0.171\n",
            "491/2810 (epoch 1), train_loss = 2.068, time/batch = 0.166\n",
            "492/2810 (epoch 1), train_loss = 2.074, time/batch = 0.158\n",
            "493/2810 (epoch 1), train_loss = 2.042, time/batch = 0.149\n",
            "494/2810 (epoch 1), train_loss = 2.123, time/batch = 0.163\n",
            "495/2810 (epoch 1), train_loss = 2.032, time/batch = 0.145\n",
            "496/2810 (epoch 1), train_loss = 2.033, time/batch = 0.149\n",
            "497/2810 (epoch 1), train_loss = 2.051, time/batch = 0.165\n",
            "498/2810 (epoch 1), train_loss = 2.083, time/batch = 0.158\n",
            "499/2810 (epoch 1), train_loss = 2.087, time/batch = 0.166\n",
            "500/2810 (epoch 1), train_loss = 2.098, time/batch = 0.170\n",
            "501/2810 (epoch 1), train_loss = 2.025, time/batch = 0.152\n",
            "502/2810 (epoch 1), train_loss = 2.006, time/batch = 0.150\n",
            "503/2810 (epoch 1), train_loss = 2.042, time/batch = 0.176\n",
            "504/2810 (epoch 1), train_loss = 2.008, time/batch = 0.158\n",
            "505/2810 (epoch 1), train_loss = 1.986, time/batch = 0.161\n",
            "506/2810 (epoch 1), train_loss = 2.035, time/batch = 0.160\n",
            "507/2810 (epoch 1), train_loss = 2.016, time/batch = 0.161\n",
            "508/2810 (epoch 1), train_loss = 2.048, time/batch = 0.155\n",
            "509/2810 (epoch 1), train_loss = 2.040, time/batch = 0.156\n",
            "510/2810 (epoch 1), train_loss = 2.115, time/batch = 0.173\n",
            "511/2810 (epoch 1), train_loss = 2.029, time/batch = 0.163\n",
            "512/2810 (epoch 1), train_loss = 2.065, time/batch = 0.152\n",
            "513/2810 (epoch 1), train_loss = 2.070, time/batch = 0.160\n",
            "514/2810 (epoch 1), train_loss = 2.039, time/batch = 0.155\n",
            "515/2810 (epoch 1), train_loss = 2.010, time/batch = 0.151\n",
            "516/2810 (epoch 1), train_loss = 1.972, time/batch = 0.172\n",
            "517/2810 (epoch 1), train_loss = 2.054, time/batch = 0.162\n",
            "518/2810 (epoch 1), train_loss = 2.063, time/batch = 0.157\n",
            "519/2810 (epoch 1), train_loss = 2.058, time/batch = 0.155\n",
            "520/2810 (epoch 1), train_loss = 2.005, time/batch = 0.149\n",
            "521/2810 (epoch 1), train_loss = 2.011, time/batch = 0.146\n",
            "522/2810 (epoch 1), train_loss = 2.108, time/batch = 0.150\n",
            "523/2810 (epoch 1), train_loss = 2.015, time/batch = 0.169\n",
            "524/2810 (epoch 1), train_loss = 2.061, time/batch = 0.155\n",
            "525/2810 (epoch 1), train_loss = 2.042, time/batch = 0.150\n",
            "526/2810 (epoch 1), train_loss = 2.071, time/batch = 0.167\n",
            "527/2810 (epoch 1), train_loss = 2.036, time/batch = 0.148\n",
            "528/2810 (epoch 1), train_loss = 2.066, time/batch = 0.155\n",
            "529/2810 (epoch 1), train_loss = 2.016, time/batch = 0.177\n",
            "530/2810 (epoch 1), train_loss = 2.042, time/batch = 0.161\n",
            "531/2810 (epoch 1), train_loss = 1.976, time/batch = 0.151\n",
            "532/2810 (epoch 1), train_loss = 2.034, time/batch = 0.164\n",
            "533/2810 (epoch 1), train_loss = 2.038, time/batch = 0.170\n",
            "534/2810 (epoch 1), train_loss = 2.036, time/batch = 0.153\n",
            "535/2810 (epoch 1), train_loss = 2.022, time/batch = 0.158\n",
            "536/2810 (epoch 1), train_loss = 2.018, time/batch = 0.174\n",
            "537/2810 (epoch 1), train_loss = 2.010, time/batch = 0.151\n",
            "538/2810 (epoch 1), train_loss = 1.982, time/batch = 0.170\n",
            "539/2810 (epoch 1), train_loss = 1.991, time/batch = 0.151\n",
            "540/2810 (epoch 1), train_loss = 2.051, time/batch = 0.152\n",
            "541/2810 (epoch 1), train_loss = 2.022, time/batch = 0.149\n",
            "542/2810 (epoch 1), train_loss = 2.009, time/batch = 0.177\n",
            "543/2810 (epoch 1), train_loss = 1.929, time/batch = 0.140\n",
            "544/2810 (epoch 1), train_loss = 2.022, time/batch = 0.148\n",
            "545/2810 (epoch 1), train_loss = 2.070, time/batch = 0.205\n",
            "546/2810 (epoch 1), train_loss = 2.039, time/batch = 0.253\n",
            "547/2810 (epoch 1), train_loss = 2.001, time/batch = 0.248\n",
            "548/2810 (epoch 1), train_loss = 1.976, time/batch = 0.275\n",
            "549/2810 (epoch 1), train_loss = 2.013, time/batch = 0.275\n",
            "550/2810 (epoch 1), train_loss = 2.007, time/batch = 0.288\n",
            "551/2810 (epoch 1), train_loss = 2.004, time/batch = 0.266\n",
            "552/2810 (epoch 1), train_loss = 1.969, time/batch = 0.251\n",
            "553/2810 (epoch 1), train_loss = 2.005, time/batch = 0.295\n",
            "554/2810 (epoch 1), train_loss = 2.030, time/batch = 0.269\n",
            "555/2810 (epoch 1), train_loss = 2.077, time/batch = 0.262\n",
            "556/2810 (epoch 1), train_loss = 2.052, time/batch = 0.299\n",
            "557/2810 (epoch 1), train_loss = 2.005, time/batch = 0.249\n",
            "558/2810 (epoch 1), train_loss = 2.026, time/batch = 0.235\n",
            "559/2810 (epoch 1), train_loss = 1.955, time/batch = 0.167\n",
            "560/2810 (epoch 1), train_loss = 1.962, time/batch = 0.171\n",
            "561/2810 (epoch 1), train_loss = 2.035, time/batch = 0.160\n",
            "562/2810 (epoch 2), train_loss = 2.103, time/batch = 0.166\n",
            "563/2810 (epoch 2), train_loss = 2.051, time/batch = 0.153\n",
            "564/2810 (epoch 2), train_loss = 2.012, time/batch = 0.159\n",
            "565/2810 (epoch 2), train_loss = 2.028, time/batch = 0.176\n",
            "566/2810 (epoch 2), train_loss = 1.946, time/batch = 0.166\n",
            "567/2810 (epoch 2), train_loss = 2.000, time/batch = 0.204\n",
            "568/2810 (epoch 2), train_loss = 1.984, time/batch = 0.262\n",
            "569/2810 (epoch 2), train_loss = 1.971, time/batch = 0.268\n",
            "570/2810 (epoch 2), train_loss = 2.035, time/batch = 0.290\n",
            "571/2810 (epoch 2), train_loss = 1.939, time/batch = 0.276\n",
            "572/2810 (epoch 2), train_loss = 2.022, time/batch = 0.270\n",
            "573/2810 (epoch 2), train_loss = 2.008, time/batch = 0.277\n",
            "574/2810 (epoch 2), train_loss = 1.973, time/batch = 0.285\n",
            "575/2810 (epoch 2), train_loss = 2.007, time/batch = 0.273\n",
            "576/2810 (epoch 2), train_loss = 2.036, time/batch = 0.256\n",
            "577/2810 (epoch 2), train_loss = 2.012, time/batch = 0.252\n",
            "578/2810 (epoch 2), train_loss = 1.964, time/batch = 0.314\n",
            "579/2810 (epoch 2), train_loss = 2.083, time/batch = 0.232\n",
            "580/2810 (epoch 2), train_loss = 1.980, time/batch = 0.170\n",
            "581/2810 (epoch 2), train_loss = 2.020, time/batch = 0.150\n",
            "582/2810 (epoch 2), train_loss = 2.022, time/batch = 0.154\n",
            "583/2810 (epoch 2), train_loss = 2.025, time/batch = 0.148\n",
            "584/2810 (epoch 2), train_loss = 2.013, time/batch = 0.159\n",
            "585/2810 (epoch 2), train_loss = 1.996, time/batch = 0.148\n",
            "586/2810 (epoch 2), train_loss = 1.988, time/batch = 0.160\n",
            "587/2810 (epoch 2), train_loss = 1.983, time/batch = 0.158\n",
            "588/2810 (epoch 2), train_loss = 1.995, time/batch = 0.155\n",
            "589/2810 (epoch 2), train_loss = 1.973, time/batch = 0.143\n",
            "590/2810 (epoch 2), train_loss = 1.970, time/batch = 0.166\n",
            "591/2810 (epoch 2), train_loss = 2.014, time/batch = 0.154\n",
            "592/2810 (epoch 2), train_loss = 1.984, time/batch = 0.148\n",
            "593/2810 (epoch 2), train_loss = 1.991, time/batch = 0.156\n",
            "594/2810 (epoch 2), train_loss = 1.942, time/batch = 0.155\n",
            "595/2810 (epoch 2), train_loss = 2.058, time/batch = 0.147\n",
            "596/2810 (epoch 2), train_loss = 2.036, time/batch = 0.151\n",
            "597/2810 (epoch 2), train_loss = 1.982, time/batch = 0.164\n",
            "598/2810 (epoch 2), train_loss = 2.011, time/batch = 0.144\n",
            "599/2810 (epoch 2), train_loss = 2.003, time/batch = 0.149\n",
            "600/2810 (epoch 2), train_loss = 1.963, time/batch = 0.149\n",
            "601/2810 (epoch 2), train_loss = 2.004, time/batch = 0.138\n",
            "602/2810 (epoch 2), train_loss = 1.958, time/batch = 0.147\n",
            "603/2810 (epoch 2), train_loss = 1.948, time/batch = 0.138\n",
            "604/2810 (epoch 2), train_loss = 1.989, time/batch = 0.165\n",
            "605/2810 (epoch 2), train_loss = 1.983, time/batch = 0.142\n",
            "606/2810 (epoch 2), train_loss = 2.001, time/batch = 0.152\n",
            "607/2810 (epoch 2), train_loss = 1.958, time/batch = 0.146\n",
            "608/2810 (epoch 2), train_loss = 1.932, time/batch = 0.148\n",
            "609/2810 (epoch 2), train_loss = 1.934, time/batch = 0.147\n",
            "610/2810 (epoch 2), train_loss = 1.959, time/batch = 0.154\n",
            "611/2810 (epoch 2), train_loss = 1.958, time/batch = 0.158\n",
            "612/2810 (epoch 2), train_loss = 1.976, time/batch = 0.152\n",
            "613/2810 (epoch 2), train_loss = 1.987, time/batch = 0.225\n",
            "614/2810 (epoch 2), train_loss = 1.977, time/batch = 0.249\n",
            "615/2810 (epoch 2), train_loss = 1.991, time/batch = 0.257\n",
            "616/2810 (epoch 2), train_loss = 1.966, time/batch = 0.262\n",
            "617/2810 (epoch 2), train_loss = 1.949, time/batch = 0.271\n",
            "618/2810 (epoch 2), train_loss = 1.964, time/batch = 0.253\n",
            "619/2810 (epoch 2), train_loss = 1.969, time/batch = 0.266\n",
            "620/2810 (epoch 2), train_loss = 1.981, time/batch = 0.270\n",
            "621/2810 (epoch 2), train_loss = 1.914, time/batch = 0.275\n",
            "622/2810 (epoch 2), train_loss = 1.949, time/batch = 0.267\n",
            "623/2810 (epoch 2), train_loss = 1.931, time/batch = 0.262\n",
            "624/2810 (epoch 2), train_loss = 1.977, time/batch = 0.287\n",
            "625/2810 (epoch 2), train_loss = 1.996, time/batch = 0.207\n",
            "626/2810 (epoch 2), train_loss = 2.008, time/batch = 0.164\n",
            "627/2810 (epoch 2), train_loss = 2.001, time/batch = 0.151\n",
            "628/2810 (epoch 2), train_loss = 1.870, time/batch = 0.162\n",
            "629/2810 (epoch 2), train_loss = 1.972, time/batch = 0.173\n",
            "630/2810 (epoch 2), train_loss = 2.015, time/batch = 0.162\n",
            "631/2810 (epoch 2), train_loss = 1.961, time/batch = 0.156\n",
            "632/2810 (epoch 2), train_loss = 1.923, time/batch = 0.149\n",
            "633/2810 (epoch 2), train_loss = 1.998, time/batch = 0.145\n",
            "634/2810 (epoch 2), train_loss = 1.974, time/batch = 0.153\n",
            "635/2810 (epoch 2), train_loss = 1.953, time/batch = 0.142\n",
            "636/2810 (epoch 2), train_loss = 1.918, time/batch = 0.174\n",
            "637/2810 (epoch 2), train_loss = 1.951, time/batch = 0.148\n",
            "638/2810 (epoch 2), train_loss = 1.911, time/batch = 0.152\n",
            "639/2810 (epoch 2), train_loss = 1.933, time/batch = 0.157\n",
            "640/2810 (epoch 2), train_loss = 1.977, time/batch = 0.146\n",
            "641/2810 (epoch 2), train_loss = 1.999, time/batch = 0.155\n",
            "642/2810 (epoch 2), train_loss = 1.920, time/batch = 0.164\n",
            "643/2810 (epoch 2), train_loss = 1.910, time/batch = 0.160\n",
            "644/2810 (epoch 2), train_loss = 1.915, time/batch = 0.159\n",
            "645/2810 (epoch 2), train_loss = 1.891, time/batch = 0.159\n",
            "646/2810 (epoch 2), train_loss = 1.864, time/batch = 0.143\n",
            "647/2810 (epoch 2), train_loss = 1.928, time/batch = 0.153\n",
            "648/2810 (epoch 2), train_loss = 1.936, time/batch = 0.153\n",
            "649/2810 (epoch 2), train_loss = 1.988, time/batch = 0.158\n",
            "650/2810 (epoch 2), train_loss = 1.925, time/batch = 0.160\n",
            "651/2810 (epoch 2), train_loss = 1.943, time/batch = 0.147\n",
            "652/2810 (epoch 2), train_loss = 1.954, time/batch = 0.157\n",
            "653/2810 (epoch 2), train_loss = 1.931, time/batch = 0.150\n",
            "654/2810 (epoch 2), train_loss = 1.942, time/batch = 0.153\n",
            "655/2810 (epoch 2), train_loss = 2.028, time/batch = 0.154\n",
            "656/2810 (epoch 2), train_loss = 1.962, time/batch = 0.179\n",
            "657/2810 (epoch 2), train_loss = 2.001, time/batch = 0.152\n",
            "658/2810 (epoch 2), train_loss = 1.944, time/batch = 0.149\n",
            "659/2810 (epoch 2), train_loss = 1.864, time/batch = 0.150\n",
            "660/2810 (epoch 2), train_loss = 1.868, time/batch = 0.154\n",
            "661/2810 (epoch 2), train_loss = 1.913, time/batch = 0.153\n",
            "662/2810 (epoch 2), train_loss = 1.908, time/batch = 0.160\n",
            "663/2810 (epoch 2), train_loss = 1.956, time/batch = 0.155\n",
            "664/2810 (epoch 2), train_loss = 1.997, time/batch = 0.148\n",
            "665/2810 (epoch 2), train_loss = 1.953, time/batch = 0.148\n",
            "666/2810 (epoch 2), train_loss = 1.877, time/batch = 0.150\n",
            "667/2810 (epoch 2), train_loss = 1.851, time/batch = 0.145\n",
            "668/2810 (epoch 2), train_loss = 1.928, time/batch = 0.149\n",
            "669/2810 (epoch 2), train_loss = 1.978, time/batch = 0.150\n",
            "670/2810 (epoch 2), train_loss = 1.965, time/batch = 0.165\n",
            "671/2810 (epoch 2), train_loss = 1.916, time/batch = 0.146\n",
            "672/2810 (epoch 2), train_loss = 1.944, time/batch = 0.155\n",
            "673/2810 (epoch 2), train_loss = 1.833, time/batch = 0.146\n",
            "674/2810 (epoch 2), train_loss = 1.888, time/batch = 0.147\n",
            "675/2810 (epoch 2), train_loss = 1.909, time/batch = 0.150\n",
            "676/2810 (epoch 2), train_loss = 1.963, time/batch = 0.157\n",
            "677/2810 (epoch 2), train_loss = 1.928, time/batch = 0.164\n",
            "678/2810 (epoch 2), train_loss = 1.926, time/batch = 0.151\n",
            "679/2810 (epoch 2), train_loss = 1.908, time/batch = 0.145\n",
            "680/2810 (epoch 2), train_loss = 1.884, time/batch = 0.152\n",
            "681/2810 (epoch 2), train_loss = 1.950, time/batch = 0.151\n",
            "682/2810 (epoch 2), train_loss = 1.900, time/batch = 0.163\n",
            "683/2810 (epoch 2), train_loss = 1.901, time/batch = 0.169\n",
            "684/2810 (epoch 2), train_loss = 1.920, time/batch = 0.146\n",
            "685/2810 (epoch 2), train_loss = 1.924, time/batch = 0.144\n",
            "686/2810 (epoch 2), train_loss = 1.906, time/batch = 0.154\n",
            "687/2810 (epoch 2), train_loss = 1.875, time/batch = 0.140\n",
            "688/2810 (epoch 2), train_loss = 1.891, time/batch = 0.143\n",
            "689/2810 (epoch 2), train_loss = 1.901, time/batch = 0.151\n",
            "690/2810 (epoch 2), train_loss = 1.980, time/batch = 0.223\n",
            "691/2810 (epoch 2), train_loss = 1.893, time/batch = 0.263\n",
            "692/2810 (epoch 2), train_loss = 1.925, time/batch = 0.244\n",
            "693/2810 (epoch 2), train_loss = 1.908, time/batch = 0.275\n",
            "694/2810 (epoch 2), train_loss = 1.930, time/batch = 0.261\n",
            "695/2810 (epoch 2), train_loss = 1.924, time/batch = 0.265\n",
            "696/2810 (epoch 2), train_loss = 1.912, time/batch = 0.269\n",
            "697/2810 (epoch 2), train_loss = 1.934, time/batch = 0.251\n",
            "698/2810 (epoch 2), train_loss = 1.993, time/batch = 0.274\n",
            "699/2810 (epoch 2), train_loss = 1.954, time/batch = 0.242\n",
            "700/2810 (epoch 2), train_loss = 1.923, time/batch = 0.235\n",
            "701/2810 (epoch 2), train_loss = 1.958, time/batch = 0.278\n",
            "702/2810 (epoch 2), train_loss = 1.946, time/batch = 0.244\n",
            "703/2810 (epoch 2), train_loss = 1.912, time/batch = 0.170\n",
            "704/2810 (epoch 2), train_loss = 2.016, time/batch = 0.160\n",
            "705/2810 (epoch 2), train_loss = 2.006, time/batch = 0.148\n",
            "706/2810 (epoch 2), train_loss = 1.910, time/batch = 0.154\n",
            "707/2810 (epoch 2), train_loss = 1.873, time/batch = 0.152\n",
            "708/2810 (epoch 2), train_loss = 1.948, time/batch = 0.153\n",
            "709/2810 (epoch 2), train_loss = 1.969, time/batch = 0.166\n",
            "710/2810 (epoch 2), train_loss = 1.960, time/batch = 0.152\n",
            "711/2810 (epoch 2), train_loss = 1.939, time/batch = 0.153\n",
            "712/2810 (epoch 2), train_loss = 1.991, time/batch = 0.160\n",
            "713/2810 (epoch 2), train_loss = 1.905, time/batch = 0.161\n",
            "714/2810 (epoch 2), train_loss = 1.941, time/batch = 0.151\n",
            "715/2810 (epoch 2), train_loss = 1.980, time/batch = 0.152\n",
            "716/2810 (epoch 2), train_loss = 1.919, time/batch = 0.166\n",
            "717/2810 (epoch 2), train_loss = 1.909, time/batch = 0.168\n",
            "718/2810 (epoch 2), train_loss = 1.950, time/batch = 0.164\n",
            "719/2810 (epoch 2), train_loss = 1.888, time/batch = 0.149\n",
            "720/2810 (epoch 2), train_loss = 1.910, time/batch = 0.152\n",
            "721/2810 (epoch 2), train_loss = 1.948, time/batch = 0.145\n",
            "722/2810 (epoch 2), train_loss = 1.926, time/batch = 0.163\n",
            "723/2810 (epoch 2), train_loss = 1.970, time/batch = 0.151\n",
            "724/2810 (epoch 2), train_loss = 1.970, time/batch = 0.147\n",
            "725/2810 (epoch 2), train_loss = 1.924, time/batch = 0.151\n",
            "726/2810 (epoch 2), train_loss = 1.947, time/batch = 0.153\n",
            "727/2810 (epoch 2), train_loss = 1.848, time/batch = 0.150\n",
            "728/2810 (epoch 2), train_loss = 1.912, time/batch = 0.166\n",
            "729/2810 (epoch 2), train_loss = 1.912, time/batch = 0.160\n",
            "730/2810 (epoch 2), train_loss = 1.864, time/batch = 0.153\n",
            "731/2810 (epoch 2), train_loss = 1.896, time/batch = 0.147\n",
            "732/2810 (epoch 2), train_loss = 1.931, time/batch = 0.150\n",
            "733/2810 (epoch 2), train_loss = 1.858, time/batch = 0.153\n",
            "734/2810 (epoch 2), train_loss = 1.842, time/batch = 0.145\n",
            "735/2810 (epoch 2), train_loss = 1.976, time/batch = 0.137\n",
            "736/2810 (epoch 2), train_loss = 1.933, time/batch = 0.177\n",
            "737/2810 (epoch 2), train_loss = 1.914, time/batch = 0.143\n",
            "738/2810 (epoch 2), train_loss = 1.862, time/batch = 0.157\n",
            "739/2810 (epoch 2), train_loss = 1.880, time/batch = 0.147\n",
            "740/2810 (epoch 2), train_loss = 1.934, time/batch = 0.155\n",
            "741/2810 (epoch 2), train_loss = 1.926, time/batch = 0.153\n",
            "742/2810 (epoch 2), train_loss = 1.805, time/batch = 0.147\n",
            "743/2810 (epoch 2), train_loss = 1.907, time/batch = 0.165\n",
            "744/2810 (epoch 2), train_loss = 1.926, time/batch = 0.150\n",
            "745/2810 (epoch 2), train_loss = 1.915, time/batch = 0.147\n",
            "746/2810 (epoch 2), train_loss = 1.933, time/batch = 0.131\n",
            "747/2810 (epoch 2), train_loss = 1.826, time/batch = 0.143\n",
            "748/2810 (epoch 2), train_loss = 1.863, time/batch = 0.160\n",
            "749/2810 (epoch 2), train_loss = 1.887, time/batch = 0.146\n",
            "750/2810 (epoch 2), train_loss = 1.965, time/batch = 0.165\n",
            "751/2810 (epoch 2), train_loss = 1.871, time/batch = 0.150\n",
            "752/2810 (epoch 2), train_loss = 1.920, time/batch = 0.157\n",
            "753/2810 (epoch 2), train_loss = 1.916, time/batch = 0.149\n",
            "754/2810 (epoch 2), train_loss = 1.955, time/batch = 0.155\n",
            "755/2810 (epoch 2), train_loss = 1.853, time/batch = 0.140\n",
            "756/2810 (epoch 2), train_loss = 1.879, time/batch = 0.143\n",
            "757/2810 (epoch 2), train_loss = 1.852, time/batch = 0.163\n",
            "758/2810 (epoch 2), train_loss = 1.973, time/batch = 0.157\n",
            "759/2810 (epoch 2), train_loss = 1.805, time/batch = 0.147\n",
            "760/2810 (epoch 2), train_loss = 1.925, time/batch = 0.152\n",
            "761/2810 (epoch 2), train_loss = 1.849, time/batch = 0.148\n",
            "762/2810 (epoch 2), train_loss = 1.924, time/batch = 0.146\n",
            "763/2810 (epoch 2), train_loss = 1.887, time/batch = 0.159\n",
            "764/2810 (epoch 2), train_loss = 1.909, time/batch = 0.154\n",
            "765/2810 (epoch 2), train_loss = 1.910, time/batch = 0.154\n",
            "766/2810 (epoch 2), train_loss = 1.900, time/batch = 0.150\n",
            "767/2810 (epoch 2), train_loss = 1.932, time/batch = 0.175\n",
            "768/2810 (epoch 2), train_loss = 1.875, time/batch = 0.232\n",
            "769/2810 (epoch 2), train_loss = 1.803, time/batch = 0.282\n",
            "770/2810 (epoch 2), train_loss = 1.848, time/batch = 0.249\n",
            "771/2810 (epoch 2), train_loss = 1.862, time/batch = 0.277\n",
            "772/2810 (epoch 2), train_loss = 1.900, time/batch = 0.269\n",
            "773/2810 (epoch 2), train_loss = 1.912, time/batch = 0.280\n",
            "774/2810 (epoch 2), train_loss = 1.873, time/batch = 0.267\n",
            "775/2810 (epoch 2), train_loss = 1.947, time/batch = 0.280\n",
            "776/2810 (epoch 2), train_loss = 1.866, time/batch = 0.280\n",
            "777/2810 (epoch 2), train_loss = 1.874, time/batch = 0.300\n",
            "778/2810 (epoch 2), train_loss = 1.873, time/batch = 0.285\n",
            "779/2810 (epoch 2), train_loss = 1.928, time/batch = 0.250\n",
            "780/2810 (epoch 2), train_loss = 1.929, time/batch = 0.160\n",
            "781/2810 (epoch 2), train_loss = 1.928, time/batch = 0.153\n",
            "782/2810 (epoch 2), train_loss = 1.865, time/batch = 0.172\n",
            "783/2810 (epoch 2), train_loss = 1.842, time/batch = 0.151\n",
            "784/2810 (epoch 2), train_loss = 1.876, time/batch = 0.155\n",
            "785/2810 (epoch 2), train_loss = 1.855, time/batch = 0.145\n",
            "786/2810 (epoch 2), train_loss = 1.821, time/batch = 0.141\n",
            "787/2810 (epoch 2), train_loss = 1.877, time/batch = 0.144\n",
            "788/2810 (epoch 2), train_loss = 1.859, time/batch = 0.166\n",
            "789/2810 (epoch 2), train_loss = 1.884, time/batch = 0.150\n",
            "790/2810 (epoch 2), train_loss = 1.878, time/batch = 0.153\n",
            "791/2810 (epoch 2), train_loss = 1.928, time/batch = 0.156\n",
            "792/2810 (epoch 2), train_loss = 1.866, time/batch = 0.169\n",
            "793/2810 (epoch 2), train_loss = 1.897, time/batch = 0.152\n",
            "794/2810 (epoch 2), train_loss = 1.913, time/batch = 0.156\n",
            "795/2810 (epoch 2), train_loss = 1.868, time/batch = 0.170\n",
            "796/2810 (epoch 2), train_loss = 1.873, time/batch = 0.153\n",
            "797/2810 (epoch 2), train_loss = 1.812, time/batch = 0.150\n",
            "798/2810 (epoch 2), train_loss = 1.893, time/batch = 0.158\n",
            "799/2810 (epoch 2), train_loss = 1.908, time/batch = 0.145\n",
            "800/2810 (epoch 2), train_loss = 1.889, time/batch = 0.154\n",
            "801/2810 (epoch 2), train_loss = 1.861, time/batch = 0.150\n",
            "802/2810 (epoch 2), train_loss = 1.855, time/batch = 0.170\n",
            "803/2810 (epoch 2), train_loss = 1.963, time/batch = 0.155\n",
            "804/2810 (epoch 2), train_loss = 1.846, time/batch = 0.164\n",
            "805/2810 (epoch 2), train_loss = 1.911, time/batch = 0.147\n",
            "806/2810 (epoch 2), train_loss = 1.889, time/batch = 0.147\n",
            "807/2810 (epoch 2), train_loss = 1.915, time/batch = 0.150\n",
            "808/2810 (epoch 2), train_loss = 1.869, time/batch = 0.162\n",
            "809/2810 (epoch 2), train_loss = 1.906, time/batch = 0.148\n",
            "810/2810 (epoch 2), train_loss = 1.850, time/batch = 0.152\n",
            "811/2810 (epoch 2), train_loss = 1.882, time/batch = 0.145\n",
            "812/2810 (epoch 2), train_loss = 1.822, time/batch = 0.146\n",
            "813/2810 (epoch 2), train_loss = 1.890, time/batch = 0.147\n",
            "814/2810 (epoch 2), train_loss = 1.888, time/batch = 0.151\n",
            "815/2810 (epoch 2), train_loss = 1.870, time/batch = 0.166\n",
            "816/2810 (epoch 2), train_loss = 1.857, time/batch = 0.154\n",
            "817/2810 (epoch 2), train_loss = 1.850, time/batch = 0.158\n",
            "818/2810 (epoch 2), train_loss = 1.852, time/batch = 0.150\n",
            "819/2810 (epoch 2), train_loss = 1.830, time/batch = 0.140\n",
            "820/2810 (epoch 2), train_loss = 1.838, time/batch = 0.164\n",
            "821/2810 (epoch 2), train_loss = 1.892, time/batch = 0.145\n",
            "822/2810 (epoch 2), train_loss = 1.867, time/batch = 0.167\n",
            "823/2810 (epoch 2), train_loss = 1.857, time/batch = 0.144\n",
            "824/2810 (epoch 2), train_loss = 1.772, time/batch = 0.148\n",
            "825/2810 (epoch 2), train_loss = 1.876, time/batch = 0.136\n",
            "826/2810 (epoch 2), train_loss = 1.903, time/batch = 0.152\n",
            "827/2810 (epoch 2), train_loss = 1.885, time/batch = 0.154\n",
            "828/2810 (epoch 2), train_loss = 1.857, time/batch = 0.148\n",
            "829/2810 (epoch 2), train_loss = 1.852, time/batch = 0.173\n",
            "830/2810 (epoch 2), train_loss = 1.864, time/batch = 0.150\n",
            "831/2810 (epoch 2), train_loss = 1.873, time/batch = 0.150\n",
            "832/2810 (epoch 2), train_loss = 1.872, time/batch = 0.152\n",
            "833/2810 (epoch 2), train_loss = 1.831, time/batch = 0.167\n",
            "834/2810 (epoch 2), train_loss = 1.839, time/batch = 0.155\n",
            "835/2810 (epoch 2), train_loss = 1.884, time/batch = 0.148\n",
            "836/2810 (epoch 2), train_loss = 1.943, time/batch = 0.172\n",
            "837/2810 (epoch 2), train_loss = 1.903, time/batch = 0.146\n",
            "838/2810 (epoch 2), train_loss = 1.870, time/batch = 0.149\n",
            "839/2810 (epoch 2), train_loss = 1.883, time/batch = 0.161\n",
            "840/2810 (epoch 2), train_loss = 1.806, time/batch = 0.149\n",
            "841/2810 (epoch 2), train_loss = 1.834, time/batch = 0.153\n",
            "842/2810 (epoch 2), train_loss = 1.885, time/batch = 0.162\n",
            "843/2810 (epoch 3), train_loss = 1.919, time/batch = 0.167\n",
            "844/2810 (epoch 3), train_loss = 1.896, time/batch = 0.262\n",
            "845/2810 (epoch 3), train_loss = 1.869, time/batch = 0.279\n",
            "846/2810 (epoch 3), train_loss = 1.878, time/batch = 0.280\n",
            "847/2810 (epoch 3), train_loss = 1.798, time/batch = 0.261\n",
            "848/2810 (epoch 3), train_loss = 1.867, time/batch = 0.255\n",
            "849/2810 (epoch 3), train_loss = 1.840, time/batch = 0.263\n",
            "850/2810 (epoch 3), train_loss = 1.832, time/batch = 0.240\n",
            "851/2810 (epoch 3), train_loss = 1.905, time/batch = 0.244\n",
            "852/2810 (epoch 3), train_loss = 1.797, time/batch = 0.265\n",
            "853/2810 (epoch 3), train_loss = 1.884, time/batch = 0.257\n",
            "854/2810 (epoch 3), train_loss = 1.867, time/batch = 0.278\n",
            "855/2810 (epoch 3), train_loss = 1.822, time/batch = 0.273\n",
            "856/2810 (epoch 3), train_loss = 1.868, time/batch = 0.174\n",
            "857/2810 (epoch 3), train_loss = 1.898, time/batch = 0.143\n",
            "858/2810 (epoch 3), train_loss = 1.875, time/batch = 0.141\n",
            "859/2810 (epoch 3), train_loss = 1.816, time/batch = 0.158\n",
            "860/2810 (epoch 3), train_loss = 1.943, time/batch = 0.153\n",
            "861/2810 (epoch 3), train_loss = 1.835, time/batch = 0.158\n",
            "862/2810 (epoch 3), train_loss = 1.885, time/batch = 0.156\n",
            "863/2810 (epoch 3), train_loss = 1.867, time/batch = 0.148\n",
            "864/2810 (epoch 3), train_loss = 1.889, time/batch = 0.167\n",
            "865/2810 (epoch 3), train_loss = 1.871, time/batch = 0.156\n",
            "866/2810 (epoch 3), train_loss = 1.854, time/batch = 0.158\n",
            "867/2810 (epoch 3), train_loss = 1.846, time/batch = 0.158\n",
            "868/2810 (epoch 3), train_loss = 1.830, time/batch = 0.147\n",
            "869/2810 (epoch 3), train_loss = 1.853, time/batch = 0.153\n",
            "870/2810 (epoch 3), train_loss = 1.835, time/batch = 0.154\n",
            "871/2810 (epoch 3), train_loss = 1.809, time/batch = 0.159\n",
            "872/2810 (epoch 3), train_loss = 1.860, time/batch = 0.156\n",
            "873/2810 (epoch 3), train_loss = 1.853, time/batch = 0.175\n",
            "874/2810 (epoch 3), train_loss = 1.868, time/batch = 0.161\n",
            "875/2810 (epoch 3), train_loss = 1.800, time/batch = 0.153\n",
            "876/2810 (epoch 3), train_loss = 1.909, time/batch = 0.161\n",
            "877/2810 (epoch 3), train_loss = 1.897, time/batch = 0.151\n",
            "878/2810 (epoch 3), train_loss = 1.839, time/batch = 0.149\n",
            "879/2810 (epoch 3), train_loss = 1.865, time/batch = 0.156\n",
            "880/2810 (epoch 3), train_loss = 1.858, time/batch = 0.171\n",
            "881/2810 (epoch 3), train_loss = 1.835, time/batch = 0.148\n",
            "882/2810 (epoch 3), train_loss = 1.865, time/batch = 0.154\n",
            "883/2810 (epoch 3), train_loss = 1.833, time/batch = 0.158\n",
            "884/2810 (epoch 3), train_loss = 1.807, time/batch = 0.148\n",
            "885/2810 (epoch 3), train_loss = 1.852, time/batch = 0.146\n",
            "886/2810 (epoch 3), train_loss = 1.861, time/batch = 0.155\n",
            "887/2810 (epoch 3), train_loss = 1.872, time/batch = 0.168\n",
            "888/2810 (epoch 3), train_loss = 1.827, time/batch = 0.155\n",
            "889/2810 (epoch 3), train_loss = 1.784, time/batch = 0.139\n",
            "890/2810 (epoch 3), train_loss = 1.801, time/batch = 0.149\n",
            "891/2810 (epoch 3), train_loss = 1.816, time/batch = 0.154\n",
            "892/2810 (epoch 3), train_loss = 1.819, time/batch = 0.156\n",
            "893/2810 (epoch 3), train_loss = 1.838, time/batch = 0.139\n",
            "894/2810 (epoch 3), train_loss = 1.848, time/batch = 0.159\n",
            "895/2810 (epoch 3), train_loss = 1.834, time/batch = 0.148\n",
            "896/2810 (epoch 3), train_loss = 1.859, time/batch = 0.196\n",
            "897/2810 (epoch 3), train_loss = 1.834, time/batch = 0.151\n",
            "898/2810 (epoch 3), train_loss = 1.798, time/batch = 0.155\n",
            "899/2810 (epoch 3), train_loss = 1.828, time/batch = 0.155\n",
            "900/2810 (epoch 3), train_loss = 1.836, time/batch = 0.167\n",
            "901/2810 (epoch 3), train_loss = 1.848, time/batch = 0.152\n",
            "902/2810 (epoch 3), train_loss = 1.776, time/batch = 0.148\n",
            "903/2810 (epoch 3), train_loss = 1.812, time/batch = 0.151\n",
            "904/2810 (epoch 3), train_loss = 1.807, time/batch = 0.160\n",
            "905/2810 (epoch 3), train_loss = 1.832, time/batch = 0.155\n",
            "906/2810 (epoch 3), train_loss = 1.855, time/batch = 0.153\n",
            "907/2810 (epoch 3), train_loss = 1.872, time/batch = 0.171\n",
            "908/2810 (epoch 3), train_loss = 1.850, time/batch = 0.166\n",
            "909/2810 (epoch 3), train_loss = 1.730, time/batch = 0.171\n",
            "910/2810 (epoch 3), train_loss = 1.838, time/batch = 0.159\n",
            "911/2810 (epoch 3), train_loss = 1.881, time/batch = 0.146\n",
            "912/2810 (epoch 3), train_loss = 1.825, time/batch = 0.154\n",
            "913/2810 (epoch 3), train_loss = 1.800, time/batch = 0.171\n",
            "914/2810 (epoch 3), train_loss = 1.860, time/batch = 0.146\n",
            "915/2810 (epoch 3), train_loss = 1.848, time/batch = 0.155\n",
            "916/2810 (epoch 3), train_loss = 1.818, time/batch = 0.164\n",
            "917/2810 (epoch 3), train_loss = 1.787, time/batch = 0.154\n",
            "918/2810 (epoch 3), train_loss = 1.812, time/batch = 0.148\n",
            "919/2810 (epoch 3), train_loss = 1.776, time/batch = 0.151\n",
            "920/2810 (epoch 3), train_loss = 1.797, time/batch = 0.221\n",
            "921/2810 (epoch 3), train_loss = 1.839, time/batch = 0.271\n",
            "922/2810 (epoch 3), train_loss = 1.871, time/batch = 0.261\n",
            "923/2810 (epoch 3), train_loss = 1.786, time/batch = 0.276\n",
            "924/2810 (epoch 3), train_loss = 1.785, time/batch = 0.261\n",
            "925/2810 (epoch 3), train_loss = 1.787, time/batch = 0.278\n",
            "926/2810 (epoch 3), train_loss = 1.761, time/batch = 0.258\n",
            "927/2810 (epoch 3), train_loss = 1.724, time/batch = 0.229\n",
            "928/2810 (epoch 3), train_loss = 1.795, time/batch = 0.246\n",
            "929/2810 (epoch 3), train_loss = 1.806, time/batch = 0.270\n",
            "930/2810 (epoch 3), train_loss = 1.854, time/batch = 0.264\n",
            "931/2810 (epoch 3), train_loss = 1.796, time/batch = 0.301\n",
            "932/2810 (epoch 3), train_loss = 1.812, time/batch = 0.299\n",
            "933/2810 (epoch 3), train_loss = 1.820, time/batch = 0.196\n",
            "934/2810 (epoch 3), train_loss = 1.817, time/batch = 0.165\n",
            "935/2810 (epoch 3), train_loss = 1.822, time/batch = 0.153\n",
            "936/2810 (epoch 3), train_loss = 1.900, time/batch = 0.153\n",
            "937/2810 (epoch 3), train_loss = 1.832, time/batch = 0.157\n",
            "938/2810 (epoch 3), train_loss = 1.865, time/batch = 0.177\n",
            "939/2810 (epoch 3), train_loss = 1.831, time/batch = 0.157\n",
            "940/2810 (epoch 3), train_loss = 1.738, time/batch = 0.162\n",
            "941/2810 (epoch 3), train_loss = 1.742, time/batch = 0.149\n",
            "942/2810 (epoch 3), train_loss = 1.782, time/batch = 0.149\n",
            "943/2810 (epoch 3), train_loss = 1.780, time/batch = 0.169\n",
            "944/2810 (epoch 3), train_loss = 1.827, time/batch = 0.174\n",
            "945/2810 (epoch 3), train_loss = 1.878, time/batch = 0.149\n",
            "946/2810 (epoch 3), train_loss = 1.826, time/batch = 0.159\n",
            "947/2810 (epoch 3), train_loss = 1.744, time/batch = 0.152\n",
            "948/2810 (epoch 3), train_loss = 1.730, time/batch = 0.157\n",
            "949/2810 (epoch 3), train_loss = 1.797, time/batch = 0.161\n",
            "950/2810 (epoch 3), train_loss = 1.855, time/batch = 0.154\n",
            "951/2810 (epoch 3), train_loss = 1.837, time/batch = 0.180\n",
            "952/2810 (epoch 3), train_loss = 1.794, time/batch = 0.163\n",
            "953/2810 (epoch 3), train_loss = 1.821, time/batch = 0.164\n",
            "954/2810 (epoch 3), train_loss = 1.712, time/batch = 0.155\n",
            "955/2810 (epoch 3), train_loss = 1.767, time/batch = 0.158\n",
            "956/2810 (epoch 3), train_loss = 1.811, time/batch = 0.150\n",
            "957/2810 (epoch 3), train_loss = 1.841, time/batch = 0.172\n",
            "958/2810 (epoch 3), train_loss = 1.812, time/batch = 0.159\n",
            "959/2810 (epoch 3), train_loss = 1.798, time/batch = 0.158\n",
            "960/2810 (epoch 3), train_loss = 1.790, time/batch = 0.146\n",
            "961/2810 (epoch 3), train_loss = 1.774, time/batch = 0.165\n",
            "962/2810 (epoch 3), train_loss = 1.836, time/batch = 0.158\n",
            "963/2810 (epoch 3), train_loss = 1.779, time/batch = 0.152\n",
            "964/2810 (epoch 3), train_loss = 1.774, time/batch = 0.168\n",
            "965/2810 (epoch 3), train_loss = 1.801, time/batch = 0.158\n",
            "966/2810 (epoch 3), train_loss = 1.811, time/batch = 0.142\n",
            "967/2810 (epoch 3), train_loss = 1.779, time/batch = 0.143\n",
            "968/2810 (epoch 3), train_loss = 1.747, time/batch = 0.171\n",
            "969/2810 (epoch 3), train_loss = 1.770, time/batch = 0.149\n",
            "970/2810 (epoch 3), train_loss = 1.785, time/batch = 0.170\n",
            "971/2810 (epoch 3), train_loss = 1.854, time/batch = 0.136\n",
            "972/2810 (epoch 3), train_loss = 1.788, time/batch = 0.152\n",
            "973/2810 (epoch 3), train_loss = 1.798, time/batch = 0.152\n",
            "974/2810 (epoch 3), train_loss = 1.779, time/batch = 0.151\n",
            "975/2810 (epoch 3), train_loss = 1.811, time/batch = 0.163\n",
            "976/2810 (epoch 3), train_loss = 1.821, time/batch = 0.160\n",
            "977/2810 (epoch 3), train_loss = 1.787, time/batch = 0.168\n",
            "978/2810 (epoch 3), train_loss = 1.811, time/batch = 0.149\n",
            "979/2810 (epoch 3), train_loss = 1.879, time/batch = 0.148\n",
            "980/2810 (epoch 3), train_loss = 1.839, time/batch = 0.145\n",
            "981/2810 (epoch 3), train_loss = 1.808, time/batch = 0.160\n",
            "982/2810 (epoch 3), train_loss = 1.831, time/batch = 0.155\n",
            "983/2810 (epoch 3), train_loss = 1.842, time/batch = 0.162\n",
            "984/2810 (epoch 3), train_loss = 1.799, time/batch = 0.169\n",
            "985/2810 (epoch 3), train_loss = 1.895, time/batch = 0.144\n",
            "986/2810 (epoch 3), train_loss = 1.879, time/batch = 0.146\n",
            "987/2810 (epoch 3), train_loss = 1.783, time/batch = 0.159\n",
            "988/2810 (epoch 3), train_loss = 1.760, time/batch = 0.148\n",
            "989/2810 (epoch 3), train_loss = 1.826, time/batch = 0.148\n",
            "990/2810 (epoch 3), train_loss = 1.840, time/batch = 0.160\n",
            "991/2810 (epoch 3), train_loss = 1.843, time/batch = 0.156\n",
            "992/2810 (epoch 3), train_loss = 1.825, time/batch = 0.157\n",
            "993/2810 (epoch 3), train_loss = 1.856, time/batch = 0.153\n",
            "994/2810 (epoch 3), train_loss = 1.785, time/batch = 0.150\n",
            "995/2810 (epoch 3), train_loss = 1.833, time/batch = 0.139\n",
            "996/2810 (epoch 3), train_loss = 1.859, time/batch = 0.157\n",
            "997/2810 (epoch 3), train_loss = 1.786, time/batch = 0.266\n",
            "998/2810 (epoch 3), train_loss = 1.796, time/batch = 0.255\n",
            "999/2810 (epoch 3), train_loss = 1.841, time/batch = 0.261\n",
            "1000/2810 (epoch 3), train_loss = 1.758, time/batch = 0.278\n",
            "Model saved to ./checkpoints/pg74571/pg74571!\n",
            "1001/2810 (epoch 3), train_loss = 1.788, time/batch = 0.289\n",
            "1002/2810 (epoch 3), train_loss = 1.819, time/batch = 0.244\n",
            "1003/2810 (epoch 3), train_loss = 1.812, time/batch = 0.278\n",
            "1004/2810 (epoch 3), train_loss = 1.867, time/batch = 0.255\n",
            "1005/2810 (epoch 3), train_loss = 1.844, time/batch = 0.278\n",
            "1006/2810 (epoch 3), train_loss = 1.809, time/batch = 0.268\n",
            "1007/2810 (epoch 3), train_loss = 1.817, time/batch = 0.213\n",
            "1008/2810 (epoch 3), train_loss = 1.735, time/batch = 0.167\n",
            "1009/2810 (epoch 3), train_loss = 1.802, time/batch = 0.149\n",
            "1010/2810 (epoch 3), train_loss = 1.799, time/batch = 0.146\n",
            "1011/2810 (epoch 3), train_loss = 1.746, time/batch = 0.166\n",
            "1012/2810 (epoch 3), train_loss = 1.784, time/batch = 0.142\n",
            "1013/2810 (epoch 3), train_loss = 1.820, time/batch = 0.142\n",
            "1014/2810 (epoch 3), train_loss = 1.748, time/batch = 0.171\n",
            "1015/2810 (epoch 3), train_loss = 1.719, time/batch = 0.146\n",
            "1016/2810 (epoch 3), train_loss = 1.869, time/batch = 0.159\n",
            "1017/2810 (epoch 3), train_loss = 1.810, time/batch = 0.160\n",
            "1018/2810 (epoch 3), train_loss = 1.796, time/batch = 0.157\n",
            "1019/2810 (epoch 3), train_loss = 1.751, time/batch = 0.149\n",
            "1020/2810 (epoch 3), train_loss = 1.764, time/batch = 0.153\n",
            "1021/2810 (epoch 3), train_loss = 1.821, time/batch = 0.168\n",
            "1022/2810 (epoch 3), train_loss = 1.812, time/batch = 0.146\n",
            "1023/2810 (epoch 3), train_loss = 1.700, time/batch = 0.152\n",
            "1024/2810 (epoch 3), train_loss = 1.786, time/batch = 0.141\n",
            "1025/2810 (epoch 3), train_loss = 1.809, time/batch = 0.155\n",
            "1026/2810 (epoch 3), train_loss = 1.797, time/batch = 0.151\n",
            "1027/2810 (epoch 3), train_loss = 1.820, time/batch = 0.154\n",
            "1028/2810 (epoch 3), train_loss = 1.725, time/batch = 0.161\n",
            "1029/2810 (epoch 3), train_loss = 1.758, time/batch = 0.159\n",
            "1030/2810 (epoch 3), train_loss = 1.771, time/batch = 0.159\n",
            "1031/2810 (epoch 3), train_loss = 1.852, time/batch = 0.157\n",
            "1032/2810 (epoch 3), train_loss = 1.764, time/batch = 0.155\n",
            "1033/2810 (epoch 3), train_loss = 1.815, time/batch = 0.163\n",
            "1034/2810 (epoch 3), train_loss = 1.812, time/batch = 0.161\n",
            "1035/2810 (epoch 3), train_loss = 1.849, time/batch = 0.163\n",
            "1036/2810 (epoch 3), train_loss = 1.751, time/batch = 0.153\n",
            "1037/2810 (epoch 3), train_loss = 1.779, time/batch = 0.156\n",
            "1038/2810 (epoch 3), train_loss = 1.735, time/batch = 0.152\n",
            "1039/2810 (epoch 3), train_loss = 1.865, time/batch = 0.152\n",
            "1040/2810 (epoch 3), train_loss = 1.694, time/batch = 0.155\n",
            "1041/2810 (epoch 3), train_loss = 1.819, time/batch = 0.160\n",
            "1042/2810 (epoch 3), train_loss = 1.738, time/batch = 0.156\n",
            "1043/2810 (epoch 3), train_loss = 1.812, time/batch = 0.145\n",
            "1044/2810 (epoch 3), train_loss = 1.772, time/batch = 0.144\n",
            "1045/2810 (epoch 3), train_loss = 1.790, time/batch = 0.150\n",
            "1046/2810 (epoch 3), train_loss = 1.811, time/batch = 0.162\n",
            "1047/2810 (epoch 3), train_loss = 1.792, time/batch = 0.157\n",
            "1048/2810 (epoch 3), train_loss = 1.811, time/batch = 0.160\n",
            "1049/2810 (epoch 3), train_loss = 1.773, time/batch = 0.163\n",
            "1050/2810 (epoch 3), train_loss = 1.686, time/batch = 0.147\n",
            "1051/2810 (epoch 3), train_loss = 1.746, time/batch = 0.157\n",
            "1052/2810 (epoch 3), train_loss = 1.750, time/batch = 0.149\n",
            "1053/2810 (epoch 3), train_loss = 1.800, time/batch = 0.152\n",
            "1054/2810 (epoch 3), train_loss = 1.799, time/batch = 0.174\n",
            "1055/2810 (epoch 3), train_loss = 1.765, time/batch = 0.157\n",
            "1056/2810 (epoch 3), train_loss = 1.828, time/batch = 0.158\n",
            "1057/2810 (epoch 3), train_loss = 1.762, time/batch = 0.166\n",
            "1058/2810 (epoch 3), train_loss = 1.774, time/batch = 0.148\n",
            "1059/2810 (epoch 3), train_loss = 1.763, time/batch = 0.150\n",
            "1060/2810 (epoch 3), train_loss = 1.823, time/batch = 0.160\n",
            "1061/2810 (epoch 3), train_loss = 1.813, time/batch = 0.174\n",
            "1062/2810 (epoch 3), train_loss = 1.820, time/batch = 0.148\n",
            "1063/2810 (epoch 3), train_loss = 1.751, time/batch = 0.168\n",
            "1064/2810 (epoch 3), train_loss = 1.734, time/batch = 0.139\n",
            "1065/2810 (epoch 3), train_loss = 1.766, time/batch = 0.154\n",
            "1066/2810 (epoch 3), train_loss = 1.755, time/batch = 0.140\n",
            "1067/2810 (epoch 3), train_loss = 1.716, time/batch = 0.165\n",
            "1068/2810 (epoch 3), train_loss = 1.777, time/batch = 0.167\n",
            "1069/2810 (epoch 3), train_loss = 1.757, time/batch = 0.156\n",
            "1070/2810 (epoch 3), train_loss = 1.776, time/batch = 0.194\n",
            "1071/2810 (epoch 3), train_loss = 1.771, time/batch = 0.192\n",
            "1072/2810 (epoch 3), train_loss = 1.820, time/batch = 0.254\n",
            "1073/2810 (epoch 3), train_loss = 1.762, time/batch = 0.253\n",
            "1074/2810 (epoch 3), train_loss = 1.781, time/batch = 0.271\n",
            "1075/2810 (epoch 3), train_loss = 1.811, time/batch = 0.271\n",
            "1076/2810 (epoch 3), train_loss = 1.757, time/batch = 0.269\n",
            "1077/2810 (epoch 3), train_loss = 1.786, time/batch = 0.280\n",
            "1078/2810 (epoch 3), train_loss = 1.707, time/batch = 0.276\n",
            "1079/2810 (epoch 3), train_loss = 1.785, time/batch = 0.276\n",
            "1080/2810 (epoch 3), train_loss = 1.809, time/batch = 0.264\n",
            "1081/2810 (epoch 3), train_loss = 1.781, time/batch = 0.271\n",
            "1082/2810 (epoch 3), train_loss = 1.762, time/batch = 0.286\n",
            "1083/2810 (epoch 3), train_loss = 1.758, time/batch = 0.244\n",
            "1084/2810 (epoch 3), train_loss = 1.867, time/batch = 0.155\n",
            "1085/2810 (epoch 3), train_loss = 1.743, time/batch = 0.172\n",
            "1086/2810 (epoch 3), train_loss = 1.812, time/batch = 0.147\n",
            "1087/2810 (epoch 3), train_loss = 1.790, time/batch = 0.154\n",
            "1088/2810 (epoch 3), train_loss = 1.808, time/batch = 0.154\n",
            "1089/2810 (epoch 3), train_loss = 1.759, time/batch = 0.148\n",
            "1090/2810 (epoch 3), train_loss = 1.800, time/batch = 0.154\n",
            "1091/2810 (epoch 3), train_loss = 1.742, time/batch = 0.157\n",
            "1092/2810 (epoch 3), train_loss = 1.781, time/batch = 0.164\n",
            "1093/2810 (epoch 3), train_loss = 1.721, time/batch = 0.153\n",
            "1094/2810 (epoch 3), train_loss = 1.795, time/batch = 0.151\n",
            "1095/2810 (epoch 3), train_loss = 1.797, time/batch = 0.142\n",
            "1096/2810 (epoch 3), train_loss = 1.762, time/batch = 0.141\n",
            "1097/2810 (epoch 3), train_loss = 1.752, time/batch = 0.159\n",
            "1098/2810 (epoch 3), train_loss = 1.750, time/batch = 0.144\n",
            "1099/2810 (epoch 3), train_loss = 1.747, time/batch = 0.175\n",
            "1100/2810 (epoch 3), train_loss = 1.730, time/batch = 0.148\n",
            "1101/2810 (epoch 3), train_loss = 1.743, time/batch = 0.158\n",
            "1102/2810 (epoch 3), train_loss = 1.793, time/batch = 0.146\n",
            "1103/2810 (epoch 3), train_loss = 1.762, time/batch = 0.164\n",
            "1104/2810 (epoch 3), train_loss = 1.759, time/batch = 0.145\n",
            "1105/2810 (epoch 3), train_loss = 1.668, time/batch = 0.147\n",
            "1106/2810 (epoch 3), train_loss = 1.778, time/batch = 0.177\n",
            "1107/2810 (epoch 3), train_loss = 1.803, time/batch = 0.158\n",
            "1108/2810 (epoch 3), train_loss = 1.791, time/batch = 0.146\n",
            "1109/2810 (epoch 3), train_loss = 1.757, time/batch = 0.154\n",
            "1110/2810 (epoch 3), train_loss = 1.771, time/batch = 0.166\n",
            "1111/2810 (epoch 3), train_loss = 1.768, time/batch = 0.155\n",
            "1112/2810 (epoch 3), train_loss = 1.777, time/batch = 0.172\n",
            "1113/2810 (epoch 3), train_loss = 1.775, time/batch = 0.152\n",
            "1114/2810 (epoch 3), train_loss = 1.741, time/batch = 0.156\n",
            "1115/2810 (epoch 3), train_loss = 1.734, time/batch = 0.149\n",
            "1116/2810 (epoch 3), train_loss = 1.784, time/batch = 0.159\n",
            "1117/2810 (epoch 3), train_loss = 1.844, time/batch = 0.137\n",
            "1118/2810 (epoch 3), train_loss = 1.805, time/batch = 0.150\n",
            "1119/2810 (epoch 3), train_loss = 1.773, time/batch = 0.173\n",
            "1120/2810 (epoch 3), train_loss = 1.782, time/batch = 0.150\n",
            "1121/2810 (epoch 3), train_loss = 1.711, time/batch = 0.148\n",
            "1122/2810 (epoch 3), train_loss = 1.744, time/batch = 0.153\n",
            "1123/2810 (epoch 3), train_loss = 1.781, time/batch = 0.158\n",
            "1124/2810 (epoch 4), train_loss = 1.803, time/batch = 0.146\n",
            "1125/2810 (epoch 4), train_loss = 1.794, time/batch = 0.158\n",
            "1126/2810 (epoch 4), train_loss = 1.776, time/batch = 0.149\n",
            "1127/2810 (epoch 4), train_loss = 1.779, time/batch = 0.147\n",
            "1128/2810 (epoch 4), train_loss = 1.697, time/batch = 0.151\n",
            "1129/2810 (epoch 4), train_loss = 1.780, time/batch = 0.149\n",
            "1130/2810 (epoch 4), train_loss = 1.738, time/batch = 0.154\n",
            "1131/2810 (epoch 4), train_loss = 1.737, time/batch = 0.154\n",
            "1132/2810 (epoch 4), train_loss = 1.811, time/batch = 0.183\n",
            "1133/2810 (epoch 4), train_loss = 1.708, time/batch = 0.159\n",
            "1134/2810 (epoch 4), train_loss = 1.786, time/batch = 0.157\n",
            "1135/2810 (epoch 4), train_loss = 1.768, time/batch = 0.151\n",
            "1136/2810 (epoch 4), train_loss = 1.731, time/batch = 0.166\n",
            "1137/2810 (epoch 4), train_loss = 1.776, time/batch = 0.157\n",
            "1138/2810 (epoch 4), train_loss = 1.802, time/batch = 0.159\n",
            "1139/2810 (epoch 4), train_loss = 1.783, time/batch = 0.148\n",
            "1140/2810 (epoch 4), train_loss = 1.734, time/batch = 0.155\n",
            "1141/2810 (epoch 4), train_loss = 1.868, time/batch = 0.157\n",
            "1142/2810 (epoch 4), train_loss = 1.756, time/batch = 0.152\n",
            "1143/2810 (epoch 4), train_loss = 1.799, time/batch = 0.152\n",
            "1144/2810 (epoch 4), train_loss = 1.781, time/batch = 0.148\n",
            "1145/2810 (epoch 4), train_loss = 1.808, time/batch = 0.178\n",
            "1146/2810 (epoch 4), train_loss = 1.777, time/batch = 0.153\n",
            "1147/2810 (epoch 4), train_loss = 1.763, time/batch = 0.207\n",
            "1148/2810 (epoch 4), train_loss = 1.764, time/batch = 0.283\n",
            "1149/2810 (epoch 4), train_loss = 1.728, time/batch = 0.288\n",
            "1150/2810 (epoch 4), train_loss = 1.757, time/batch = 0.285\n",
            "1151/2810 (epoch 4), train_loss = 1.741, time/batch = 0.260\n",
            "1152/2810 (epoch 4), train_loss = 1.700, time/batch = 0.270\n",
            "1153/2810 (epoch 4), train_loss = 1.759, time/batch = 0.259\n",
            "1154/2810 (epoch 4), train_loss = 1.765, time/batch = 0.279\n",
            "1155/2810 (epoch 4), train_loss = 1.781, time/batch = 0.250\n",
            "1156/2810 (epoch 4), train_loss = 1.711, time/batch = 0.282\n",
            "1157/2810 (epoch 4), train_loss = 1.813, time/batch = 0.285\n",
            "1158/2810 (epoch 4), train_loss = 1.808, time/batch = 0.293\n",
            "1159/2810 (epoch 4), train_loss = 1.743, time/batch = 0.158\n",
            "1160/2810 (epoch 4), train_loss = 1.771, time/batch = 0.145\n",
            "1161/2810 (epoch 4), train_loss = 1.768, time/batch = 0.138\n",
            "1162/2810 (epoch 4), train_loss = 1.747, time/batch = 0.150\n",
            "1163/2810 (epoch 4), train_loss = 1.773, time/batch = 0.159\n",
            "1164/2810 (epoch 4), train_loss = 1.754, time/batch = 0.173\n",
            "1165/2810 (epoch 4), train_loss = 1.707, time/batch = 0.154\n",
            "1166/2810 (epoch 4), train_loss = 1.760, time/batch = 0.155\n",
            "1167/2810 (epoch 4), train_loss = 1.780, time/batch = 0.147\n",
            "1168/2810 (epoch 4), train_loss = 1.792, time/batch = 0.151\n",
            "1169/2810 (epoch 4), train_loss = 1.742, time/batch = 0.159\n",
            "1170/2810 (epoch 4), train_loss = 1.693, time/batch = 0.177\n",
            "1171/2810 (epoch 4), train_loss = 1.710, time/batch = 0.152\n",
            "1172/2810 (epoch 4), train_loss = 1.722, time/batch = 0.155\n",
            "1173/2810 (epoch 4), train_loss = 1.728, time/batch = 0.152\n",
            "1174/2810 (epoch 4), train_loss = 1.751, time/batch = 0.156\n",
            "1175/2810 (epoch 4), train_loss = 1.756, time/batch = 0.159\n",
            "1176/2810 (epoch 4), train_loss = 1.732, time/batch = 0.147\n",
            "1177/2810 (epoch 4), train_loss = 1.770, time/batch = 0.164\n",
            "1178/2810 (epoch 4), train_loss = 1.738, time/batch = 0.168\n",
            "1179/2810 (epoch 4), train_loss = 1.705, time/batch = 0.161\n",
            "1180/2810 (epoch 4), train_loss = 1.733, time/batch = 0.159\n",
            "1181/2810 (epoch 4), train_loss = 1.748, time/batch = 0.151\n",
            "1182/2810 (epoch 4), train_loss = 1.760, time/batch = 0.165\n",
            "1183/2810 (epoch 4), train_loss = 1.676, time/batch = 0.176\n",
            "1184/2810 (epoch 4), train_loss = 1.720, time/batch = 0.152\n",
            "1185/2810 (epoch 4), train_loss = 1.725, time/batch = 0.154\n",
            "1186/2810 (epoch 4), train_loss = 1.737, time/batch = 0.150\n",
            "1187/2810 (epoch 4), train_loss = 1.758, time/batch = 0.141\n",
            "1188/2810 (epoch 4), train_loss = 1.778, time/batch = 0.159\n",
            "1189/2810 (epoch 4), train_loss = 1.752, time/batch = 0.140\n",
            "1190/2810 (epoch 4), train_loss = 1.644, time/batch = 0.171\n",
            "1191/2810 (epoch 4), train_loss = 1.746, time/batch = 0.151\n",
            "1192/2810 (epoch 4), train_loss = 1.796, time/batch = 0.158\n",
            "1193/2810 (epoch 4), train_loss = 1.742, time/batch = 0.161\n",
            "1194/2810 (epoch 4), train_loss = 1.713, time/batch = 0.155\n",
            "1195/2810 (epoch 4), train_loss = 1.767, time/batch = 0.160\n",
            "1196/2810 (epoch 4), train_loss = 1.767, time/batch = 0.162\n",
            "1197/2810 (epoch 4), train_loss = 1.738, time/batch = 0.156\n",
            "1198/2810 (epoch 4), train_loss = 1.697, time/batch = 0.166\n",
            "1199/2810 (epoch 4), train_loss = 1.719, time/batch = 0.158\n",
            "1200/2810 (epoch 4), train_loss = 1.690, time/batch = 0.157\n",
            "1201/2810 (epoch 4), train_loss = 1.706, time/batch = 0.156\n",
            "1202/2810 (epoch 4), train_loss = 1.747, time/batch = 0.152\n",
            "1203/2810 (epoch 4), train_loss = 1.782, time/batch = 0.175\n",
            "1204/2810 (epoch 4), train_loss = 1.696, time/batch = 0.164\n",
            "1205/2810 (epoch 4), train_loss = 1.703, time/batch = 0.155\n",
            "1206/2810 (epoch 4), train_loss = 1.697, time/batch = 0.147\n",
            "1207/2810 (epoch 4), train_loss = 1.676, time/batch = 0.152\n",
            "1208/2810 (epoch 4), train_loss = 1.637, time/batch = 0.159\n",
            "1209/2810 (epoch 4), train_loss = 1.703, time/batch = 0.157\n",
            "1210/2810 (epoch 4), train_loss = 1.721, time/batch = 0.167\n",
            "1211/2810 (epoch 4), train_loss = 1.765, time/batch = 0.154\n",
            "1212/2810 (epoch 4), train_loss = 1.710, time/batch = 0.158\n",
            "1213/2810 (epoch 4), train_loss = 1.722, time/batch = 0.149\n",
            "1214/2810 (epoch 4), train_loss = 1.728, time/batch = 0.157\n",
            "1215/2810 (epoch 4), train_loss = 1.739, time/batch = 0.162\n",
            "1216/2810 (epoch 4), train_loss = 1.737, time/batch = 0.161\n",
            "1217/2810 (epoch 4), train_loss = 1.820, time/batch = 0.158\n",
            "1218/2810 (epoch 4), train_loss = 1.740, time/batch = 0.157\n",
            "1219/2810 (epoch 4), train_loss = 1.768, time/batch = 0.145\n",
            "1220/2810 (epoch 4), train_loss = 1.752, time/batch = 0.155\n",
            "1221/2810 (epoch 4), train_loss = 1.650, time/batch = 0.153\n",
            "1222/2810 (epoch 4), train_loss = 1.651, time/batch = 0.147\n",
            "1223/2810 (epoch 4), train_loss = 1.687, time/batch = 0.248\n",
            "1224/2810 (epoch 4), train_loss = 1.695, time/batch = 0.266\n",
            "1225/2810 (epoch 4), train_loss = 1.741, time/batch = 0.273\n",
            "1226/2810 (epoch 4), train_loss = 1.793, time/batch = 0.271\n",
            "1227/2810 (epoch 4), train_loss = 1.731, time/batch = 0.285\n",
            "1228/2810 (epoch 4), train_loss = 1.661, time/batch = 0.278\n",
            "1229/2810 (epoch 4), train_loss = 1.649, time/batch = 0.256\n",
            "1230/2810 (epoch 4), train_loss = 1.706, time/batch = 0.255\n",
            "1231/2810 (epoch 4), train_loss = 1.768, time/batch = 0.245\n",
            "1232/2810 (epoch 4), train_loss = 1.754, time/batch = 0.245\n",
            "1233/2810 (epoch 4), train_loss = 1.702, time/batch = 0.294\n",
            "1234/2810 (epoch 4), train_loss = 1.740, time/batch = 0.265\n",
            "1235/2810 (epoch 4), train_loss = 1.632, time/batch = 0.196\n",
            "1236/2810 (epoch 4), train_loss = 1.685, time/batch = 0.148\n",
            "1237/2810 (epoch 4), train_loss = 1.736, time/batch = 0.207\n",
            "1238/2810 (epoch 4), train_loss = 1.752, time/batch = 0.159\n",
            "1239/2810 (epoch 4), train_loss = 1.735, time/batch = 0.153\n",
            "1240/2810 (epoch 4), train_loss = 1.717, time/batch = 0.151\n",
            "1241/2810 (epoch 4), train_loss = 1.695, time/batch = 0.153\n",
            "1242/2810 (epoch 4), train_loss = 1.695, time/batch = 0.145\n",
            "1243/2810 (epoch 4), train_loss = 1.760, time/batch = 0.151\n",
            "1244/2810 (epoch 4), train_loss = 1.707, time/batch = 0.154\n",
            "1245/2810 (epoch 4), train_loss = 1.696, time/batch = 0.158\n",
            "1246/2810 (epoch 4), train_loss = 1.717, time/batch = 0.154\n",
            "1247/2810 (epoch 4), train_loss = 1.731, time/batch = 0.153\n",
            "1248/2810 (epoch 4), train_loss = 1.695, time/batch = 0.166\n",
            "1249/2810 (epoch 4), train_loss = 1.660, time/batch = 0.153\n",
            "1250/2810 (epoch 4), train_loss = 1.685, time/batch = 0.156\n",
            "1251/2810 (epoch 4), train_loss = 1.708, time/batch = 0.151\n",
            "1252/2810 (epoch 4), train_loss = 1.771, time/batch = 0.156\n",
            "1253/2810 (epoch 4), train_loss = 1.705, time/batch = 0.153\n",
            "1254/2810 (epoch 4), train_loss = 1.712, time/batch = 0.146\n",
            "1255/2810 (epoch 4), train_loss = 1.695, time/batch = 0.164\n",
            "1256/2810 (epoch 4), train_loss = 1.728, time/batch = 0.143\n",
            "1257/2810 (epoch 4), train_loss = 1.739, time/batch = 0.150\n",
            "1258/2810 (epoch 4), train_loss = 1.704, time/batch = 0.154\n",
            "1259/2810 (epoch 4), train_loss = 1.724, time/batch = 0.152\n",
            "1260/2810 (epoch 4), train_loss = 1.803, time/batch = 0.154\n",
            "1261/2810 (epoch 4), train_loss = 1.762, time/batch = 0.163\n",
            "1262/2810 (epoch 4), train_loss = 1.733, time/batch = 0.155\n",
            "1263/2810 (epoch 4), train_loss = 1.758, time/batch = 0.154\n",
            "1264/2810 (epoch 4), train_loss = 1.764, time/batch = 0.167\n",
            "1265/2810 (epoch 4), train_loss = 1.726, time/batch = 0.154\n",
            "1266/2810 (epoch 4), train_loss = 1.819, time/batch = 0.172\n",
            "1267/2810 (epoch 4), train_loss = 1.799, time/batch = 0.168\n",
            "1268/2810 (epoch 4), train_loss = 1.698, time/batch = 0.184\n",
            "1269/2810 (epoch 4), train_loss = 1.679, time/batch = 0.154\n",
            "1270/2810 (epoch 4), train_loss = 1.747, time/batch = 0.160\n",
            "1271/2810 (epoch 4), train_loss = 1.758, time/batch = 0.154\n",
            "1272/2810 (epoch 4), train_loss = 1.767, time/batch = 0.153\n",
            "1273/2810 (epoch 4), train_loss = 1.742, time/batch = 0.154\n",
            "1274/2810 (epoch 4), train_loss = 1.769, time/batch = 0.169\n",
            "1275/2810 (epoch 4), train_loss = 1.704, time/batch = 0.139\n",
            "1276/2810 (epoch 4), train_loss = 1.752, time/batch = 0.152\n",
            "1277/2810 (epoch 4), train_loss = 1.777, time/batch = 0.146\n",
            "1278/2810 (epoch 4), train_loss = 1.698, time/batch = 0.150\n",
            "1279/2810 (epoch 4), train_loss = 1.723, time/batch = 0.146\n",
            "1280/2810 (epoch 4), train_loss = 1.767, time/batch = 0.165\n",
            "1281/2810 (epoch 4), train_loss = 1.674, time/batch = 0.165\n",
            "1282/2810 (epoch 4), train_loss = 1.708, time/batch = 0.152\n",
            "1283/2810 (epoch 4), train_loss = 1.733, time/batch = 0.161\n",
            "1284/2810 (epoch 4), train_loss = 1.740, time/batch = 0.143\n",
            "1285/2810 (epoch 4), train_loss = 1.795, time/batch = 0.143\n",
            "1286/2810 (epoch 4), train_loss = 1.756, time/batch = 0.156\n",
            "1287/2810 (epoch 4), train_loss = 1.726, time/batch = 0.149\n",
            "1288/2810 (epoch 4), train_loss = 1.742, time/batch = 0.173\n",
            "1289/2810 (epoch 4), train_loss = 1.662, time/batch = 0.165\n",
            "1290/2810 (epoch 4), train_loss = 1.729, time/batch = 0.153\n",
            "1291/2810 (epoch 4), train_loss = 1.726, time/batch = 0.146\n",
            "1292/2810 (epoch 4), train_loss = 1.671, time/batch = 0.173\n",
            "1293/2810 (epoch 4), train_loss = 1.705, time/batch = 0.157\n",
            "1294/2810 (epoch 4), train_loss = 1.744, time/batch = 0.168\n",
            "1295/2810 (epoch 4), train_loss = 1.675, time/batch = 0.152\n",
            "1296/2810 (epoch 4), train_loss = 1.636, time/batch = 0.158\n",
            "1297/2810 (epoch 4), train_loss = 1.796, time/batch = 0.153\n",
            "1298/2810 (epoch 4), train_loss = 1.730, time/batch = 0.158\n",
            "1299/2810 (epoch 4), train_loss = 1.711, time/batch = 0.261\n",
            "1300/2810 (epoch 4), train_loss = 1.679, time/batch = 0.276\n",
            "1301/2810 (epoch 4), train_loss = 1.690, time/batch = 0.266\n",
            "1302/2810 (epoch 4), train_loss = 1.742, time/batch = 0.262\n",
            "1303/2810 (epoch 4), train_loss = 1.735, time/batch = 0.253\n",
            "1304/2810 (epoch 4), train_loss = 1.627, time/batch = 0.275\n",
            "1305/2810 (epoch 4), train_loss = 1.708, time/batch = 0.242\n",
            "1306/2810 (epoch 4), train_loss = 1.728, time/batch = 0.251\n",
            "1307/2810 (epoch 4), train_loss = 1.715, time/batch = 0.245\n",
            "1308/2810 (epoch 4), train_loss = 1.745, time/batch = 0.250\n",
            "1309/2810 (epoch 4), train_loss = 1.654, time/batch = 0.239\n",
            "1310/2810 (epoch 4), train_loss = 1.690, time/batch = 0.244\n",
            "1311/2810 (epoch 4), train_loss = 1.686, time/batch = 0.262\n",
            "1312/2810 (epoch 4), train_loss = 1.771, time/batch = 0.141\n",
            "1313/2810 (epoch 4), train_loss = 1.688, time/batch = 0.155\n",
            "1314/2810 (epoch 4), train_loss = 1.739, time/batch = 0.157\n",
            "1315/2810 (epoch 4), train_loss = 1.743, time/batch = 0.153\n",
            "1316/2810 (epoch 4), train_loss = 1.776, time/batch = 0.152\n",
            "1317/2810 (epoch 4), train_loss = 1.677, time/batch = 0.163\n",
            "1318/2810 (epoch 4), train_loss = 1.708, time/batch = 0.152\n",
            "1319/2810 (epoch 4), train_loss = 1.654, time/batch = 0.152\n",
            "1320/2810 (epoch 4), train_loss = 1.783, time/batch = 0.165\n",
            "1321/2810 (epoch 4), train_loss = 1.618, time/batch = 0.145\n",
            "1322/2810 (epoch 4), train_loss = 1.747, time/batch = 0.142\n",
            "1323/2810 (epoch 4), train_loss = 1.660, time/batch = 0.150\n",
            "1324/2810 (epoch 4), train_loss = 1.738, time/batch = 0.136\n",
            "1325/2810 (epoch 4), train_loss = 1.693, time/batch = 0.156\n",
            "1326/2810 (epoch 4), train_loss = 1.710, time/batch = 0.142\n",
            "1327/2810 (epoch 4), train_loss = 1.741, time/batch = 0.174\n",
            "1328/2810 (epoch 4), train_loss = 1.714, time/batch = 0.154\n",
            "1329/2810 (epoch 4), train_loss = 1.723, time/batch = 0.138\n",
            "1330/2810 (epoch 4), train_loss = 1.699, time/batch = 0.137\n",
            "1331/2810 (epoch 4), train_loss = 1.606, time/batch = 0.138\n",
            "1332/2810 (epoch 4), train_loss = 1.675, time/batch = 0.142\n",
            "1333/2810 (epoch 4), train_loss = 1.670, time/batch = 0.172\n",
            "1334/2810 (epoch 4), train_loss = 1.734, time/batch = 0.161\n",
            "1335/2810 (epoch 4), train_loss = 1.730, time/batch = 0.138\n",
            "1336/2810 (epoch 4), train_loss = 1.688, time/batch = 0.150\n",
            "1337/2810 (epoch 4), train_loss = 1.745, time/batch = 0.153\n",
            "1338/2810 (epoch 4), train_loss = 1.698, time/batch = 0.142\n",
            "1339/2810 (epoch 4), train_loss = 1.701, time/batch = 0.151\n",
            "1340/2810 (epoch 4), train_loss = 1.679, time/batch = 0.153\n",
            "1341/2810 (epoch 4), train_loss = 1.750, time/batch = 0.175\n",
            "1342/2810 (epoch 4), train_loss = 1.734, time/batch = 0.150\n",
            "1343/2810 (epoch 4), train_loss = 1.743, time/batch = 0.149\n",
            "1344/2810 (epoch 4), train_loss = 1.674, time/batch = 0.152\n",
            "1345/2810 (epoch 4), train_loss = 1.659, time/batch = 0.150\n",
            "1346/2810 (epoch 4), train_loss = 1.698, time/batch = 0.149\n",
            "1347/2810 (epoch 4), train_loss = 1.679, time/batch = 0.147\n",
            "1348/2810 (epoch 4), train_loss = 1.639, time/batch = 0.166\n",
            "1349/2810 (epoch 4), train_loss = 1.707, time/batch = 0.155\n",
            "1350/2810 (epoch 4), train_loss = 1.687, time/batch = 0.140\n",
            "1351/2810 (epoch 4), train_loss = 1.702, time/batch = 0.151\n",
            "1352/2810 (epoch 4), train_loss = 1.694, time/batch = 0.146\n",
            "1353/2810 (epoch 4), train_loss = 1.744, time/batch = 0.161\n",
            "1354/2810 (epoch 4), train_loss = 1.690, time/batch = 0.159\n",
            "1355/2810 (epoch 4), train_loss = 1.703, time/batch = 0.156\n",
            "1356/2810 (epoch 4), train_loss = 1.731, time/batch = 0.142\n",
            "1357/2810 (epoch 4), train_loss = 1.677, time/batch = 0.144\n",
            "1358/2810 (epoch 4), train_loss = 1.724, time/batch = 0.142\n",
            "1359/2810 (epoch 4), train_loss = 1.637, time/batch = 0.160\n",
            "1360/2810 (epoch 4), train_loss = 1.710, time/batch = 0.157\n",
            "1361/2810 (epoch 4), train_loss = 1.735, time/batch = 0.177\n",
            "1362/2810 (epoch 4), train_loss = 1.711, time/batch = 0.155\n",
            "1363/2810 (epoch 4), train_loss = 1.695, time/batch = 0.146\n",
            "1364/2810 (epoch 4), train_loss = 1.691, time/batch = 0.145\n",
            "1365/2810 (epoch 4), train_loss = 1.798, time/batch = 0.157\n",
            "1366/2810 (epoch 4), train_loss = 1.673, time/batch = 0.164\n",
            "1367/2810 (epoch 4), train_loss = 1.740, time/batch = 0.149\n",
            "1368/2810 (epoch 4), train_loss = 1.722, time/batch = 0.166\n",
            "1369/2810 (epoch 4), train_loss = 1.733, time/batch = 0.157\n",
            "1370/2810 (epoch 4), train_loss = 1.679, time/batch = 0.146\n",
            "1371/2810 (epoch 4), train_loss = 1.725, time/batch = 0.152\n",
            "1372/2810 (epoch 4), train_loss = 1.670, time/batch = 0.151\n",
            "1373/2810 (epoch 4), train_loss = 1.713, time/batch = 0.151\n",
            "1374/2810 (epoch 4), train_loss = 1.654, time/batch = 0.145\n",
            "1375/2810 (epoch 4), train_loss = 1.726, time/batch = 0.165\n",
            "1376/2810 (epoch 4), train_loss = 1.730, time/batch = 0.148\n",
            "1377/2810 (epoch 4), train_loss = 1.686, time/batch = 0.168\n",
            "1378/2810 (epoch 4), train_loss = 1.682, time/batch = 0.240\n",
            "1379/2810 (epoch 4), train_loss = 1.680, time/batch = 0.263\n",
            "1380/2810 (epoch 4), train_loss = 1.676, time/batch = 0.257\n",
            "1381/2810 (epoch 4), train_loss = 1.660, time/batch = 0.257\n",
            "1382/2810 (epoch 4), train_loss = 1.676, time/batch = 0.258\n",
            "1383/2810 (epoch 4), train_loss = 1.724, time/batch = 0.266\n",
            "1384/2810 (epoch 4), train_loss = 1.686, time/batch = 0.239\n",
            "1385/2810 (epoch 4), train_loss = 1.688, time/batch = 0.269\n",
            "1386/2810 (epoch 4), train_loss = 1.596, time/batch = 0.239\n",
            "1387/2810 (epoch 4), train_loss = 1.704, time/batch = 0.278\n",
            "1388/2810 (epoch 4), train_loss = 1.737, time/batch = 0.264\n",
            "1389/2810 (epoch 4), train_loss = 1.724, time/batch = 0.274\n",
            "1390/2810 (epoch 4), train_loss = 1.686, time/batch = 0.222\n",
            "1391/2810 (epoch 4), train_loss = 1.710, time/batch = 0.156\n",
            "1392/2810 (epoch 4), train_loss = 1.702, time/batch = 0.154\n",
            "1393/2810 (epoch 4), train_loss = 1.709, time/batch = 0.162\n",
            "1394/2810 (epoch 4), train_loss = 1.706, time/batch = 0.149\n",
            "1395/2810 (epoch 4), train_loss = 1.675, time/batch = 0.153\n",
            "1396/2810 (epoch 4), train_loss = 1.663, time/batch = 0.158\n",
            "1397/2810 (epoch 4), train_loss = 1.715, time/batch = 0.158\n",
            "1398/2810 (epoch 4), train_loss = 1.772, time/batch = 0.140\n",
            "1399/2810 (epoch 4), train_loss = 1.732, time/batch = 0.144\n",
            "1400/2810 (epoch 4), train_loss = 1.705, time/batch = 0.175\n",
            "1401/2810 (epoch 4), train_loss = 1.705, time/batch = 0.147\n",
            "1402/2810 (epoch 4), train_loss = 1.646, time/batch = 0.155\n",
            "1403/2810 (epoch 4), train_loss = 1.675, time/batch = 0.159\n",
            "1404/2810 (epoch 4), train_loss = 1.707, time/batch = 0.156\n",
            "1405/2810 (epoch 5), train_loss = 1.718, time/batch = 0.153\n",
            "1406/2810 (epoch 5), train_loss = 1.722, time/batch = 0.155\n",
            "1407/2810 (epoch 5), train_loss = 1.711, time/batch = 0.142\n",
            "1408/2810 (epoch 5), train_loss = 1.714, time/batch = 0.149\n",
            "1409/2810 (epoch 5), train_loss = 1.621, time/batch = 0.149\n",
            "1410/2810 (epoch 5), train_loss = 1.716, time/batch = 0.145\n",
            "1411/2810 (epoch 5), train_loss = 1.668, time/batch = 0.159\n",
            "1412/2810 (epoch 5), train_loss = 1.667, time/batch = 0.155\n",
            "1413/2810 (epoch 5), train_loss = 1.744, time/batch = 0.173\n",
            "1414/2810 (epoch 5), train_loss = 1.642, time/batch = 0.161\n",
            "1415/2810 (epoch 5), train_loss = 1.718, time/batch = 0.197\n",
            "1416/2810 (epoch 5), train_loss = 1.697, time/batch = 0.146\n",
            "1417/2810 (epoch 5), train_loss = 1.666, time/batch = 0.156\n",
            "1418/2810 (epoch 5), train_loss = 1.705, time/batch = 0.146\n",
            "1419/2810 (epoch 5), train_loss = 1.737, time/batch = 0.166\n",
            "1420/2810 (epoch 5), train_loss = 1.713, time/batch = 0.148\n",
            "1421/2810 (epoch 5), train_loss = 1.648, time/batch = 0.155\n",
            "1422/2810 (epoch 5), train_loss = 1.787, time/batch = 0.150\n",
            "1423/2810 (epoch 5), train_loss = 1.679, time/batch = 0.143\n",
            "1424/2810 (epoch 5), train_loss = 1.726, time/batch = 0.151\n",
            "1425/2810 (epoch 5), train_loss = 1.698, time/batch = 0.154\n",
            "1426/2810 (epoch 5), train_loss = 1.737, time/batch = 0.160\n",
            "1427/2810 (epoch 5), train_loss = 1.699, time/batch = 0.174\n",
            "1428/2810 (epoch 5), train_loss = 1.689, time/batch = 0.156\n",
            "1429/2810 (epoch 5), train_loss = 1.691, time/batch = 0.150\n",
            "1430/2810 (epoch 5), train_loss = 1.649, time/batch = 0.158\n",
            "1431/2810 (epoch 5), train_loss = 1.686, time/batch = 0.145\n",
            "1432/2810 (epoch 5), train_loss = 1.671, time/batch = 0.165\n",
            "1433/2810 (epoch 5), train_loss = 1.621, time/batch = 0.167\n",
            "1434/2810 (epoch 5), train_loss = 1.682, time/batch = 0.155\n",
            "1435/2810 (epoch 5), train_loss = 1.701, time/batch = 0.149\n",
            "1436/2810 (epoch 5), train_loss = 1.714, time/batch = 0.151\n",
            "1437/2810 (epoch 5), train_loss = 1.644, time/batch = 0.151\n",
            "1438/2810 (epoch 5), train_loss = 1.738, time/batch = 0.153\n",
            "1439/2810 (epoch 5), train_loss = 1.741, time/batch = 0.168\n",
            "1440/2810 (epoch 5), train_loss = 1.676, time/batch = 0.162\n",
            "1441/2810 (epoch 5), train_loss = 1.696, time/batch = 0.151\n",
            "1442/2810 (epoch 5), train_loss = 1.702, time/batch = 0.152\n",
            "1443/2810 (epoch 5), train_loss = 1.684, time/batch = 0.148\n",
            "1444/2810 (epoch 5), train_loss = 1.704, time/batch = 0.151\n",
            "1445/2810 (epoch 5), train_loss = 1.689, time/batch = 0.145\n",
            "1446/2810 (epoch 5), train_loss = 1.635, time/batch = 0.171\n",
            "1447/2810 (epoch 5), train_loss = 1.696, time/batch = 0.147\n",
            "1448/2810 (epoch 5), train_loss = 1.720, time/batch = 0.139\n",
            "1449/2810 (epoch 5), train_loss = 1.729, time/batch = 0.143\n",
            "1450/2810 (epoch 5), train_loss = 1.678, time/batch = 0.153\n",
            "1451/2810 (epoch 5), train_loss = 1.630, time/batch = 0.153\n",
            "1452/2810 (epoch 5), train_loss = 1.641, time/batch = 0.140\n",
            "1453/2810 (epoch 5), train_loss = 1.655, time/batch = 0.173\n",
            "1454/2810 (epoch 5), train_loss = 1.669, time/batch = 0.181\n",
            "1455/2810 (epoch 5), train_loss = 1.687, time/batch = 0.255\n",
            "1456/2810 (epoch 5), train_loss = 1.691, time/batch = 0.242\n",
            "1457/2810 (epoch 5), train_loss = 1.656, time/batch = 0.270\n",
            "1458/2810 (epoch 5), train_loss = 1.702, time/batch = 0.286\n",
            "1459/2810 (epoch 5), train_loss = 1.672, time/batch = 0.269\n",
            "1460/2810 (epoch 5), train_loss = 1.639, time/batch = 0.270\n",
            "1461/2810 (epoch 5), train_loss = 1.656, time/batch = 0.274\n",
            "1462/2810 (epoch 5), train_loss = 1.684, time/batch = 0.270\n",
            "1463/2810 (epoch 5), train_loss = 1.694, time/batch = 0.248\n",
            "1464/2810 (epoch 5), train_loss = 1.598, time/batch = 0.274\n",
            "1465/2810 (epoch 5), train_loss = 1.653, time/batch = 0.276\n",
            "1466/2810 (epoch 5), train_loss = 1.659, time/batch = 0.251\n",
            "1467/2810 (epoch 5), train_loss = 1.671, time/batch = 0.156\n",
            "1468/2810 (epoch 5), train_loss = 1.687, time/batch = 0.157\n",
            "1469/2810 (epoch 5), train_loss = 1.706, time/batch = 0.153\n",
            "1470/2810 (epoch 5), train_loss = 1.681, time/batch = 0.151\n",
            "1471/2810 (epoch 5), train_loss = 1.581, time/batch = 0.181\n",
            "1472/2810 (epoch 5), train_loss = 1.673, time/batch = 0.142\n",
            "1473/2810 (epoch 5), train_loss = 1.735, time/batch = 0.154\n",
            "1474/2810 (epoch 5), train_loss = 1.681, time/batch = 0.149\n",
            "1475/2810 (epoch 5), train_loss = 1.652, time/batch = 0.145\n",
            "1476/2810 (epoch 5), train_loss = 1.699, time/batch = 0.144\n",
            "1477/2810 (epoch 5), train_loss = 1.701, time/batch = 0.146\n",
            "1478/2810 (epoch 5), train_loss = 1.676, time/batch = 0.161\n",
            "1479/2810 (epoch 5), train_loss = 1.632, time/batch = 0.149\n",
            "1480/2810 (epoch 5), train_loss = 1.655, time/batch = 0.141\n",
            "1481/2810 (epoch 5), train_loss = 1.626, time/batch = 0.147\n",
            "1482/2810 (epoch 5), train_loss = 1.635, time/batch = 0.148\n",
            "1483/2810 (epoch 5), train_loss = 1.678, time/batch = 0.146\n",
            "1484/2810 (epoch 5), train_loss = 1.717, time/batch = 0.152\n",
            "1485/2810 (epoch 5), train_loss = 1.626, time/batch = 0.167\n",
            "1486/2810 (epoch 5), train_loss = 1.635, time/batch = 0.150\n",
            "1487/2810 (epoch 5), train_loss = 1.632, time/batch = 0.153\n",
            "1488/2810 (epoch 5), train_loss = 1.615, time/batch = 0.144\n",
            "1489/2810 (epoch 5), train_loss = 1.571, time/batch = 0.143\n",
            "1490/2810 (epoch 5), train_loss = 1.632, time/batch = 0.152\n",
            "1491/2810 (epoch 5), train_loss = 1.658, time/batch = 0.155\n",
            "1492/2810 (epoch 5), train_loss = 1.701, time/batch = 0.177\n",
            "1493/2810 (epoch 5), train_loss = 1.643, time/batch = 0.153\n",
            "1494/2810 (epoch 5), train_loss = 1.659, time/batch = 0.151\n",
            "1495/2810 (epoch 5), train_loss = 1.657, time/batch = 0.149\n",
            "1496/2810 (epoch 5), train_loss = 1.682, time/batch = 0.154\n",
            "1497/2810 (epoch 5), train_loss = 1.675, time/batch = 0.160\n",
            "1498/2810 (epoch 5), train_loss = 1.759, time/batch = 0.145\n",
            "1499/2810 (epoch 5), train_loss = 1.672, time/batch = 0.176\n",
            "1500/2810 (epoch 5), train_loss = 1.698, time/batch = 0.151\n",
            "1501/2810 (epoch 5), train_loss = 1.698, time/batch = 0.151\n",
            "1502/2810 (epoch 5), train_loss = 1.590, time/batch = 0.144\n",
            "1503/2810 (epoch 5), train_loss = 1.583, time/batch = 0.158\n",
            "1504/2810 (epoch 5), train_loss = 1.625, time/batch = 0.153\n",
            "1505/2810 (epoch 5), train_loss = 1.628, time/batch = 0.173\n",
            "1506/2810 (epoch 5), train_loss = 1.675, time/batch = 0.147\n",
            "1507/2810 (epoch 5), train_loss = 1.732, time/batch = 0.154\n",
            "1508/2810 (epoch 5), train_loss = 1.666, time/batch = 0.161\n",
            "1509/2810 (epoch 5), train_loss = 1.602, time/batch = 0.154\n",
            "1510/2810 (epoch 5), train_loss = 1.587, time/batch = 0.159\n",
            "1511/2810 (epoch 5), train_loss = 1.641, time/batch = 0.152\n",
            "1512/2810 (epoch 5), train_loss = 1.702, time/batch = 0.160\n",
            "1513/2810 (epoch 5), train_loss = 1.690, time/batch = 0.144\n",
            "1514/2810 (epoch 5), train_loss = 1.636, time/batch = 0.149\n",
            "1515/2810 (epoch 5), train_loss = 1.681, time/batch = 0.147\n",
            "1516/2810 (epoch 5), train_loss = 1.576, time/batch = 0.146\n",
            "1517/2810 (epoch 5), train_loss = 1.621, time/batch = 0.149\n",
            "1518/2810 (epoch 5), train_loss = 1.680, time/batch = 0.154\n",
            "1519/2810 (epoch 5), train_loss = 1.687, time/batch = 0.169\n",
            "1520/2810 (epoch 5), train_loss = 1.680, time/batch = 0.150\n",
            "1521/2810 (epoch 5), train_loss = 1.662, time/batch = 0.152\n",
            "1522/2810 (epoch 5), train_loss = 1.623, time/batch = 0.156\n",
            "1523/2810 (epoch 5), train_loss = 1.639, time/batch = 0.157\n",
            "1524/2810 (epoch 5), train_loss = 1.700, time/batch = 0.157\n",
            "1525/2810 (epoch 5), train_loss = 1.647, time/batch = 0.147\n",
            "1526/2810 (epoch 5), train_loss = 1.632, time/batch = 0.158\n",
            "1527/2810 (epoch 5), train_loss = 1.652, time/batch = 0.141\n",
            "1528/2810 (epoch 5), train_loss = 1.667, time/batch = 0.150\n",
            "1529/2810 (epoch 5), train_loss = 1.626, time/batch = 0.156\n",
            "1530/2810 (epoch 5), train_loss = 1.596, time/batch = 0.159\n",
            "1531/2810 (epoch 5), train_loss = 1.623, time/batch = 0.143\n",
            "1532/2810 (epoch 5), train_loss = 1.647, time/batch = 0.231\n",
            "1533/2810 (epoch 5), train_loss = 1.709, time/batch = 0.243\n",
            "1534/2810 (epoch 5), train_loss = 1.643, time/batch = 0.249\n",
            "1535/2810 (epoch 5), train_loss = 1.649, time/batch = 0.256\n",
            "1536/2810 (epoch 5), train_loss = 1.629, time/batch = 0.223\n",
            "1537/2810 (epoch 5), train_loss = 1.661, time/batch = 0.236\n",
            "1538/2810 (epoch 5), train_loss = 1.676, time/batch = 0.235\n",
            "1539/2810 (epoch 5), train_loss = 1.644, time/batch = 0.257\n",
            "1540/2810 (epoch 5), train_loss = 1.661, time/batch = 0.248\n",
            "1541/2810 (epoch 5), train_loss = 1.738, time/batch = 0.269\n",
            "1542/2810 (epoch 5), train_loss = 1.704, time/batch = 0.276\n",
            "1543/2810 (epoch 5), train_loss = 1.675, time/batch = 0.273\n",
            "1544/2810 (epoch 5), train_loss = 1.696, time/batch = 0.224\n",
            "1545/2810 (epoch 5), train_loss = 1.703, time/batch = 0.159\n",
            "1546/2810 (epoch 5), train_loss = 1.673, time/batch = 0.138\n",
            "1547/2810 (epoch 5), train_loss = 1.755, time/batch = 0.152\n",
            "1548/2810 (epoch 5), train_loss = 1.734, time/batch = 0.153\n",
            "1549/2810 (epoch 5), train_loss = 1.635, time/batch = 0.160\n",
            "1550/2810 (epoch 5), train_loss = 1.622, time/batch = 0.147\n",
            "1551/2810 (epoch 5), train_loss = 1.684, time/batch = 0.150\n",
            "1552/2810 (epoch 5), train_loss = 1.695, time/batch = 0.161\n",
            "1553/2810 (epoch 5), train_loss = 1.707, time/batch = 0.148\n",
            "1554/2810 (epoch 5), train_loss = 1.675, time/batch = 0.157\n",
            "1555/2810 (epoch 5), train_loss = 1.702, time/batch = 0.147\n",
            "1556/2810 (epoch 5), train_loss = 1.642, time/batch = 0.143\n",
            "1557/2810 (epoch 5), train_loss = 1.690, time/batch = 0.147\n",
            "1558/2810 (epoch 5), train_loss = 1.713, time/batch = 0.145\n",
            "1559/2810 (epoch 5), train_loss = 1.631, time/batch = 0.161\n",
            "1560/2810 (epoch 5), train_loss = 1.665, time/batch = 0.157\n",
            "1561/2810 (epoch 5), train_loss = 1.708, time/batch = 0.159\n",
            "1562/2810 (epoch 5), train_loss = 1.607, time/batch = 0.145\n",
            "1563/2810 (epoch 5), train_loss = 1.647, time/batch = 0.148\n",
            "1564/2810 (epoch 5), train_loss = 1.668, time/batch = 0.139\n",
            "1565/2810 (epoch 5), train_loss = 1.684, time/batch = 0.146\n",
            "1566/2810 (epoch 5), train_loss = 1.738, time/batch = 0.163\n",
            "1567/2810 (epoch 5), train_loss = 1.688, time/batch = 0.159\n",
            "1568/2810 (epoch 5), train_loss = 1.663, time/batch = 0.153\n",
            "1569/2810 (epoch 5), train_loss = 1.681, time/batch = 0.151\n",
            "1570/2810 (epoch 5), train_loss = 1.608, time/batch = 0.142\n",
            "1571/2810 (epoch 5), train_loss = 1.676, time/batch = 0.151\n",
            "1572/2810 (epoch 5), train_loss = 1.667, time/batch = 0.149\n",
            "1573/2810 (epoch 5), train_loss = 1.612, time/batch = 0.166\n",
            "1574/2810 (epoch 5), train_loss = 1.648, time/batch = 0.156\n",
            "1575/2810 (epoch 5), train_loss = 1.685, time/batch = 0.147\n",
            "1576/2810 (epoch 5), train_loss = 1.622, time/batch = 0.149\n",
            "1577/2810 (epoch 5), train_loss = 1.576, time/batch = 0.153\n",
            "1578/2810 (epoch 5), train_loss = 1.742, time/batch = 0.154\n",
            "1579/2810 (epoch 5), train_loss = 1.670, time/batch = 0.152\n",
            "1580/2810 (epoch 5), train_loss = 1.646, time/batch = 0.157\n",
            "1581/2810 (epoch 5), train_loss = 1.625, time/batch = 0.153\n",
            "1582/2810 (epoch 5), train_loss = 1.634, time/batch = 0.152\n",
            "1583/2810 (epoch 5), train_loss = 1.681, time/batch = 0.143\n",
            "1584/2810 (epoch 5), train_loss = 1.680, time/batch = 0.153\n",
            "1585/2810 (epoch 5), train_loss = 1.566, time/batch = 0.142\n",
            "1586/2810 (epoch 5), train_loss = 1.647, time/batch = 0.166\n",
            "1587/2810 (epoch 5), train_loss = 1.670, time/batch = 0.147\n",
            "1588/2810 (epoch 5), train_loss = 1.651, time/batch = 0.149\n",
            "1589/2810 (epoch 5), train_loss = 1.688, time/batch = 0.150\n",
            "1590/2810 (epoch 5), train_loss = 1.598, time/batch = 0.143\n",
            "1591/2810 (epoch 5), train_loss = 1.640, time/batch = 0.151\n",
            "1592/2810 (epoch 5), train_loss = 1.625, time/batch = 0.159\n",
            "1593/2810 (epoch 5), train_loss = 1.704, time/batch = 0.166\n",
            "1594/2810 (epoch 5), train_loss = 1.627, time/batch = 0.157\n",
            "1595/2810 (epoch 5), train_loss = 1.677, time/batch = 0.153\n",
            "1596/2810 (epoch 5), train_loss = 1.687, time/batch = 0.187\n",
            "1597/2810 (epoch 5), train_loss = 1.715, time/batch = 0.145\n",
            "1598/2810 (epoch 5), train_loss = 1.615, time/batch = 0.155\n",
            "1599/2810 (epoch 5), train_loss = 1.654, time/batch = 0.139\n",
            "1600/2810 (epoch 5), train_loss = 1.595, time/batch = 0.176\n",
            "1601/2810 (epoch 5), train_loss = 1.717, time/batch = 0.148\n",
            "1602/2810 (epoch 5), train_loss = 1.564, time/batch = 0.147\n",
            "1603/2810 (epoch 5), train_loss = 1.689, time/batch = 0.148\n",
            "1604/2810 (epoch 5), train_loss = 1.601, time/batch = 0.150\n",
            "1605/2810 (epoch 5), train_loss = 1.681, time/batch = 0.147\n",
            "1606/2810 (epoch 5), train_loss = 1.635, time/batch = 0.163\n",
            "1607/2810 (epoch 5), train_loss = 1.650, time/batch = 0.146\n",
            "1608/2810 (epoch 5), train_loss = 1.686, time/batch = 0.149\n",
            "1609/2810 (epoch 5), train_loss = 1.649, time/batch = 0.149\n",
            "1610/2810 (epoch 5), train_loss = 1.657, time/batch = 0.192\n",
            "1611/2810 (epoch 5), train_loss = 1.641, time/batch = 0.264\n",
            "1612/2810 (epoch 5), train_loss = 1.549, time/batch = 0.268\n",
            "1613/2810 (epoch 5), train_loss = 1.623, time/batch = 0.267\n",
            "1614/2810 (epoch 5), train_loss = 1.609, time/batch = 0.252\n",
            "1615/2810 (epoch 5), train_loss = 1.683, time/batch = 0.263\n",
            "1616/2810 (epoch 5), train_loss = 1.676, time/batch = 0.284\n",
            "1617/2810 (epoch 5), train_loss = 1.629, time/batch = 0.263\n",
            "1618/2810 (epoch 5), train_loss = 1.680, time/batch = 0.245\n",
            "1619/2810 (epoch 5), train_loss = 1.649, time/batch = 0.250\n",
            "1620/2810 (epoch 5), train_loss = 1.646, time/batch = 0.295\n",
            "1621/2810 (epoch 5), train_loss = 1.614, time/batch = 0.279\n",
            "1622/2810 (epoch 5), train_loss = 1.691, time/batch = 0.193\n",
            "1623/2810 (epoch 5), train_loss = 1.674, time/batch = 0.151\n",
            "1624/2810 (epoch 5), train_loss = 1.682, time/batch = 0.163\n",
            "1625/2810 (epoch 5), train_loss = 1.619, time/batch = 0.166\n",
            "1626/2810 (epoch 5), train_loss = 1.599, time/batch = 0.138\n",
            "1627/2810 (epoch 5), train_loss = 1.645, time/batch = 0.142\n",
            "1628/2810 (epoch 5), train_loss = 1.620, time/batch = 0.151\n",
            "1629/2810 (epoch 5), train_loss = 1.579, time/batch = 0.144\n",
            "1630/2810 (epoch 5), train_loss = 1.652, time/batch = 0.143\n",
            "1631/2810 (epoch 5), train_loss = 1.631, time/batch = 0.146\n",
            "1632/2810 (epoch 5), train_loss = 1.647, time/batch = 0.178\n",
            "1633/2810 (epoch 5), train_loss = 1.635, time/batch = 0.153\n",
            "1634/2810 (epoch 5), train_loss = 1.687, time/batch = 0.146\n",
            "1635/2810 (epoch 5), train_loss = 1.637, time/batch = 0.149\n",
            "1636/2810 (epoch 5), train_loss = 1.650, time/batch = 0.149\n",
            "1637/2810 (epoch 5), train_loss = 1.669, time/batch = 0.152\n",
            "1638/2810 (epoch 5), train_loss = 1.616, time/batch = 0.153\n",
            "1639/2810 (epoch 5), train_loss = 1.671, time/batch = 0.169\n",
            "1640/2810 (epoch 5), train_loss = 1.586, time/batch = 0.153\n",
            "1641/2810 (epoch 5), train_loss = 1.653, time/batch = 0.154\n",
            "1642/2810 (epoch 5), train_loss = 1.675, time/batch = 0.157\n",
            "1643/2810 (epoch 5), train_loss = 1.658, time/batch = 0.158\n",
            "1644/2810 (epoch 5), train_loss = 1.646, time/batch = 0.161\n",
            "1645/2810 (epoch 5), train_loss = 1.640, time/batch = 0.150\n",
            "1646/2810 (epoch 5), train_loss = 1.748, time/batch = 0.171\n",
            "1647/2810 (epoch 5), train_loss = 1.621, time/batch = 0.153\n",
            "1648/2810 (epoch 5), train_loss = 1.686, time/batch = 0.163\n",
            "1649/2810 (epoch 5), train_loss = 1.670, time/batch = 0.165\n",
            "1650/2810 (epoch 5), train_loss = 1.676, time/batch = 0.152\n",
            "1651/2810 (epoch 5), train_loss = 1.616, time/batch = 0.148\n",
            "1652/2810 (epoch 5), train_loss = 1.663, time/batch = 0.164\n",
            "1653/2810 (epoch 5), train_loss = 1.615, time/batch = 0.148\n",
            "1654/2810 (epoch 5), train_loss = 1.661, time/batch = 0.153\n",
            "1655/2810 (epoch 5), train_loss = 1.601, time/batch = 0.154\n",
            "1656/2810 (epoch 5), train_loss = 1.672, time/batch = 0.160\n",
            "1657/2810 (epoch 5), train_loss = 1.677, time/batch = 0.151\n",
            "1658/2810 (epoch 5), train_loss = 1.624, time/batch = 0.160\n",
            "1659/2810 (epoch 5), train_loss = 1.629, time/batch = 0.167\n",
            "1660/2810 (epoch 5), train_loss = 1.625, time/batch = 0.147\n",
            "1661/2810 (epoch 5), train_loss = 1.622, time/batch = 0.151\n",
            "1662/2810 (epoch 5), train_loss = 1.605, time/batch = 0.169\n",
            "1663/2810 (epoch 5), train_loss = 1.622, time/batch = 0.154\n",
            "1664/2810 (epoch 5), train_loss = 1.674, time/batch = 0.167\n",
            "1665/2810 (epoch 5), train_loss = 1.626, time/batch = 0.158\n",
            "1666/2810 (epoch 5), train_loss = 1.628, time/batch = 0.157\n",
            "1667/2810 (epoch 5), train_loss = 1.542, time/batch = 0.150\n",
            "1668/2810 (epoch 5), train_loss = 1.645, time/batch = 0.158\n",
            "1669/2810 (epoch 5), train_loss = 1.685, time/batch = 0.151\n",
            "1670/2810 (epoch 5), train_loss = 1.673, time/batch = 0.157\n",
            "1671/2810 (epoch 5), train_loss = 1.631, time/batch = 0.145\n",
            "1672/2810 (epoch 5), train_loss = 1.659, time/batch = 0.175\n",
            "1673/2810 (epoch 5), train_loss = 1.649, time/batch = 0.147\n",
            "1674/2810 (epoch 5), train_loss = 1.655, time/batch = 0.236\n",
            "1675/2810 (epoch 5), train_loss = 1.651, time/batch = 0.235\n",
            "1676/2810 (epoch 5), train_loss = 1.623, time/batch = 0.249\n",
            "1677/2810 (epoch 5), train_loss = 1.608, time/batch = 0.279\n",
            "1678/2810 (epoch 5), train_loss = 1.659, time/batch = 0.256\n",
            "1679/2810 (epoch 5), train_loss = 1.715, time/batch = 0.281\n",
            "1680/2810 (epoch 5), train_loss = 1.675, time/batch = 0.270\n",
            "1681/2810 (epoch 5), train_loss = 1.653, time/batch = 0.292\n",
            "1682/2810 (epoch 5), train_loss = 1.645, time/batch = 0.285\n",
            "1683/2810 (epoch 5), train_loss = 1.592, time/batch = 0.285\n",
            "1684/2810 (epoch 5), train_loss = 1.623, time/batch = 0.286\n",
            "1685/2810 (epoch 5), train_loss = 1.652, time/batch = 0.303\n",
            "1686/2810 (epoch 6), train_loss = 1.656, time/batch = 0.288\n",
            "1687/2810 (epoch 6), train_loss = 1.666, time/batch = 0.301\n",
            "1688/2810 (epoch 6), train_loss = 1.660, time/batch = 0.291\n",
            "1689/2810 (epoch 6), train_loss = 1.662, time/batch = 0.294\n",
            "1690/2810 (epoch 6), train_loss = 1.563, time/batch = 0.250\n",
            "1691/2810 (epoch 6), train_loss = 1.665, time/batch = 0.255\n",
            "1692/2810 (epoch 6), train_loss = 1.615, time/batch = 0.285\n",
            "1693/2810 (epoch 6), train_loss = 1.614, time/batch = 0.248\n",
            "1694/2810 (epoch 6), train_loss = 1.693, time/batch = 0.270\n",
            "1695/2810 (epoch 6), train_loss = 1.588, time/batch = 0.233\n",
            "1696/2810 (epoch 6), train_loss = 1.665, time/batch = 0.169\n",
            "1697/2810 (epoch 6), train_loss = 1.640, time/batch = 0.152\n",
            "1698/2810 (epoch 6), train_loss = 1.614, time/batch = 0.157\n",
            "1699/2810 (epoch 6), train_loss = 1.649, time/batch = 0.162\n",
            "1700/2810 (epoch 6), train_loss = 1.684, time/batch = 0.151\n",
            "1701/2810 (epoch 6), train_loss = 1.660, time/batch = 0.145\n",
            "1702/2810 (epoch 6), train_loss = 1.595, time/batch = 0.147\n",
            "1703/2810 (epoch 6), train_loss = 1.733, time/batch = 0.167\n",
            "1704/2810 (epoch 6), train_loss = 1.633, time/batch = 0.153\n",
            "1705/2810 (epoch 6), train_loss = 1.677, time/batch = 0.142\n",
            "1706/2810 (epoch 6), train_loss = 1.644, time/batch = 0.147\n",
            "1707/2810 (epoch 6), train_loss = 1.687, time/batch = 0.137\n",
            "1708/2810 (epoch 6), train_loss = 1.644, time/batch = 0.157\n",
            "1709/2810 (epoch 6), train_loss = 1.637, time/batch = 0.166\n",
            "1710/2810 (epoch 6), train_loss = 1.641, time/batch = 0.150\n",
            "1711/2810 (epoch 6), train_loss = 1.589, time/batch = 0.153\n",
            "1712/2810 (epoch 6), train_loss = 1.631, time/batch = 0.154\n",
            "1713/2810 (epoch 6), train_loss = 1.621, time/batch = 0.146\n",
            "1714/2810 (epoch 6), train_loss = 1.562, time/batch = 0.156\n",
            "1715/2810 (epoch 6), train_loss = 1.623, time/batch = 0.140\n",
            "1716/2810 (epoch 6), train_loss = 1.648, time/batch = 0.183\n",
            "1717/2810 (epoch 6), train_loss = 1.659, time/batch = 0.153\n",
            "1718/2810 (epoch 6), train_loss = 1.595, time/batch = 0.149\n",
            "1719/2810 (epoch 6), train_loss = 1.681, time/batch = 0.158\n",
            "1720/2810 (epoch 6), train_loss = 1.690, time/batch = 0.150\n",
            "1721/2810 (epoch 6), train_loss = 1.624, time/batch = 0.148\n",
            "1722/2810 (epoch 6), train_loss = 1.638, time/batch = 0.148\n",
            "1723/2810 (epoch 6), train_loss = 1.648, time/batch = 0.158\n",
            "1724/2810 (epoch 6), train_loss = 1.637, time/batch = 0.153\n",
            "1725/2810 (epoch 6), train_loss = 1.648, time/batch = 0.152\n",
            "1726/2810 (epoch 6), train_loss = 1.639, time/batch = 0.148\n",
            "1727/2810 (epoch 6), train_loss = 1.577, time/batch = 0.151\n",
            "1728/2810 (epoch 6), train_loss = 1.644, time/batch = 0.143\n",
            "1729/2810 (epoch 6), train_loss = 1.669, time/batch = 0.147\n",
            "1730/2810 (epoch 6), train_loss = 1.679, time/batch = 0.159\n",
            "1731/2810 (epoch 6), train_loss = 1.624, time/batch = 0.180\n",
            "1732/2810 (epoch 6), train_loss = 1.584, time/batch = 0.160\n",
            "1733/2810 (epoch 6), train_loss = 1.588, time/batch = 0.155\n",
            "1734/2810 (epoch 6), train_loss = 1.604, time/batch = 0.174\n",
            "1735/2810 (epoch 6), train_loss = 1.621, time/batch = 0.162\n",
            "1736/2810 (epoch 6), train_loss = 1.634, time/batch = 0.175\n",
            "1737/2810 (epoch 6), train_loss = 1.639, time/batch = 0.155\n",
            "1738/2810 (epoch 6), train_loss = 1.595, time/batch = 0.144\n",
            "1739/2810 (epoch 6), train_loss = 1.645, time/batch = 0.151\n",
            "1740/2810 (epoch 6), train_loss = 1.619, time/batch = 0.144\n",
            "1741/2810 (epoch 6), train_loss = 1.589, time/batch = 0.157\n",
            "1742/2810 (epoch 6), train_loss = 1.598, time/batch = 0.151\n",
            "1743/2810 (epoch 6), train_loss = 1.633, time/batch = 0.176\n",
            "1744/2810 (epoch 6), train_loss = 1.642, time/batch = 0.149\n",
            "1745/2810 (epoch 6), train_loss = 1.537, time/batch = 0.142\n",
            "1746/2810 (epoch 6), train_loss = 1.600, time/batch = 0.149\n",
            "1747/2810 (epoch 6), train_loss = 1.604, time/batch = 0.158\n",
            "1748/2810 (epoch 6), train_loss = 1.620, time/batch = 0.155\n",
            "1749/2810 (epoch 6), train_loss = 1.630, time/batch = 0.161\n",
            "1750/2810 (epoch 6), train_loss = 1.649, time/batch = 0.149\n",
            "1751/2810 (epoch 6), train_loss = 1.625, time/batch = 0.159\n",
            "1752/2810 (epoch 6), train_loss = 1.525, time/batch = 0.138\n",
            "1753/2810 (epoch 6), train_loss = 1.612, time/batch = 0.156\n",
            "1754/2810 (epoch 6), train_loss = 1.689, time/batch = 0.153\n",
            "1755/2810 (epoch 6), train_loss = 1.635, time/batch = 0.142\n",
            "1756/2810 (epoch 6), train_loss = 1.602, time/batch = 0.165\n",
            "1757/2810 (epoch 6), train_loss = 1.644, time/batch = 0.157\n",
            "1758/2810 (epoch 6), train_loss = 1.648, time/batch = 0.147\n",
            "1759/2810 (epoch 6), train_loss = 1.625, time/batch = 0.149\n",
            "1760/2810 (epoch 6), train_loss = 1.579, time/batch = 0.202\n",
            "1761/2810 (epoch 6), train_loss = 1.606, time/batch = 0.275\n",
            "1762/2810 (epoch 6), train_loss = 1.575, time/batch = 0.275\n",
            "1763/2810 (epoch 6), train_loss = 1.580, time/batch = 0.264\n",
            "1764/2810 (epoch 6), train_loss = 1.623, time/batch = 0.265\n",
            "1765/2810 (epoch 6), train_loss = 1.666, time/batch = 0.257\n",
            "1766/2810 (epoch 6), train_loss = 1.574, time/batch = 0.270\n",
            "1767/2810 (epoch 6), train_loss = 1.582, time/batch = 0.266\n",
            "1768/2810 (epoch 6), train_loss = 1.579, time/batch = 0.310\n",
            "1769/2810 (epoch 6), train_loss = 1.567, time/batch = 0.292\n",
            "1770/2810 (epoch 6), train_loss = 1.520, time/batch = 0.250\n",
            "1771/2810 (epoch 6), train_loss = 1.577, time/batch = 0.281\n",
            "1772/2810 (epoch 6), train_loss = 1.610, time/batch = 0.232\n",
            "1773/2810 (epoch 6), train_loss = 1.654, time/batch = 0.151\n",
            "1774/2810 (epoch 6), train_loss = 1.593, time/batch = 0.163\n",
            "1775/2810 (epoch 6), train_loss = 1.612, time/batch = 0.140\n",
            "1776/2810 (epoch 6), train_loss = 1.600, time/batch = 0.136\n",
            "1777/2810 (epoch 6), train_loss = 1.636, time/batch = 0.143\n",
            "1778/2810 (epoch 6), train_loss = 1.628, time/batch = 0.144\n",
            "1779/2810 (epoch 6), train_loss = 1.709, time/batch = 0.140\n",
            "1780/2810 (epoch 6), train_loss = 1.616, time/batch = 0.164\n",
            "1781/2810 (epoch 6), train_loss = 1.643, time/batch = 0.164\n",
            "1782/2810 (epoch 6), train_loss = 1.651, time/batch = 0.144\n",
            "1783/2810 (epoch 6), train_loss = 1.543, time/batch = 0.143\n",
            "1784/2810 (epoch 6), train_loss = 1.532, time/batch = 0.151\n",
            "1785/2810 (epoch 6), train_loss = 1.578, time/batch = 0.154\n",
            "1786/2810 (epoch 6), train_loss = 1.576, time/batch = 0.145\n",
            "1787/2810 (epoch 6), train_loss = 1.626, time/batch = 0.141\n",
            "1788/2810 (epoch 6), train_loss = 1.682, time/batch = 0.168\n",
            "1789/2810 (epoch 6), train_loss = 1.616, time/batch = 0.145\n",
            "1790/2810 (epoch 6), train_loss = 1.555, time/batch = 0.146\n",
            "1791/2810 (epoch 6), train_loss = 1.538, time/batch = 0.145\n",
            "1792/2810 (epoch 6), train_loss = 1.593, time/batch = 0.156\n",
            "1793/2810 (epoch 6), train_loss = 1.650, time/batch = 0.160\n",
            "1794/2810 (epoch 6), train_loss = 1.637, time/batch = 0.142\n",
            "1795/2810 (epoch 6), train_loss = 1.586, time/batch = 0.167\n",
            "1796/2810 (epoch 6), train_loss = 1.633, time/batch = 0.161\n",
            "1797/2810 (epoch 6), train_loss = 1.531, time/batch = 0.148\n",
            "1798/2810 (epoch 6), train_loss = 1.573, time/batch = 0.148\n",
            "1799/2810 (epoch 6), train_loss = 1.637, time/batch = 0.150\n",
            "1800/2810 (epoch 6), train_loss = 1.639, time/batch = 0.155\n",
            "1801/2810 (epoch 6), train_loss = 1.635, time/batch = 0.137\n",
            "1802/2810 (epoch 6), train_loss = 1.621, time/batch = 0.162\n",
            "1803/2810 (epoch 6), train_loss = 1.570, time/batch = 0.159\n",
            "1804/2810 (epoch 6), train_loss = 1.594, time/batch = 0.158\n",
            "1805/2810 (epoch 6), train_loss = 1.649, time/batch = 0.150\n",
            "1806/2810 (epoch 6), train_loss = 1.604, time/batch = 0.162\n",
            "1807/2810 (epoch 6), train_loss = 1.590, time/batch = 0.152\n",
            "1808/2810 (epoch 6), train_loss = 1.604, time/batch = 0.139\n",
            "1809/2810 (epoch 6), train_loss = 1.619, time/batch = 0.173\n",
            "1810/2810 (epoch 6), train_loss = 1.576, time/batch = 0.144\n",
            "1811/2810 (epoch 6), train_loss = 1.548, time/batch = 0.160\n",
            "1812/2810 (epoch 6), train_loss = 1.576, time/batch = 0.146\n",
            "1813/2810 (epoch 6), train_loss = 1.602, time/batch = 0.149\n",
            "1814/2810 (epoch 6), train_loss = 1.659, time/batch = 0.140\n",
            "1815/2810 (epoch 6), train_loss = 1.595, time/batch = 0.167\n",
            "1816/2810 (epoch 6), train_loss = 1.602, time/batch = 0.150\n",
            "1817/2810 (epoch 6), train_loss = 1.577, time/batch = 0.153\n",
            "1818/2810 (epoch 6), train_loss = 1.613, time/batch = 0.148\n",
            "1819/2810 (epoch 6), train_loss = 1.628, time/batch = 0.153\n",
            "1820/2810 (epoch 6), train_loss = 1.598, time/batch = 0.157\n",
            "1821/2810 (epoch 6), train_loss = 1.610, time/batch = 0.141\n",
            "1822/2810 (epoch 6), train_loss = 1.685, time/batch = 0.160\n",
            "1823/2810 (epoch 6), train_loss = 1.659, time/batch = 0.157\n",
            "1824/2810 (epoch 6), train_loss = 1.627, time/batch = 0.155\n",
            "1825/2810 (epoch 6), train_loss = 1.649, time/batch = 0.149\n",
            "1826/2810 (epoch 6), train_loss = 1.656, time/batch = 0.165\n",
            "1827/2810 (epoch 6), train_loss = 1.632, time/batch = 0.157\n",
            "1828/2810 (epoch 6), train_loss = 1.705, time/batch = 0.147\n",
            "1829/2810 (epoch 6), train_loss = 1.682, time/batch = 0.157\n",
            "1830/2810 (epoch 6), train_loss = 1.590, time/batch = 0.156\n",
            "1831/2810 (epoch 6), train_loss = 1.579, time/batch = 0.144\n",
            "1832/2810 (epoch 6), train_loss = 1.634, time/batch = 0.156\n",
            "1833/2810 (epoch 6), train_loss = 1.644, time/batch = 0.151\n",
            "1834/2810 (epoch 6), train_loss = 1.662, time/batch = 0.164\n",
            "1835/2810 (epoch 6), train_loss = 1.625, time/batch = 0.163\n",
            "1836/2810 (epoch 6), train_loss = 1.652, time/batch = 0.161\n",
            "1837/2810 (epoch 6), train_loss = 1.592, time/batch = 0.158\n",
            "1838/2810 (epoch 6), train_loss = 1.642, time/batch = 0.206\n",
            "1839/2810 (epoch 6), train_loss = 1.664, time/batch = 0.258\n",
            "1840/2810 (epoch 6), train_loss = 1.579, time/batch = 0.270\n",
            "1841/2810 (epoch 6), train_loss = 1.621, time/batch = 0.278\n",
            "1842/2810 (epoch 6), train_loss = 1.662, time/batch = 0.271\n",
            "1843/2810 (epoch 6), train_loss = 1.556, time/batch = 0.255\n",
            "1844/2810 (epoch 6), train_loss = 1.601, time/batch = 0.268\n",
            "1845/2810 (epoch 6), train_loss = 1.617, time/batch = 0.271\n",
            "1846/2810 (epoch 6), train_loss = 1.643, time/batch = 0.257\n",
            "1847/2810 (epoch 6), train_loss = 1.694, time/batch = 0.255\n",
            "1848/2810 (epoch 6), train_loss = 1.637, time/batch = 0.267\n",
            "1849/2810 (epoch 6), train_loss = 1.613, time/batch = 0.281\n",
            "1850/2810 (epoch 6), train_loss = 1.634, time/batch = 0.291\n",
            "1851/2810 (epoch 6), train_loss = 1.563, time/batch = 0.145\n",
            "1852/2810 (epoch 6), train_loss = 1.630, time/batch = 0.142\n",
            "1853/2810 (epoch 6), train_loss = 1.617, time/batch = 0.146\n",
            "1854/2810 (epoch 6), train_loss = 1.565, time/batch = 0.159\n",
            "1855/2810 (epoch 6), train_loss = 1.601, time/batch = 0.149\n",
            "1856/2810 (epoch 6), train_loss = 1.637, time/batch = 0.152\n",
            "1857/2810 (epoch 6), train_loss = 1.578, time/batch = 0.143\n",
            "1858/2810 (epoch 6), train_loss = 1.528, time/batch = 0.146\n",
            "1859/2810 (epoch 6), train_loss = 1.697, time/batch = 0.145\n",
            "1860/2810 (epoch 6), train_loss = 1.621, time/batch = 0.151\n",
            "1861/2810 (epoch 6), train_loss = 1.594, time/batch = 0.153\n",
            "1862/2810 (epoch 6), train_loss = 1.583, time/batch = 0.157\n",
            "1863/2810 (epoch 6), train_loss = 1.592, time/batch = 0.147\n",
            "1864/2810 (epoch 6), train_loss = 1.629, time/batch = 0.154\n",
            "1865/2810 (epoch 6), train_loss = 1.635, time/batch = 0.151\n",
            "1866/2810 (epoch 6), train_loss = 1.517, time/batch = 0.144\n",
            "1867/2810 (epoch 6), train_loss = 1.600, time/batch = 0.163\n",
            "1868/2810 (epoch 6), train_loss = 1.623, time/batch = 0.140\n",
            "1869/2810 (epoch 6), train_loss = 1.602, time/batch = 0.141\n",
            "1870/2810 (epoch 6), train_loss = 1.643, time/batch = 0.139\n",
            "1871/2810 (epoch 6), train_loss = 1.554, time/batch = 0.151\n",
            "1872/2810 (epoch 6), train_loss = 1.602, time/batch = 0.149\n",
            "1873/2810 (epoch 6), train_loss = 1.576, time/batch = 0.142\n",
            "1874/2810 (epoch 6), train_loss = 1.652, time/batch = 0.167\n",
            "1875/2810 (epoch 6), train_loss = 1.580, time/batch = 0.136\n",
            "1876/2810 (epoch 6), train_loss = 1.629, time/batch = 0.145\n",
            "1877/2810 (epoch 6), train_loss = 1.639, time/batch = 0.150\n",
            "1878/2810 (epoch 6), train_loss = 1.667, time/batch = 0.146\n",
            "1879/2810 (epoch 6), train_loss = 1.566, time/batch = 0.149\n",
            "1880/2810 (epoch 6), train_loss = 1.610, time/batch = 0.146\n",
            "1881/2810 (epoch 6), train_loss = 1.551, time/batch = 0.175\n",
            "1882/2810 (epoch 6), train_loss = 1.662, time/batch = 0.150\n",
            "1883/2810 (epoch 6), train_loss = 1.522, time/batch = 0.163\n",
            "1884/2810 (epoch 6), train_loss = 1.643, time/batch = 0.155\n",
            "1885/2810 (epoch 6), train_loss = 1.555, time/batch = 0.148\n",
            "1886/2810 (epoch 6), train_loss = 1.636, time/batch = 0.150\n",
            "1887/2810 (epoch 6), train_loss = 1.587, time/batch = 0.151\n",
            "1888/2810 (epoch 6), train_loss = 1.603, time/batch = 0.159\n",
            "1889/2810 (epoch 6), train_loss = 1.644, time/batch = 0.150\n",
            "1890/2810 (epoch 6), train_loss = 1.597, time/batch = 0.140\n",
            "1891/2810 (epoch 6), train_loss = 1.607, time/batch = 0.143\n",
            "1892/2810 (epoch 6), train_loss = 1.592, time/batch = 0.138\n",
            "1893/2810 (epoch 6), train_loss = 1.506, time/batch = 0.139\n",
            "1894/2810 (epoch 6), train_loss = 1.581, time/batch = 0.147\n",
            "1895/2810 (epoch 6), train_loss = 1.558, time/batch = 0.165\n",
            "1896/2810 (epoch 6), train_loss = 1.643, time/batch = 0.143\n",
            "1897/2810 (epoch 6), train_loss = 1.633, time/batch = 0.139\n",
            "1898/2810 (epoch 6), train_loss = 1.582, time/batch = 0.148\n",
            "1899/2810 (epoch 6), train_loss = 1.625, time/batch = 0.141\n",
            "1900/2810 (epoch 6), train_loss = 1.610, time/batch = 0.147\n",
            "1901/2810 (epoch 6), train_loss = 1.601, time/batch = 0.140\n",
            "1902/2810 (epoch 6), train_loss = 1.563, time/batch = 0.157\n",
            "1903/2810 (epoch 6), train_loss = 1.645, time/batch = 0.142\n",
            "1904/2810 (epoch 6), train_loss = 1.622, time/batch = 0.146\n",
            "1905/2810 (epoch 6), train_loss = 1.631, time/batch = 0.150\n",
            "1906/2810 (epoch 6), train_loss = 1.578, time/batch = 0.163\n",
            "1907/2810 (epoch 6), train_loss = 1.553, time/batch = 0.144\n",
            "1908/2810 (epoch 6), train_loss = 1.600, time/batch = 0.151\n",
            "1909/2810 (epoch 6), train_loss = 1.572, time/batch = 0.151\n",
            "1910/2810 (epoch 6), train_loss = 1.529, time/batch = 0.164\n",
            "1911/2810 (epoch 6), train_loss = 1.606, time/batch = 0.150\n",
            "1912/2810 (epoch 6), train_loss = 1.582, time/batch = 0.142\n",
            "1913/2810 (epoch 6), train_loss = 1.601, time/batch = 0.147\n",
            "1914/2810 (epoch 6), train_loss = 1.584, time/batch = 0.148\n",
            "1915/2810 (epoch 6), train_loss = 1.640, time/batch = 0.140\n",
            "1916/2810 (epoch 6), train_loss = 1.592, time/batch = 0.168\n",
            "1917/2810 (epoch 6), train_loss = 1.609, time/batch = 0.168\n",
            "1918/2810 (epoch 6), train_loss = 1.622, time/batch = 0.238\n",
            "1919/2810 (epoch 6), train_loss = 1.571, time/batch = 0.271\n",
            "1920/2810 (epoch 6), train_loss = 1.631, time/batch = 0.256\n",
            "1921/2810 (epoch 6), train_loss = 1.547, time/batch = 0.270\n",
            "1922/2810 (epoch 6), train_loss = 1.607, time/batch = 0.251\n",
            "1923/2810 (epoch 6), train_loss = 1.628, time/batch = 0.246\n",
            "1924/2810 (epoch 6), train_loss = 1.614, time/batch = 0.242\n",
            "1925/2810 (epoch 6), train_loss = 1.607, time/batch = 0.282\n",
            "1926/2810 (epoch 6), train_loss = 1.597, time/batch = 0.237\n",
            "1927/2810 (epoch 6), train_loss = 1.705, time/batch = 0.270\n",
            "1928/2810 (epoch 6), train_loss = 1.578, time/batch = 0.275\n",
            "1929/2810 (epoch 6), train_loss = 1.644, time/batch = 0.279\n",
            "1930/2810 (epoch 6), train_loss = 1.626, time/batch = 0.170\n",
            "1931/2810 (epoch 6), train_loss = 1.630, time/batch = 0.152\n",
            "1932/2810 (epoch 6), train_loss = 1.562, time/batch = 0.143\n",
            "1933/2810 (epoch 6), train_loss = 1.612, time/batch = 0.154\n",
            "1934/2810 (epoch 6), train_loss = 1.569, time/batch = 0.150\n",
            "1935/2810 (epoch 6), train_loss = 1.620, time/batch = 0.179\n",
            "1936/2810 (epoch 6), train_loss = 1.556, time/batch = 0.145\n",
            "1937/2810 (epoch 6), train_loss = 1.628, time/batch = 0.142\n",
            "1938/2810 (epoch 6), train_loss = 1.634, time/batch = 0.192\n",
            "1939/2810 (epoch 6), train_loss = 1.575, time/batch = 0.158\n",
            "1940/2810 (epoch 6), train_loss = 1.584, time/batch = 0.137\n",
            "1941/2810 (epoch 6), train_loss = 1.583, time/batch = 0.152\n",
            "1942/2810 (epoch 6), train_loss = 1.577, time/batch = 0.162\n",
            "1943/2810 (epoch 6), train_loss = 1.563, time/batch = 0.160\n",
            "1944/2810 (epoch 6), train_loss = 1.579, time/batch = 0.146\n",
            "1945/2810 (epoch 6), train_loss = 1.633, time/batch = 0.146\n",
            "1946/2810 (epoch 6), train_loss = 1.579, time/batch = 0.153\n",
            "1947/2810 (epoch 6), train_loss = 1.580, time/batch = 0.162\n",
            "1948/2810 (epoch 6), train_loss = 1.499, time/batch = 0.151\n",
            "1949/2810 (epoch 6), train_loss = 1.596, time/batch = 0.147\n",
            "1950/2810 (epoch 6), train_loss = 1.639, time/batch = 0.152\n",
            "1951/2810 (epoch 6), train_loss = 1.632, time/batch = 0.152\n",
            "1952/2810 (epoch 6), train_loss = 1.588, time/batch = 0.154\n",
            "1953/2810 (epoch 6), train_loss = 1.617, time/batch = 0.146\n",
            "1954/2810 (epoch 6), train_loss = 1.607, time/batch = 0.156\n",
            "1955/2810 (epoch 6), train_loss = 1.611, time/batch = 0.157\n",
            "1956/2810 (epoch 6), train_loss = 1.608, time/batch = 0.146\n",
            "1957/2810 (epoch 6), train_loss = 1.579, time/batch = 0.149\n",
            "1958/2810 (epoch 6), train_loss = 1.563, time/batch = 0.149\n",
            "1959/2810 (epoch 6), train_loss = 1.611, time/batch = 0.145\n",
            "1960/2810 (epoch 6), train_loss = 1.666, time/batch = 0.157\n",
            "1961/2810 (epoch 6), train_loss = 1.625, time/batch = 0.141\n",
            "1962/2810 (epoch 6), train_loss = 1.612, time/batch = 0.166\n",
            "1963/2810 (epoch 6), train_loss = 1.597, time/batch = 0.142\n",
            "1964/2810 (epoch 6), train_loss = 1.549, time/batch = 0.158\n",
            "1965/2810 (epoch 6), train_loss = 1.582, time/batch = 0.149\n",
            "1966/2810 (epoch 6), train_loss = 1.610, time/batch = 0.163\n",
            "1967/2810 (epoch 7), train_loss = 1.606, time/batch = 0.146\n",
            "1968/2810 (epoch 7), train_loss = 1.622, time/batch = 0.165\n",
            "1969/2810 (epoch 7), train_loss = 1.617, time/batch = 0.153\n",
            "1970/2810 (epoch 7), train_loss = 1.619, time/batch = 0.143\n",
            "1971/2810 (epoch 7), train_loss = 1.515, time/batch = 0.146\n",
            "1972/2810 (epoch 7), train_loss = 1.623, time/batch = 0.141\n",
            "1973/2810 (epoch 7), train_loss = 1.569, time/batch = 0.154\n",
            "1974/2810 (epoch 7), train_loss = 1.569, time/batch = 0.137\n",
            "1975/2810 (epoch 7), train_loss = 1.654, time/batch = 0.170\n",
            "1976/2810 (epoch 7), train_loss = 1.544, time/batch = 0.154\n",
            "1977/2810 (epoch 7), train_loss = 1.622, time/batch = 0.151\n",
            "1978/2810 (epoch 7), train_loss = 1.597, time/batch = 0.140\n",
            "1979/2810 (epoch 7), train_loss = 1.568, time/batch = 0.150\n",
            "1980/2810 (epoch 7), train_loss = 1.602, time/batch = 0.137\n",
            "1981/2810 (epoch 7), train_loss = 1.640, time/batch = 0.146\n",
            "1982/2810 (epoch 7), train_loss = 1.618, time/batch = 0.157\n",
            "1983/2810 (epoch 7), train_loss = 1.552, time/batch = 0.155\n",
            "1984/2810 (epoch 7), train_loss = 1.692, time/batch = 0.143\n",
            "1985/2810 (epoch 7), train_loss = 1.594, time/batch = 0.162\n",
            "1986/2810 (epoch 7), train_loss = 1.636, time/batch = 0.140\n",
            "1987/2810 (epoch 7), train_loss = 1.600, time/batch = 0.152\n",
            "1988/2810 (epoch 7), train_loss = 1.646, time/batch = 0.155\n",
            "1989/2810 (epoch 7), train_loss = 1.599, time/batch = 0.162\n",
            "1990/2810 (epoch 7), train_loss = 1.596, time/batch = 0.156\n",
            "1991/2810 (epoch 7), train_loss = 1.601, time/batch = 0.143\n",
            "1992/2810 (epoch 7), train_loss = 1.547, time/batch = 0.143\n",
            "1993/2810 (epoch 7), train_loss = 1.585, time/batch = 0.148\n",
            "1994/2810 (epoch 7), train_loss = 1.580, time/batch = 0.147\n",
            "1995/2810 (epoch 7), train_loss = 1.518, time/batch = 0.244\n",
            "1996/2810 (epoch 7), train_loss = 1.576, time/batch = 0.250\n",
            "1997/2810 (epoch 7), train_loss = 1.604, time/batch = 0.263\n",
            "1998/2810 (epoch 7), train_loss = 1.612, time/batch = 0.265\n",
            "1999/2810 (epoch 7), train_loss = 1.554, time/batch = 0.259\n",
            "2000/2810 (epoch 7), train_loss = 1.636, time/batch = 0.248\n",
            "Model saved to ./checkpoints/pg74571/pg74571!\n",
            "2001/2810 (epoch 7), train_loss = 1.650, time/batch = 0.275\n",
            "2002/2810 (epoch 7), train_loss = 1.581, time/batch = 0.277\n",
            "2003/2810 (epoch 7), train_loss = 1.593, time/batch = 0.293\n",
            "2004/2810 (epoch 7), train_loss = 1.608, time/batch = 0.280\n",
            "2005/2810 (epoch 7), train_loss = 1.597, time/batch = 0.183\n",
            "2006/2810 (epoch 7), train_loss = 1.604, time/batch = 0.162\n",
            "2007/2810 (epoch 7), train_loss = 1.595, time/batch = 0.143\n",
            "2008/2810 (epoch 7), train_loss = 1.533, time/batch = 0.143\n",
            "2009/2810 (epoch 7), train_loss = 1.600, time/batch = 0.151\n",
            "2010/2810 (epoch 7), train_loss = 1.626, time/batch = 0.149\n",
            "2011/2810 (epoch 7), train_loss = 1.641, time/batch = 0.152\n",
            "2012/2810 (epoch 7), train_loss = 1.581, time/batch = 0.145\n",
            "2013/2810 (epoch 7), train_loss = 1.547, time/batch = 0.167\n",
            "2014/2810 (epoch 7), train_loss = 1.546, time/batch = 0.141\n",
            "2015/2810 (epoch 7), train_loss = 1.562, time/batch = 0.149\n",
            "2016/2810 (epoch 7), train_loss = 1.581, time/batch = 0.152\n",
            "2017/2810 (epoch 7), train_loss = 1.589, time/batch = 0.150\n",
            "2018/2810 (epoch 7), train_loss = 1.596, time/batch = 0.145\n",
            "2019/2810 (epoch 7), train_loss = 1.547, time/batch = 0.158\n",
            "2020/2810 (epoch 7), train_loss = 1.600, time/batch = 0.176\n",
            "2021/2810 (epoch 7), train_loss = 1.577, time/batch = 0.159\n",
            "2022/2810 (epoch 7), train_loss = 1.551, time/batch = 0.140\n",
            "2023/2810 (epoch 7), train_loss = 1.554, time/batch = 0.149\n",
            "2024/2810 (epoch 7), train_loss = 1.589, time/batch = 0.148\n",
            "2025/2810 (epoch 7), train_loss = 1.600, time/batch = 0.152\n",
            "2026/2810 (epoch 7), train_loss = 1.488, time/batch = 0.149\n",
            "2027/2810 (epoch 7), train_loss = 1.558, time/batch = 0.170\n",
            "2028/2810 (epoch 7), train_loss = 1.559, time/batch = 0.150\n",
            "2029/2810 (epoch 7), train_loss = 1.573, time/batch = 0.160\n",
            "2030/2810 (epoch 7), train_loss = 1.583, time/batch = 0.156\n",
            "2031/2810 (epoch 7), train_loss = 1.603, time/batch = 0.156\n",
            "2032/2810 (epoch 7), train_loss = 1.581, time/batch = 0.143\n",
            "2033/2810 (epoch 7), train_loss = 1.478, time/batch = 0.153\n",
            "2034/2810 (epoch 7), train_loss = 1.563, time/batch = 0.164\n",
            "2035/2810 (epoch 7), train_loss = 1.649, time/batch = 0.144\n",
            "2036/2810 (epoch 7), train_loss = 1.597, time/batch = 0.153\n",
            "2037/2810 (epoch 7), train_loss = 1.561, time/batch = 0.149\n",
            "2038/2810 (epoch 7), train_loss = 1.601, time/batch = 0.142\n",
            "2039/2810 (epoch 7), train_loss = 1.608, time/batch = 0.149\n",
            "2040/2810 (epoch 7), train_loss = 1.582, time/batch = 0.143\n",
            "2041/2810 (epoch 7), train_loss = 1.538, time/batch = 0.165\n",
            "2042/2810 (epoch 7), train_loss = 1.565, time/batch = 0.146\n",
            "2043/2810 (epoch 7), train_loss = 1.536, time/batch = 0.140\n",
            "2044/2810 (epoch 7), train_loss = 1.537, time/batch = 0.167\n",
            "2045/2810 (epoch 7), train_loss = 1.576, time/batch = 0.156\n",
            "2046/2810 (epoch 7), train_loss = 1.627, time/batch = 0.151\n",
            "2047/2810 (epoch 7), train_loss = 1.533, time/batch = 0.132\n",
            "2048/2810 (epoch 7), train_loss = 1.543, time/batch = 0.169\n",
            "2049/2810 (epoch 7), train_loss = 1.538, time/batch = 0.148\n",
            "2050/2810 (epoch 7), train_loss = 1.528, time/batch = 0.145\n",
            "2051/2810 (epoch 7), train_loss = 1.481, time/batch = 0.149\n",
            "2052/2810 (epoch 7), train_loss = 1.533, time/batch = 0.157\n",
            "2053/2810 (epoch 7), train_loss = 1.570, time/batch = 0.143\n",
            "2054/2810 (epoch 7), train_loss = 1.614, time/batch = 0.171\n",
            "2055/2810 (epoch 7), train_loss = 1.554, time/batch = 0.144\n",
            "2056/2810 (epoch 7), train_loss = 1.575, time/batch = 0.150\n",
            "2057/2810 (epoch 7), train_loss = 1.556, time/batch = 0.137\n",
            "2058/2810 (epoch 7), train_loss = 1.599, time/batch = 0.160\n",
            "2059/2810 (epoch 7), train_loss = 1.590, time/batch = 0.150\n",
            "2060/2810 (epoch 7), train_loss = 1.667, time/batch = 0.151\n",
            "2061/2810 (epoch 7), train_loss = 1.572, time/batch = 0.170\n",
            "2062/2810 (epoch 7), train_loss = 1.600, time/batch = 0.153\n",
            "2063/2810 (epoch 7), train_loss = 1.611, time/batch = 0.147\n",
            "2064/2810 (epoch 7), train_loss = 1.507, time/batch = 0.162\n",
            "2065/2810 (epoch 7), train_loss = 1.491, time/batch = 0.161\n",
            "2066/2810 (epoch 7), train_loss = 1.540, time/batch = 0.159\n",
            "2067/2810 (epoch 7), train_loss = 1.533, time/batch = 0.144\n",
            "2068/2810 (epoch 7), train_loss = 1.587, time/batch = 0.162\n",
            "2069/2810 (epoch 7), train_loss = 1.643, time/batch = 0.155\n",
            "2070/2810 (epoch 7), train_loss = 1.578, time/batch = 0.166\n",
            "2071/2810 (epoch 7), train_loss = 1.516, time/batch = 0.250\n",
            "2072/2810 (epoch 7), train_loss = 1.502, time/batch = 0.263\n",
            "2073/2810 (epoch 7), train_loss = 1.556, time/batch = 0.285\n",
            "2074/2810 (epoch 7), train_loss = 1.609, time/batch = 0.276\n",
            "2075/2810 (epoch 7), train_loss = 1.595, time/batch = 0.268\n",
            "2076/2810 (epoch 7), train_loss = 1.546, time/batch = 0.269\n",
            "2077/2810 (epoch 7), train_loss = 1.593, time/batch = 0.268\n",
            "2078/2810 (epoch 7), train_loss = 1.495, time/batch = 0.264\n",
            "2079/2810 (epoch 7), train_loss = 1.535, time/batch = 0.248\n",
            "2080/2810 (epoch 7), train_loss = 1.602, time/batch = 0.287\n",
            "2081/2810 (epoch 7), train_loss = 1.599, time/batch = 0.262\n",
            "2082/2810 (epoch 7), train_loss = 1.597, time/batch = 0.253\n",
            "2083/2810 (epoch 7), train_loss = 1.588, time/batch = 0.246\n",
            "2084/2810 (epoch 7), train_loss = 1.528, time/batch = 0.148\n",
            "2085/2810 (epoch 7), train_loss = 1.557, time/batch = 0.154\n",
            "2086/2810 (epoch 7), train_loss = 1.606, time/batch = 0.164\n",
            "2087/2810 (epoch 7), train_loss = 1.569, time/batch = 0.161\n",
            "2088/2810 (epoch 7), train_loss = 1.558, time/batch = 0.159\n",
            "2089/2810 (epoch 7), train_loss = 1.564, time/batch = 0.151\n",
            "2090/2810 (epoch 7), train_loss = 1.581, time/batch = 0.145\n",
            "2091/2810 (epoch 7), train_loss = 1.539, time/batch = 0.148\n",
            "2092/2810 (epoch 7), train_loss = 1.508, time/batch = 0.143\n",
            "2093/2810 (epoch 7), train_loss = 1.538, time/batch = 0.165\n",
            "2094/2810 (epoch 7), train_loss = 1.565, time/batch = 0.154\n",
            "2095/2810 (epoch 7), train_loss = 1.617, time/batch = 0.153\n",
            "2096/2810 (epoch 7), train_loss = 1.557, time/batch = 0.152\n",
            "2097/2810 (epoch 7), train_loss = 1.563, time/batch = 0.151\n",
            "2098/2810 (epoch 7), train_loss = 1.536, time/batch = 0.142\n",
            "2099/2810 (epoch 7), train_loss = 1.573, time/batch = 0.178\n",
            "2100/2810 (epoch 7), train_loss = 1.590, time/batch = 0.153\n",
            "2101/2810 (epoch 7), train_loss = 1.563, time/batch = 0.153\n",
            "2102/2810 (epoch 7), train_loss = 1.567, time/batch = 0.148\n",
            "2103/2810 (epoch 7), train_loss = 1.641, time/batch = 0.142\n",
            "2104/2810 (epoch 7), train_loss = 1.620, time/batch = 0.156\n",
            "2105/2810 (epoch 7), train_loss = 1.590, time/batch = 0.148\n",
            "2106/2810 (epoch 7), train_loss = 1.613, time/batch = 0.161\n",
            "2107/2810 (epoch 7), train_loss = 1.619, time/batch = 0.151\n",
            "2108/2810 (epoch 7), train_loss = 1.595, time/batch = 0.161\n",
            "2109/2810 (epoch 7), train_loss = 1.664, time/batch = 0.150\n",
            "2110/2810 (epoch 7), train_loss = 1.639, time/batch = 0.152\n",
            "2111/2810 (epoch 7), train_loss = 1.552, time/batch = 0.145\n",
            "2112/2810 (epoch 7), train_loss = 1.544, time/batch = 0.150\n",
            "2113/2810 (epoch 7), train_loss = 1.596, time/batch = 0.143\n",
            "2114/2810 (epoch 7), train_loss = 1.600, time/batch = 0.147\n",
            "2115/2810 (epoch 7), train_loss = 1.624, time/batch = 0.149\n",
            "2116/2810 (epoch 7), train_loss = 1.588, time/batch = 0.184\n",
            "2117/2810 (epoch 7), train_loss = 1.611, time/batch = 0.140\n",
            "2118/2810 (epoch 7), train_loss = 1.554, time/batch = 0.155\n",
            "2119/2810 (epoch 7), train_loss = 1.603, time/batch = 0.146\n",
            "2120/2810 (epoch 7), train_loss = 1.624, time/batch = 0.183\n",
            "2121/2810 (epoch 7), train_loss = 1.535, time/batch = 0.163\n",
            "2122/2810 (epoch 7), train_loss = 1.585, time/batch = 0.166\n",
            "2123/2810 (epoch 7), train_loss = 1.625, time/batch = 0.149\n",
            "2124/2810 (epoch 7), train_loss = 1.516, time/batch = 0.158\n",
            "2125/2810 (epoch 7), train_loss = 1.564, time/batch = 0.149\n",
            "2126/2810 (epoch 7), train_loss = 1.577, time/batch = 0.175\n",
            "2127/2810 (epoch 7), train_loss = 1.610, time/batch = 0.149\n",
            "2128/2810 (epoch 7), train_loss = 1.657, time/batch = 0.151\n",
            "2129/2810 (epoch 7), train_loss = 1.596, time/batch = 0.140\n",
            "2130/2810 (epoch 7), train_loss = 1.573, time/batch = 0.142\n",
            "2131/2810 (epoch 7), train_loss = 1.596, time/batch = 0.156\n",
            "2132/2810 (epoch 7), train_loss = 1.526, time/batch = 0.142\n",
            "2133/2810 (epoch 7), train_loss = 1.593, time/batch = 0.163\n",
            "2134/2810 (epoch 7), train_loss = 1.577, time/batch = 0.147\n",
            "2135/2810 (epoch 7), train_loss = 1.527, time/batch = 0.140\n",
            "2136/2810 (epoch 7), train_loss = 1.562, time/batch = 0.168\n",
            "2137/2810 (epoch 7), train_loss = 1.600, time/batch = 0.164\n",
            "2138/2810 (epoch 7), train_loss = 1.541, time/batch = 0.166\n",
            "2139/2810 (epoch 7), train_loss = 1.490, time/batch = 0.150\n",
            "2140/2810 (epoch 7), train_loss = 1.661, time/batch = 0.158\n",
            "2141/2810 (epoch 7), train_loss = 1.581, time/batch = 0.155\n",
            "2142/2810 (epoch 7), train_loss = 1.552, time/batch = 0.171\n",
            "2143/2810 (epoch 7), train_loss = 1.548, time/batch = 0.162\n",
            "2144/2810 (epoch 7), train_loss = 1.561, time/batch = 0.175\n",
            "2145/2810 (epoch 7), train_loss = 1.587, time/batch = 0.161\n",
            "2146/2810 (epoch 7), train_loss = 1.597, time/batch = 0.172\n",
            "2147/2810 (epoch 7), train_loss = 1.477, time/batch = 0.173\n",
            "2148/2810 (epoch 7), train_loss = 1.559, time/batch = 0.266\n",
            "2149/2810 (epoch 7), train_loss = 1.585, time/batch = 0.282\n",
            "2150/2810 (epoch 7), train_loss = 1.562, time/batch = 0.304\n",
            "2151/2810 (epoch 7), train_loss = 1.605, time/batch = 0.298\n",
            "2152/2810 (epoch 7), train_loss = 1.517, time/batch = 0.281\n",
            "2153/2810 (epoch 7), train_loss = 1.572, time/batch = 0.269\n",
            "2154/2810 (epoch 7), train_loss = 1.536, time/batch = 0.281\n",
            "2155/2810 (epoch 7), train_loss = 1.610, time/batch = 0.246\n",
            "2156/2810 (epoch 7), train_loss = 1.543, time/batch = 0.290\n",
            "2157/2810 (epoch 7), train_loss = 1.586, time/batch = 0.269\n",
            "2158/2810 (epoch 7), train_loss = 1.598, time/batch = 0.296\n",
            "2159/2810 (epoch 7), train_loss = 1.630, time/batch = 0.257\n",
            "2160/2810 (epoch 7), train_loss = 1.528, time/batch = 0.163\n",
            "2161/2810 (epoch 7), train_loss = 1.575, time/batch = 0.155\n",
            "2162/2810 (epoch 7), train_loss = 1.515, time/batch = 0.159\n",
            "2163/2810 (epoch 7), train_loss = 1.619, time/batch = 0.176\n",
            "2164/2810 (epoch 7), train_loss = 1.486, time/batch = 0.157\n",
            "2165/2810 (epoch 7), train_loss = 1.603, time/batch = 0.150\n",
            "2166/2810 (epoch 7), train_loss = 1.515, time/batch = 0.156\n",
            "2167/2810 (epoch 7), train_loss = 1.599, time/batch = 0.153\n",
            "2168/2810 (epoch 7), train_loss = 1.549, time/batch = 0.149\n",
            "2169/2810 (epoch 7), train_loss = 1.566, time/batch = 0.142\n",
            "2170/2810 (epoch 7), train_loss = 1.610, time/batch = 0.168\n",
            "2171/2810 (epoch 7), train_loss = 1.554, time/batch = 0.154\n",
            "2172/2810 (epoch 7), train_loss = 1.565, time/batch = 0.146\n",
            "2173/2810 (epoch 7), train_loss = 1.557, time/batch = 0.151\n",
            "2174/2810 (epoch 7), train_loss = 1.472, time/batch = 0.153\n",
            "2175/2810 (epoch 7), train_loss = 1.545, time/batch = 0.152\n",
            "2176/2810 (epoch 7), train_loss = 1.520, time/batch = 0.140\n",
            "2177/2810 (epoch 7), train_loss = 1.609, time/batch = 0.163\n",
            "2178/2810 (epoch 7), train_loss = 1.599, time/batch = 0.154\n",
            "2179/2810 (epoch 7), train_loss = 1.545, time/batch = 0.162\n",
            "2180/2810 (epoch 7), train_loss = 1.582, time/batch = 0.159\n",
            "2181/2810 (epoch 7), train_loss = 1.578, time/batch = 0.160\n",
            "2182/2810 (epoch 7), train_loss = 1.564, time/batch = 0.154\n",
            "2183/2810 (epoch 7), train_loss = 1.524, time/batch = 0.177\n",
            "2184/2810 (epoch 7), train_loss = 1.608, time/batch = 0.151\n",
            "2185/2810 (epoch 7), train_loss = 1.580, time/batch = 0.146\n",
            "2186/2810 (epoch 7), train_loss = 1.588, time/batch = 0.142\n",
            "2187/2810 (epoch 7), train_loss = 1.545, time/batch = 0.148\n",
            "2188/2810 (epoch 7), train_loss = 1.516, time/batch = 0.141\n",
            "2189/2810 (epoch 7), train_loss = 1.563, time/batch = 0.159\n",
            "2190/2810 (epoch 7), train_loss = 1.529, time/batch = 0.165\n",
            "2191/2810 (epoch 7), train_loss = 1.489, time/batch = 0.155\n",
            "2192/2810 (epoch 7), train_loss = 1.568, time/batch = 0.152\n",
            "2193/2810 (epoch 7), train_loss = 1.541, time/batch = 0.156\n",
            "2194/2810 (epoch 7), train_loss = 1.565, time/batch = 0.150\n",
            "2195/2810 (epoch 7), train_loss = 1.542, time/batch = 0.142\n",
            "2196/2810 (epoch 7), train_loss = 1.601, time/batch = 0.147\n",
            "2197/2810 (epoch 7), train_loss = 1.556, time/batch = 0.176\n",
            "2198/2810 (epoch 7), train_loss = 1.575, time/batch = 0.139\n",
            "2199/2810 (epoch 7), train_loss = 1.587, time/batch = 0.163\n",
            "2200/2810 (epoch 7), train_loss = 1.537, time/batch = 0.158\n",
            "2201/2810 (epoch 7), train_loss = 1.598, time/batch = 0.156\n",
            "2202/2810 (epoch 7), train_loss = 1.513, time/batch = 0.148\n",
            "2203/2810 (epoch 7), train_loss = 1.568, time/batch = 0.151\n",
            "2204/2810 (epoch 7), train_loss = 1.590, time/batch = 0.171\n",
            "2205/2810 (epoch 7), train_loss = 1.577, time/batch = 0.148\n",
            "2206/2810 (epoch 7), train_loss = 1.576, time/batch = 0.148\n",
            "2207/2810 (epoch 7), train_loss = 1.562, time/batch = 0.159\n",
            "2208/2810 (epoch 7), train_loss = 1.669, time/batch = 0.144\n",
            "2209/2810 (epoch 7), train_loss = 1.542, time/batch = 0.163\n",
            "2210/2810 (epoch 7), train_loss = 1.611, time/batch = 0.176\n",
            "2211/2810 (epoch 7), train_loss = 1.590, time/batch = 0.161\n",
            "2212/2810 (epoch 7), train_loss = 1.593, time/batch = 0.167\n",
            "2213/2810 (epoch 7), train_loss = 1.519, time/batch = 0.176\n",
            "2214/2810 (epoch 7), train_loss = 1.571, time/batch = 0.151\n",
            "2215/2810 (epoch 7), train_loss = 1.532, time/batch = 0.168\n",
            "2216/2810 (epoch 7), train_loss = 1.585, time/batch = 0.154\n",
            "2217/2810 (epoch 7), train_loss = 1.520, time/batch = 0.186\n",
            "2218/2810 (epoch 7), train_loss = 1.592, time/batch = 0.165\n",
            "2219/2810 (epoch 7), train_loss = 1.598, time/batch = 0.172\n",
            "2220/2810 (epoch 7), train_loss = 1.537, time/batch = 0.148\n",
            "2221/2810 (epoch 7), train_loss = 1.547, time/batch = 0.156\n",
            "2222/2810 (epoch 7), train_loss = 1.549, time/batch = 0.149\n",
            "2223/2810 (epoch 7), train_loss = 1.540, time/batch = 0.195\n",
            "2224/2810 (epoch 7), train_loss = 1.529, time/batch = 0.245\n",
            "2225/2810 (epoch 7), train_loss = 1.543, time/batch = 0.244\n",
            "2226/2810 (epoch 7), train_loss = 1.599, time/batch = 0.276\n",
            "2227/2810 (epoch 7), train_loss = 1.541, time/batch = 0.282\n",
            "2228/2810 (epoch 7), train_loss = 1.542, time/batch = 0.243\n",
            "2229/2810 (epoch 7), train_loss = 1.465, time/batch = 0.273\n",
            "2230/2810 (epoch 7), train_loss = 1.557, time/batch = 0.264\n",
            "2231/2810 (epoch 7), train_loss = 1.600, time/batch = 0.283\n",
            "2232/2810 (epoch 7), train_loss = 1.599, time/batch = 0.282\n",
            "2233/2810 (epoch 7), train_loss = 1.554, time/batch = 0.256\n",
            "2234/2810 (epoch 7), train_loss = 1.584, time/batch = 0.280\n",
            "2235/2810 (epoch 7), train_loss = 1.573, time/batch = 0.279\n",
            "2236/2810 (epoch 7), train_loss = 1.575, time/batch = 0.210\n",
            "2237/2810 (epoch 7), train_loss = 1.574, time/batch = 0.150\n",
            "2238/2810 (epoch 7), train_loss = 1.542, time/batch = 0.144\n",
            "2239/2810 (epoch 7), train_loss = 1.525, time/batch = 0.150\n",
            "2240/2810 (epoch 7), train_loss = 1.572, time/batch = 0.151\n",
            "2241/2810 (epoch 7), train_loss = 1.627, time/batch = 0.161\n",
            "2242/2810 (epoch 7), train_loss = 1.584, time/batch = 0.154\n",
            "2243/2810 (epoch 7), train_loss = 1.581, time/batch = 0.148\n",
            "2244/2810 (epoch 7), train_loss = 1.558, time/batch = 0.145\n",
            "2245/2810 (epoch 7), train_loss = 1.512, time/batch = 0.150\n",
            "2246/2810 (epoch 7), train_loss = 1.550, time/batch = 0.150\n",
            "2247/2810 (epoch 7), train_loss = 1.574, time/batch = 0.159\n",
            "2248/2810 (epoch 8), train_loss = 1.570, time/batch = 0.161\n",
            "2249/2810 (epoch 8), train_loss = 1.589, time/batch = 0.149\n",
            "2250/2810 (epoch 8), train_loss = 1.583, time/batch = 0.155\n",
            "2251/2810 (epoch 8), train_loss = 1.585, time/batch = 0.142\n",
            "2252/2810 (epoch 8), train_loss = 1.475, time/batch = 0.154\n",
            "2253/2810 (epoch 8), train_loss = 1.590, time/batch = 0.144\n",
            "2254/2810 (epoch 8), train_loss = 1.530, time/batch = 0.171\n",
            "2255/2810 (epoch 8), train_loss = 1.531, time/batch = 0.146\n",
            "2256/2810 (epoch 8), train_loss = 1.621, time/batch = 0.141\n",
            "2257/2810 (epoch 8), train_loss = 1.507, time/batch = 0.148\n",
            "2258/2810 (epoch 8), train_loss = 1.589, time/batch = 0.151\n",
            "2259/2810 (epoch 8), train_loss = 1.563, time/batch = 0.157\n",
            "2260/2810 (epoch 8), train_loss = 1.532, time/batch = 0.155\n",
            "2261/2810 (epoch 8), train_loss = 1.563, time/batch = 0.168\n",
            "2262/2810 (epoch 8), train_loss = 1.605, time/batch = 0.172\n",
            "2263/2810 (epoch 8), train_loss = 1.582, time/batch = 0.156\n",
            "2264/2810 (epoch 8), train_loss = 1.516, time/batch = 0.161\n",
            "2265/2810 (epoch 8), train_loss = 1.660, time/batch = 0.160\n",
            "2266/2810 (epoch 8), train_loss = 1.562, time/batch = 0.163\n",
            "2267/2810 (epoch 8), train_loss = 1.603, time/batch = 0.171\n",
            "2268/2810 (epoch 8), train_loss = 1.564, time/batch = 0.151\n",
            "2269/2810 (epoch 8), train_loss = 1.611, time/batch = 0.149\n",
            "2270/2810 (epoch 8), train_loss = 1.562, time/batch = 0.141\n",
            "2271/2810 (epoch 8), train_loss = 1.562, time/batch = 0.152\n",
            "2272/2810 (epoch 8), train_loss = 1.568, time/batch = 0.155\n",
            "2273/2810 (epoch 8), train_loss = 1.513, time/batch = 0.144\n",
            "2274/2810 (epoch 8), train_loss = 1.549, time/batch = 0.173\n",
            "2275/2810 (epoch 8), train_loss = 1.546, time/batch = 0.150\n",
            "2276/2810 (epoch 8), train_loss = 1.484, time/batch = 0.160\n",
            "2277/2810 (epoch 8), train_loss = 1.537, time/batch = 0.177\n",
            "2278/2810 (epoch 8), train_loss = 1.567, time/batch = 0.159\n",
            "2279/2810 (epoch 8), train_loss = 1.572, time/batch = 0.151\n",
            "2280/2810 (epoch 8), train_loss = 1.519, time/batch = 0.170\n",
            "2281/2810 (epoch 8), train_loss = 1.601, time/batch = 0.152\n",
            "2282/2810 (epoch 8), train_loss = 1.617, time/batch = 0.144\n",
            "2283/2810 (epoch 8), train_loss = 1.544, time/batch = 0.139\n",
            "2284/2810 (epoch 8), train_loss = 1.559, time/batch = 0.156\n",
            "2285/2810 (epoch 8), train_loss = 1.576, time/batch = 0.148\n",
            "2286/2810 (epoch 8), train_loss = 1.565, time/batch = 0.133\n",
            "2287/2810 (epoch 8), train_loss = 1.571, time/batch = 0.162\n",
            "2288/2810 (epoch 8), train_loss = 1.561, time/batch = 0.136\n",
            "2289/2810 (epoch 8), train_loss = 1.497, time/batch = 0.147\n",
            "2290/2810 (epoch 8), train_loss = 1.564, time/batch = 0.140\n",
            "2291/2810 (epoch 8), train_loss = 1.588, time/batch = 0.161\n",
            "2292/2810 (epoch 8), train_loss = 1.610, time/batch = 0.176\n",
            "2293/2810 (epoch 8), train_loss = 1.544, time/batch = 0.158\n",
            "2294/2810 (epoch 8), train_loss = 1.515, time/batch = 0.162\n",
            "2295/2810 (epoch 8), train_loss = 1.512, time/batch = 0.140\n",
            "2296/2810 (epoch 8), train_loss = 1.528, time/batch = 0.158\n",
            "2297/2810 (epoch 8), train_loss = 1.548, time/batch = 0.160\n",
            "2298/2810 (epoch 8), train_loss = 1.555, time/batch = 0.140\n",
            "2299/2810 (epoch 8), train_loss = 1.561, time/batch = 0.151\n",
            "2300/2810 (epoch 8), train_loss = 1.508, time/batch = 0.210\n",
            "2301/2810 (epoch 8), train_loss = 1.564, time/batch = 0.238\n",
            "2302/2810 (epoch 8), train_loss = 1.543, time/batch = 0.256\n",
            "2303/2810 (epoch 8), train_loss = 1.517, time/batch = 0.252\n",
            "2304/2810 (epoch 8), train_loss = 1.515, time/batch = 0.253\n",
            "2305/2810 (epoch 8), train_loss = 1.554, time/batch = 0.240\n",
            "2306/2810 (epoch 8), train_loss = 1.565, time/batch = 0.269\n",
            "2307/2810 (epoch 8), train_loss = 1.451, time/batch = 0.268\n",
            "2308/2810 (epoch 8), train_loss = 1.524, time/batch = 0.244\n",
            "2309/2810 (epoch 8), train_loss = 1.523, time/batch = 0.265\n",
            "2310/2810 (epoch 8), train_loss = 1.538, time/batch = 0.276\n",
            "2311/2810 (epoch 8), train_loss = 1.545, time/batch = 0.262\n",
            "2312/2810 (epoch 8), train_loss = 1.564, time/batch = 0.278\n",
            "2313/2810 (epoch 8), train_loss = 1.544, time/batch = 0.197\n",
            "2314/2810 (epoch 8), train_loss = 1.439, time/batch = 0.146\n",
            "2315/2810 (epoch 8), train_loss = 1.523, time/batch = 0.151\n",
            "2316/2810 (epoch 8), train_loss = 1.614, time/batch = 0.152\n",
            "2317/2810 (epoch 8), train_loss = 1.564, time/batch = 0.151\n",
            "2318/2810 (epoch 8), train_loss = 1.524, time/batch = 0.151\n",
            "2319/2810 (epoch 8), train_loss = 1.564, time/batch = 0.176\n",
            "2320/2810 (epoch 8), train_loss = 1.575, time/batch = 0.169\n",
            "2321/2810 (epoch 8), train_loss = 1.544, time/batch = 0.142\n",
            "2322/2810 (epoch 8), train_loss = 1.502, time/batch = 0.153\n",
            "2323/2810 (epoch 8), train_loss = 1.532, time/batch = 0.164\n",
            "2324/2810 (epoch 8), train_loss = 1.504, time/batch = 0.145\n",
            "2325/2810 (epoch 8), train_loss = 1.503, time/batch = 0.163\n",
            "2326/2810 (epoch 8), train_loss = 1.535, time/batch = 0.165\n",
            "2327/2810 (epoch 8), train_loss = 1.594, time/batch = 0.150\n",
            "2328/2810 (epoch 8), train_loss = 1.499, time/batch = 0.137\n",
            "2329/2810 (epoch 8), train_loss = 1.513, time/batch = 0.146\n",
            "2330/2810 (epoch 8), train_loss = 1.502, time/batch = 0.140\n",
            "2331/2810 (epoch 8), train_loss = 1.493, time/batch = 0.142\n",
            "2332/2810 (epoch 8), train_loss = 1.449, time/batch = 0.152\n",
            "2333/2810 (epoch 8), train_loss = 1.499, time/batch = 0.169\n",
            "2334/2810 (epoch 8), train_loss = 1.537, time/batch = 0.157\n",
            "2335/2810 (epoch 8), train_loss = 1.579, time/batch = 0.155\n",
            "2336/2810 (epoch 8), train_loss = 1.521, time/batch = 0.175\n",
            "2337/2810 (epoch 8), train_loss = 1.543, time/batch = 0.137\n",
            "2338/2810 (epoch 8), train_loss = 1.520, time/batch = 0.142\n",
            "2339/2810 (epoch 8), train_loss = 1.568, time/batch = 0.151\n",
            "2340/2810 (epoch 8), train_loss = 1.556, time/batch = 0.154\n",
            "2341/2810 (epoch 8), train_loss = 1.631, time/batch = 0.153\n",
            "2342/2810 (epoch 8), train_loss = 1.535, time/batch = 0.136\n",
            "2343/2810 (epoch 8), train_loss = 1.564, time/batch = 0.158\n",
            "2344/2810 (epoch 8), train_loss = 1.579, time/batch = 0.136\n",
            "2345/2810 (epoch 8), train_loss = 1.476, time/batch = 0.155\n",
            "2346/2810 (epoch 8), train_loss = 1.458, time/batch = 0.145\n",
            "2347/2810 (epoch 8), train_loss = 1.507, time/batch = 0.158\n",
            "2348/2810 (epoch 8), train_loss = 1.498, time/batch = 0.147\n",
            "2349/2810 (epoch 8), train_loss = 1.556, time/batch = 0.146\n",
            "2350/2810 (epoch 8), train_loss = 1.611, time/batch = 0.151\n",
            "2351/2810 (epoch 8), train_loss = 1.546, time/batch = 0.158\n",
            "2352/2810 (epoch 8), train_loss = 1.485, time/batch = 0.148\n",
            "2353/2810 (epoch 8), train_loss = 1.473, time/batch = 0.164\n",
            "2354/2810 (epoch 8), train_loss = 1.524, time/batch = 0.142\n",
            "2355/2810 (epoch 8), train_loss = 1.575, time/batch = 0.142\n",
            "2356/2810 (epoch 8), train_loss = 1.560, time/batch = 0.141\n",
            "2357/2810 (epoch 8), train_loss = 1.512, time/batch = 0.134\n",
            "2358/2810 (epoch 8), train_loss = 1.559, time/batch = 0.139\n",
            "2359/2810 (epoch 8), train_loss = 1.464, time/batch = 0.143\n",
            "2360/2810 (epoch 8), train_loss = 1.506, time/batch = 0.125\n",
            "2361/2810 (epoch 8), train_loss = 1.571, time/batch = 0.152\n",
            "2362/2810 (epoch 8), train_loss = 1.565, time/batch = 0.141\n",
            "2363/2810 (epoch 8), train_loss = 1.568, time/batch = 0.150\n",
            "2364/2810 (epoch 8), train_loss = 1.561, time/batch = 0.145\n",
            "2365/2810 (epoch 8), train_loss = 1.495, time/batch = 0.156\n",
            "2366/2810 (epoch 8), train_loss = 1.526, time/batch = 0.144\n",
            "2367/2810 (epoch 8), train_loss = 1.570, time/batch = 0.151\n",
            "2368/2810 (epoch 8), train_loss = 1.540, time/batch = 0.163\n",
            "2369/2810 (epoch 8), train_loss = 1.531, time/batch = 0.148\n",
            "2370/2810 (epoch 8), train_loss = 1.530, time/batch = 0.153\n",
            "2371/2810 (epoch 8), train_loss = 1.546, time/batch = 0.157\n",
            "2372/2810 (epoch 8), train_loss = 1.504, time/batch = 0.144\n",
            "2373/2810 (epoch 8), train_loss = 1.475, time/batch = 0.142\n",
            "2374/2810 (epoch 8), train_loss = 1.506, time/batch = 0.135\n",
            "2375/2810 (epoch 8), train_loss = 1.535, time/batch = 0.165\n",
            "2376/2810 (epoch 8), train_loss = 1.583, time/batch = 0.139\n",
            "2377/2810 (epoch 8), train_loss = 1.527, time/batch = 0.164\n",
            "2378/2810 (epoch 8), train_loss = 1.530, time/batch = 0.141\n",
            "2379/2810 (epoch 8), train_loss = 1.502, time/batch = 0.167\n",
            "2380/2810 (epoch 8), train_loss = 1.540, time/batch = 0.240\n",
            "2381/2810 (epoch 8), train_loss = 1.557, time/batch = 0.254\n",
            "2382/2810 (epoch 8), train_loss = 1.534, time/batch = 0.244\n",
            "2383/2810 (epoch 8), train_loss = 1.534, time/batch = 0.244\n",
            "2384/2810 (epoch 8), train_loss = 1.603, time/batch = 0.259\n",
            "2385/2810 (epoch 8), train_loss = 1.587, time/batch = 0.271\n",
            "2386/2810 (epoch 8), train_loss = 1.558, time/batch = 0.266\n",
            "2387/2810 (epoch 8), train_loss = 1.583, time/batch = 0.249\n",
            "2388/2810 (epoch 8), train_loss = 1.587, time/batch = 0.247\n",
            "2389/2810 (epoch 8), train_loss = 1.563, time/batch = 0.261\n",
            "2390/2810 (epoch 8), train_loss = 1.629, time/batch = 0.276\n",
            "2391/2810 (epoch 8), train_loss = 1.603, time/batch = 0.273\n",
            "2392/2810 (epoch 8), train_loss = 1.522, time/batch = 0.233\n",
            "2393/2810 (epoch 8), train_loss = 1.515, time/batch = 0.161\n",
            "2394/2810 (epoch 8), train_loss = 1.564, time/batch = 0.160\n",
            "2395/2810 (epoch 8), train_loss = 1.564, time/batch = 0.151\n",
            "2396/2810 (epoch 8), train_loss = 1.592, time/batch = 0.152\n",
            "2397/2810 (epoch 8), train_loss = 1.558, time/batch = 0.139\n",
            "2398/2810 (epoch 8), train_loss = 1.578, time/batch = 0.158\n",
            "2399/2810 (epoch 8), train_loss = 1.523, time/batch = 0.149\n",
            "2400/2810 (epoch 8), train_loss = 1.570, time/batch = 0.160\n",
            "2401/2810 (epoch 8), train_loss = 1.591, time/batch = 0.153\n",
            "2402/2810 (epoch 8), train_loss = 1.500, time/batch = 0.148\n",
            "2403/2810 (epoch 8), train_loss = 1.555, time/batch = 0.149\n",
            "2404/2810 (epoch 8), train_loss = 1.592, time/batch = 0.154\n",
            "2405/2810 (epoch 8), train_loss = 1.482, time/batch = 0.139\n",
            "2406/2810 (epoch 8), train_loss = 1.534, time/batch = 0.149\n",
            "2407/2810 (epoch 8), train_loss = 1.542, time/batch = 0.163\n",
            "2408/2810 (epoch 8), train_loss = 1.583, time/batch = 0.160\n",
            "2409/2810 (epoch 8), train_loss = 1.626, time/batch = 0.146\n",
            "2410/2810 (epoch 8), train_loss = 1.562, time/batch = 0.154\n",
            "2411/2810 (epoch 8), train_loss = 1.540, time/batch = 0.150\n",
            "2412/2810 (epoch 8), train_loss = 1.567, time/batch = 0.155\n",
            "2413/2810 (epoch 8), train_loss = 1.495, time/batch = 0.136\n",
            "2414/2810 (epoch 8), train_loss = 1.562, time/batch = 0.173\n",
            "2415/2810 (epoch 8), train_loss = 1.545, time/batch = 0.136\n",
            "2416/2810 (epoch 8), train_loss = 1.497, time/batch = 0.147\n",
            "2417/2810 (epoch 8), train_loss = 1.531, time/batch = 0.146\n",
            "2418/2810 (epoch 8), train_loss = 1.568, time/batch = 0.145\n",
            "2419/2810 (epoch 8), train_loss = 1.510, time/batch = 0.148\n",
            "2420/2810 (epoch 8), train_loss = 1.461, time/batch = 0.162\n",
            "2421/2810 (epoch 8), train_loss = 1.633, time/batch = 0.159\n",
            "2422/2810 (epoch 8), train_loss = 1.548, time/batch = 0.152\n",
            "2423/2810 (epoch 8), train_loss = 1.518, time/batch = 0.156\n",
            "2424/2810 (epoch 8), train_loss = 1.518, time/batch = 0.149\n",
            "2425/2810 (epoch 8), train_loss = 1.534, time/batch = 0.146\n",
            "2426/2810 (epoch 8), train_loss = 1.551, time/batch = 0.158\n",
            "2427/2810 (epoch 8), train_loss = 1.564, time/batch = 0.161\n",
            "2428/2810 (epoch 8), train_loss = 1.443, time/batch = 0.153\n",
            "2429/2810 (epoch 8), train_loss = 1.524, time/batch = 0.154\n",
            "2430/2810 (epoch 8), train_loss = 1.552, time/batch = 0.155\n",
            "2431/2810 (epoch 8), train_loss = 1.530, time/batch = 0.159\n",
            "2432/2810 (epoch 8), train_loss = 1.573, time/batch = 0.153\n",
            "2433/2810 (epoch 8), train_loss = 1.486, time/batch = 0.156\n",
            "2434/2810 (epoch 8), train_loss = 1.544, time/batch = 0.164\n",
            "2435/2810 (epoch 8), train_loss = 1.504, time/batch = 0.155\n",
            "2436/2810 (epoch 8), train_loss = 1.575, time/batch = 0.142\n",
            "2437/2810 (epoch 8), train_loss = 1.510, time/batch = 0.161\n",
            "2438/2810 (epoch 8), train_loss = 1.552, time/batch = 0.158\n",
            "2439/2810 (epoch 8), train_loss = 1.565, time/batch = 0.158\n",
            "2440/2810 (epoch 8), train_loss = 1.597, time/batch = 0.162\n",
            "2441/2810 (epoch 8), train_loss = 1.497, time/batch = 0.159\n",
            "2442/2810 (epoch 8), train_loss = 1.544, time/batch = 0.157\n",
            "2443/2810 (epoch 8), train_loss = 1.485, time/batch = 0.151\n",
            "2444/2810 (epoch 8), train_loss = 1.584, time/batch = 0.155\n",
            "2445/2810 (epoch 8), train_loss = 1.456, time/batch = 0.160\n",
            "2446/2810 (epoch 8), train_loss = 1.570, time/batch = 0.157\n",
            "2447/2810 (epoch 8), train_loss = 1.483, time/batch = 0.164\n",
            "2448/2810 (epoch 8), train_loss = 1.567, time/batch = 0.155\n",
            "2449/2810 (epoch 8), train_loss = 1.518, time/batch = 0.153\n",
            "2450/2810 (epoch 8), train_loss = 1.536, time/batch = 0.143\n",
            "2451/2810 (epoch 8), train_loss = 1.583, time/batch = 0.167\n",
            "2452/2810 (epoch 8), train_loss = 1.520, time/batch = 0.145\n",
            "2453/2810 (epoch 8), train_loss = 1.531, time/batch = 0.150\n",
            "2454/2810 (epoch 8), train_loss = 1.529, time/batch = 0.163\n",
            "2455/2810 (epoch 8), train_loss = 1.444, time/batch = 0.155\n",
            "2456/2810 (epoch 8), train_loss = 1.515, time/batch = 0.143\n",
            "2457/2810 (epoch 8), train_loss = 1.489, time/batch = 0.146\n",
            "2458/2810 (epoch 8), train_loss = 1.580, time/batch = 0.258\n",
            "2459/2810 (epoch 8), train_loss = 1.568, time/batch = 0.268\n",
            "2460/2810 (epoch 8), train_loss = 1.514, time/batch = 0.285\n",
            "2461/2810 (epoch 8), train_loss = 1.547, time/batch = 0.264\n",
            "2462/2810 (epoch 8), train_loss = 1.549, time/batch = 0.261\n",
            "2463/2810 (epoch 8), train_loss = 1.533, time/batch = 0.279\n",
            "2464/2810 (epoch 8), train_loss = 1.494, time/batch = 0.253\n",
            "2465/2810 (epoch 8), train_loss = 1.576, time/batch = 0.244\n",
            "2466/2810 (epoch 8), train_loss = 1.546, time/batch = 0.243\n",
            "2467/2810 (epoch 8), train_loss = 1.554, time/batch = 0.310\n",
            "2468/2810 (epoch 8), train_loss = 1.517, time/batch = 0.307\n",
            "2469/2810 (epoch 8), train_loss = 1.486, time/batch = 0.275\n",
            "2470/2810 (epoch 8), train_loss = 1.532, time/batch = 0.202\n",
            "2471/2810 (epoch 8), train_loss = 1.493, time/batch = 0.147\n",
            "2472/2810 (epoch 8), train_loss = 1.457, time/batch = 0.162\n",
            "2473/2810 (epoch 8), train_loss = 1.536, time/batch = 0.150\n",
            "2474/2810 (epoch 8), train_loss = 1.508, time/batch = 0.149\n",
            "2475/2810 (epoch 8), train_loss = 1.533, time/batch = 0.155\n",
            "2476/2810 (epoch 8), train_loss = 1.509, time/batch = 0.160\n",
            "2477/2810 (epoch 8), train_loss = 1.572, time/batch = 0.148\n",
            "2478/2810 (epoch 8), train_loss = 1.526, time/batch = 0.151\n",
            "2479/2810 (epoch 8), train_loss = 1.547, time/batch = 0.160\n",
            "2480/2810 (epoch 8), train_loss = 1.554, time/batch = 0.142\n",
            "2481/2810 (epoch 8), train_loss = 1.508, time/batch = 0.138\n",
            "2482/2810 (epoch 8), train_loss = 1.571, time/batch = 0.147\n",
            "2483/2810 (epoch 8), train_loss = 1.486, time/batch = 0.154\n",
            "2484/2810 (epoch 8), train_loss = 1.535, time/batch = 0.146\n",
            "2485/2810 (epoch 8), train_loss = 1.559, time/batch = 0.143\n",
            "2486/2810 (epoch 8), train_loss = 1.547, time/batch = 0.179\n",
            "2487/2810 (epoch 8), train_loss = 1.551, time/batch = 0.139\n",
            "2488/2810 (epoch 8), train_loss = 1.532, time/batch = 0.163\n",
            "2489/2810 (epoch 8), train_loss = 1.639, time/batch = 0.149\n",
            "2490/2810 (epoch 8), train_loss = 1.511, time/batch = 0.155\n",
            "2491/2810 (epoch 8), train_loss = 1.583, time/batch = 0.145\n",
            "2492/2810 (epoch 8), train_loss = 1.559, time/batch = 0.153\n",
            "2493/2810 (epoch 8), train_loss = 1.561, time/batch = 0.157\n",
            "2494/2810 (epoch 8), train_loss = 1.484, time/batch = 0.152\n",
            "2495/2810 (epoch 8), train_loss = 1.539, time/batch = 0.135\n",
            "2496/2810 (epoch 8), train_loss = 1.502, time/batch = 0.156\n",
            "2497/2810 (epoch 8), train_loss = 1.555, time/batch = 0.142\n",
            "2498/2810 (epoch 8), train_loss = 1.491, time/batch = 0.143\n",
            "2499/2810 (epoch 8), train_loss = 1.563, time/batch = 0.141\n",
            "2500/2810 (epoch 8), train_loss = 1.569, time/batch = 0.162\n",
            "2501/2810 (epoch 8), train_loss = 1.506, time/batch = 0.143\n",
            "2502/2810 (epoch 8), train_loss = 1.516, time/batch = 0.161\n",
            "2503/2810 (epoch 8), train_loss = 1.521, time/batch = 0.158\n",
            "2504/2810 (epoch 8), train_loss = 1.509, time/batch = 0.151\n",
            "2505/2810 (epoch 8), train_loss = 1.499, time/batch = 0.148\n",
            "2506/2810 (epoch 8), train_loss = 1.512, time/batch = 0.163\n",
            "2507/2810 (epoch 8), train_loss = 1.571, time/batch = 0.140\n",
            "2508/2810 (epoch 8), train_loss = 1.510, time/batch = 0.145\n",
            "2509/2810 (epoch 8), train_loss = 1.510, time/batch = 0.153\n",
            "2510/2810 (epoch 8), train_loss = 1.437, time/batch = 0.158\n",
            "2511/2810 (epoch 8), train_loss = 1.524, time/batch = 0.153\n",
            "2512/2810 (epoch 8), train_loss = 1.571, time/batch = 0.168\n",
            "2513/2810 (epoch 8), train_loss = 1.572, time/batch = 0.161\n",
            "2514/2810 (epoch 8), train_loss = 1.526, time/batch = 0.159\n",
            "2515/2810 (epoch 8), train_loss = 1.555, time/batch = 0.152\n",
            "2516/2810 (epoch 8), train_loss = 1.545, time/batch = 0.156\n",
            "2517/2810 (epoch 8), train_loss = 1.546, time/batch = 0.147\n",
            "2518/2810 (epoch 8), train_loss = 1.546, time/batch = 0.154\n",
            "2519/2810 (epoch 8), train_loss = 1.511, time/batch = 0.150\n",
            "2520/2810 (epoch 8), train_loss = 1.494, time/batch = 0.162\n",
            "2521/2810 (epoch 8), train_loss = 1.540, time/batch = 0.146\n",
            "2522/2810 (epoch 8), train_loss = 1.593, time/batch = 0.159\n",
            "2523/2810 (epoch 8), train_loss = 1.550, time/batch = 0.148\n",
            "2524/2810 (epoch 8), train_loss = 1.556, time/batch = 0.150\n",
            "2525/2810 (epoch 8), train_loss = 1.525, time/batch = 0.149\n",
            "2526/2810 (epoch 8), train_loss = 1.484, time/batch = 0.143\n",
            "2527/2810 (epoch 8), train_loss = 1.524, time/batch = 0.165\n",
            "2528/2810 (epoch 8), train_loss = 1.544, time/batch = 0.144\n",
            "2529/2810 (epoch 9), train_loss = 1.531, time/batch = 0.147\n",
            "2530/2810 (epoch 9), train_loss = 1.560, time/batch = 0.133\n",
            "2531/2810 (epoch 9), train_loss = 1.553, time/batch = 0.152\n",
            "2532/2810 (epoch 9), train_loss = 1.555, time/batch = 0.148\n",
            "2533/2810 (epoch 9), train_loss = 1.444, time/batch = 0.168\n",
            "2534/2810 (epoch 9), train_loss = 1.562, time/batch = 0.149\n",
            "2535/2810 (epoch 9), train_loss = 1.497, time/batch = 0.241\n",
            "2536/2810 (epoch 9), train_loss = 1.501, time/batch = 0.229\n",
            "2537/2810 (epoch 9), train_loss = 1.594, time/batch = 0.265\n",
            "2538/2810 (epoch 9), train_loss = 1.477, time/batch = 0.283\n",
            "2539/2810 (epoch 9), train_loss = 1.560, time/batch = 0.245\n",
            "2540/2810 (epoch 9), train_loss = 1.532, time/batch = 0.264\n",
            "2541/2810 (epoch 9), train_loss = 1.502, time/batch = 0.249\n",
            "2542/2810 (epoch 9), train_loss = 1.530, time/batch = 0.270\n",
            "2543/2810 (epoch 9), train_loss = 1.575, time/batch = 0.270\n",
            "2544/2810 (epoch 9), train_loss = 1.549, time/batch = 0.257\n",
            "2545/2810 (epoch 9), train_loss = 1.484, time/batch = 0.247\n",
            "2546/2810 (epoch 9), train_loss = 1.633, time/batch = 0.298\n",
            "2547/2810 (epoch 9), train_loss = 1.535, time/batch = 0.256\n",
            "2548/2810 (epoch 9), train_loss = 1.574, time/batch = 0.156\n",
            "2549/2810 (epoch 9), train_loss = 1.534, time/batch = 0.150\n",
            "2550/2810 (epoch 9), train_loss = 1.580, time/batch = 0.152\n",
            "2551/2810 (epoch 9), train_loss = 1.531, time/batch = 0.164\n",
            "2552/2810 (epoch 9), train_loss = 1.533, time/batch = 0.160\n",
            "2553/2810 (epoch 9), train_loss = 1.541, time/batch = 0.148\n",
            "2554/2810 (epoch 9), train_loss = 1.485, time/batch = 0.148\n",
            "2555/2810 (epoch 9), train_loss = 1.521, time/batch = 0.143\n",
            "2556/2810 (epoch 9), train_loss = 1.517, time/batch = 0.150\n",
            "2557/2810 (epoch 9), train_loss = 1.456, time/batch = 0.144\n",
            "2558/2810 (epoch 9), train_loss = 1.504, time/batch = 0.172\n",
            "2559/2810 (epoch 9), train_loss = 1.535, time/batch = 0.162\n",
            "2560/2810 (epoch 9), train_loss = 1.538, time/batch = 0.147\n",
            "2561/2810 (epoch 9), train_loss = 1.488, time/batch = 0.136\n",
            "2562/2810 (epoch 9), train_loss = 1.573, time/batch = 0.151\n",
            "2563/2810 (epoch 9), train_loss = 1.588, time/batch = 0.136\n",
            "2564/2810 (epoch 9), train_loss = 1.513, time/batch = 0.147\n",
            "2565/2810 (epoch 9), train_loss = 1.532, time/batch = 0.163\n",
            "2566/2810 (epoch 9), train_loss = 1.549, time/batch = 0.148\n",
            "2567/2810 (epoch 9), train_loss = 1.537, time/batch = 0.146\n",
            "2568/2810 (epoch 9), train_loss = 1.543, time/batch = 0.149\n",
            "2569/2810 (epoch 9), train_loss = 1.533, time/batch = 0.139\n",
            "2570/2810 (epoch 9), train_loss = 1.468, time/batch = 0.158\n",
            "2571/2810 (epoch 9), train_loss = 1.533, time/batch = 0.134\n",
            "2572/2810 (epoch 9), train_loss = 1.557, time/batch = 0.159\n",
            "2573/2810 (epoch 9), train_loss = 1.584, time/batch = 0.138\n",
            "2574/2810 (epoch 9), train_loss = 1.514, time/batch = 0.143\n",
            "2575/2810 (epoch 9), train_loss = 1.489, time/batch = 0.138\n",
            "2576/2810 (epoch 9), train_loss = 1.485, time/batch = 0.144\n",
            "2577/2810 (epoch 9), train_loss = 1.499, time/batch = 0.141\n",
            "2578/2810 (epoch 9), train_loss = 1.520, time/batch = 0.141\n",
            "2579/2810 (epoch 9), train_loss = 1.526, time/batch = 0.164\n",
            "2580/2810 (epoch 9), train_loss = 1.533, time/batch = 0.145\n",
            "2581/2810 (epoch 9), train_loss = 1.476, time/batch = 0.157\n",
            "2582/2810 (epoch 9), train_loss = 1.535, time/batch = 0.156\n",
            "2583/2810 (epoch 9), train_loss = 1.516, time/batch = 0.154\n",
            "2584/2810 (epoch 9), train_loss = 1.490, time/batch = 0.143\n",
            "2585/2810 (epoch 9), train_loss = 1.484, time/batch = 0.152\n",
            "2586/2810 (epoch 9), train_loss = 1.523, time/batch = 0.172\n",
            "2587/2810 (epoch 9), train_loss = 1.536, time/batch = 0.149\n",
            "2588/2810 (epoch 9), train_loss = 1.419, time/batch = 0.148\n",
            "2589/2810 (epoch 9), train_loss = 1.497, time/batch = 0.152\n",
            "2590/2810 (epoch 9), train_loss = 1.492, time/batch = 0.140\n",
            "2591/2810 (epoch 9), train_loss = 1.509, time/batch = 0.160\n",
            "2592/2810 (epoch 9), train_loss = 1.515, time/batch = 0.145\n",
            "2593/2810 (epoch 9), train_loss = 1.532, time/batch = 0.168\n",
            "2594/2810 (epoch 9), train_loss = 1.514, time/batch = 0.142\n",
            "2595/2810 (epoch 9), train_loss = 1.407, time/batch = 0.146\n",
            "2596/2810 (epoch 9), train_loss = 1.488, time/batch = 0.141\n",
            "2597/2810 (epoch 9), train_loss = 1.585, time/batch = 0.146\n",
            "2598/2810 (epoch 9), train_loss = 1.537, time/batch = 0.154\n",
            "2599/2810 (epoch 9), train_loss = 1.493, time/batch = 0.151\n",
            "2600/2810 (epoch 9), train_loss = 1.532, time/batch = 0.162\n",
            "2601/2810 (epoch 9), train_loss = 1.547, time/batch = 0.155\n",
            "2602/2810 (epoch 9), train_loss = 1.513, time/batch = 0.140\n",
            "2603/2810 (epoch 9), train_loss = 1.473, time/batch = 0.143\n",
            "2604/2810 (epoch 9), train_loss = 1.503, time/batch = 0.161\n",
            "2605/2810 (epoch 9), train_loss = 1.478, time/batch = 0.155\n",
            "2606/2810 (epoch 9), train_loss = 1.473, time/batch = 0.151\n",
            "2607/2810 (epoch 9), train_loss = 1.502, time/batch = 0.161\n",
            "2608/2810 (epoch 9), train_loss = 1.567, time/batch = 0.143\n",
            "2609/2810 (epoch 9), train_loss = 1.471, time/batch = 0.148\n",
            "2610/2810 (epoch 9), train_loss = 1.488, time/batch = 0.145\n",
            "2611/2810 (epoch 9), train_loss = 1.474, time/batch = 0.148\n",
            "2612/2810 (epoch 9), train_loss = 1.461, time/batch = 0.150\n",
            "2613/2810 (epoch 9), train_loss = 1.420, time/batch = 0.152\n",
            "2614/2810 (epoch 9), train_loss = 1.471, time/batch = 0.218\n",
            "2615/2810 (epoch 9), train_loss = 1.509, time/batch = 0.280\n",
            "2616/2810 (epoch 9), train_loss = 1.550, time/batch = 0.265\n",
            "2617/2810 (epoch 9), train_loss = 1.492, time/batch = 0.247\n",
            "2618/2810 (epoch 9), train_loss = 1.515, time/batch = 0.309\n",
            "2619/2810 (epoch 9), train_loss = 1.488, time/batch = 0.322\n",
            "2620/2810 (epoch 9), train_loss = 1.540, time/batch = 0.272\n",
            "2621/2810 (epoch 9), train_loss = 1.526, time/batch = 0.196\n",
            "2622/2810 (epoch 9), train_loss = 1.602, time/batch = 0.251\n",
            "2623/2810 (epoch 9), train_loss = 1.503, time/batch = 0.267\n",
            "2624/2810 (epoch 9), train_loss = 1.533, time/batch = 0.302\n",
            "2625/2810 (epoch 9), train_loss = 1.550, time/batch = 0.311\n",
            "2626/2810 (epoch 9), train_loss = 1.448, time/batch = 0.266\n",
            "2627/2810 (epoch 9), train_loss = 1.429, time/batch = 0.206\n",
            "2628/2810 (epoch 9), train_loss = 1.478, time/batch = 0.158\n",
            "2629/2810 (epoch 9), train_loss = 1.471, time/batch = 0.157\n",
            "2630/2810 (epoch 9), train_loss = 1.531, time/batch = 0.147\n",
            "2631/2810 (epoch 9), train_loss = 1.582, time/batch = 0.195\n",
            "2632/2810 (epoch 9), train_loss = 1.521, time/batch = 0.163\n",
            "2633/2810 (epoch 9), train_loss = 1.460, time/batch = 0.149\n",
            "2634/2810 (epoch 9), train_loss = 1.448, time/batch = 0.166\n",
            "2635/2810 (epoch 9), train_loss = 1.498, time/batch = 0.149\n",
            "2636/2810 (epoch 9), train_loss = 1.546, time/batch = 0.147\n",
            "2637/2810 (epoch 9), train_loss = 1.530, time/batch = 0.152\n",
            "2638/2810 (epoch 9), train_loss = 1.484, time/batch = 0.170\n",
            "2639/2810 (epoch 9), train_loss = 1.531, time/batch = 0.151\n",
            "2640/2810 (epoch 9), train_loss = 1.439, time/batch = 0.163\n",
            "2641/2810 (epoch 9), train_loss = 1.480, time/batch = 0.157\n",
            "2642/2810 (epoch 9), train_loss = 1.545, time/batch = 0.154\n",
            "2643/2810 (epoch 9), train_loss = 1.536, time/batch = 0.204\n",
            "2644/2810 (epoch 9), train_loss = 1.541, time/batch = 0.157\n",
            "2645/2810 (epoch 9), train_loss = 1.536, time/batch = 0.147\n",
            "2646/2810 (epoch 9), train_loss = 1.466, time/batch = 0.149\n",
            "2647/2810 (epoch 9), train_loss = 1.500, time/batch = 0.156\n",
            "2648/2810 (epoch 9), train_loss = 1.542, time/batch = 0.143\n",
            "2649/2810 (epoch 9), train_loss = 1.514, time/batch = 0.158\n",
            "2650/2810 (epoch 9), train_loss = 1.507, time/batch = 0.158\n",
            "2651/2810 (epoch 9), train_loss = 1.502, time/batch = 0.170\n",
            "2652/2810 (epoch 9), train_loss = 1.519, time/batch = 0.157\n",
            "2653/2810 (epoch 9), train_loss = 1.477, time/batch = 0.163\n",
            "2654/2810 (epoch 9), train_loss = 1.447, time/batch = 0.162\n",
            "2655/2810 (epoch 9), train_loss = 1.479, time/batch = 0.154\n",
            "2656/2810 (epoch 9), train_loss = 1.509, time/batch = 0.153\n",
            "2657/2810 (epoch 9), train_loss = 1.553, time/batch = 0.179\n",
            "2658/2810 (epoch 9), train_loss = 1.499, time/batch = 0.145\n",
            "2659/2810 (epoch 9), train_loss = 1.502, time/batch = 0.149\n",
            "2660/2810 (epoch 9), train_loss = 1.474, time/batch = 0.157\n",
            "2661/2810 (epoch 9), train_loss = 1.511, time/batch = 0.146\n",
            "2662/2810 (epoch 9), train_loss = 1.529, time/batch = 0.148\n",
            "2663/2810 (epoch 9), train_loss = 1.508, time/batch = 0.161\n",
            "2664/2810 (epoch 9), train_loss = 1.505, time/batch = 0.164\n",
            "2665/2810 (epoch 9), train_loss = 1.572, time/batch = 0.161\n",
            "2666/2810 (epoch 9), train_loss = 1.560, time/batch = 0.147\n",
            "2667/2810 (epoch 9), train_loss = 1.532, time/batch = 0.146\n",
            "2668/2810 (epoch 9), train_loss = 1.556, time/batch = 0.149\n",
            "2669/2810 (epoch 9), train_loss = 1.560, time/batch = 0.169\n",
            "2670/2810 (epoch 9), train_loss = 1.537, time/batch = 0.184\n",
            "2671/2810 (epoch 9), train_loss = 1.599, time/batch = 0.174\n",
            "2672/2810 (epoch 9), train_loss = 1.573, time/batch = 0.145\n",
            "2673/2810 (epoch 9), train_loss = 1.497, time/batch = 0.143\n",
            "2674/2810 (epoch 9), train_loss = 1.490, time/batch = 0.153\n",
            "2675/2810 (epoch 9), train_loss = 1.538, time/batch = 0.156\n",
            "2676/2810 (epoch 9), train_loss = 1.533, time/batch = 0.161\n",
            "2677/2810 (epoch 9), train_loss = 1.564, time/batch = 0.160\n",
            "2678/2810 (epoch 9), train_loss = 1.531, time/batch = 0.169\n",
            "2679/2810 (epoch 9), train_loss = 1.551, time/batch = 0.160\n",
            "2680/2810 (epoch 9), train_loss = 1.499, time/batch = 0.158\n",
            "2681/2810 (epoch 9), train_loss = 1.543, time/batch = 0.155\n",
            "2682/2810 (epoch 9), train_loss = 1.565, time/batch = 0.150\n",
            "2683/2810 (epoch 9), train_loss = 1.470, time/batch = 0.181\n",
            "2684/2810 (epoch 9), train_loss = 1.529, time/batch = 0.153\n",
            "2685/2810 (epoch 9), train_loss = 1.564, time/batch = 0.151\n",
            "2686/2810 (epoch 9), train_loss = 1.453, time/batch = 0.156\n",
            "2687/2810 (epoch 9), train_loss = 1.509, time/batch = 0.240\n",
            "2688/2810 (epoch 9), train_loss = 1.512, time/batch = 0.173\n",
            "2689/2810 (epoch 9), train_loss = 1.559, time/batch = 0.200\n",
            "2690/2810 (epoch 9), train_loss = 1.598, time/batch = 0.260\n",
            "2691/2810 (epoch 9), train_loss = 1.535, time/batch = 0.265\n",
            "2692/2810 (epoch 9), train_loss = 1.513, time/batch = 0.282\n",
            "2693/2810 (epoch 9), train_loss = 1.542, time/batch = 0.252\n",
            "2694/2810 (epoch 9), train_loss = 1.469, time/batch = 0.266\n",
            "2695/2810 (epoch 9), train_loss = 1.536, time/batch = 0.283\n",
            "2696/2810 (epoch 9), train_loss = 1.518, time/batch = 0.250\n",
            "2697/2810 (epoch 9), train_loss = 1.472, time/batch = 0.271\n",
            "2698/2810 (epoch 9), train_loss = 1.505, time/batch = 0.249\n",
            "2699/2810 (epoch 9), train_loss = 1.539, time/batch = 0.251\n",
            "2700/2810 (epoch 9), train_loss = 1.483, time/batch = 0.262\n",
            "2701/2810 (epoch 9), train_loss = 1.436, time/batch = 0.246\n",
            "2702/2810 (epoch 9), train_loss = 1.609, time/batch = 0.147\n",
            "2703/2810 (epoch 9), train_loss = 1.521, time/batch = 0.155\n",
            "2704/2810 (epoch 9), train_loss = 1.490, time/batch = 0.148\n",
            "2705/2810 (epoch 9), train_loss = 1.491, time/batch = 0.155\n",
            "2706/2810 (epoch 9), train_loss = 1.510, time/batch = 0.148\n",
            "2707/2810 (epoch 9), train_loss = 1.520, time/batch = 0.159\n",
            "2708/2810 (epoch 9), train_loss = 1.534, time/batch = 0.159\n",
            "2709/2810 (epoch 9), train_loss = 1.414, time/batch = 0.154\n",
            "2710/2810 (epoch 9), train_loss = 1.494, time/batch = 0.141\n",
            "2711/2810 (epoch 9), train_loss = 1.523, time/batch = 0.162\n",
            "2712/2810 (epoch 9), train_loss = 1.503, time/batch = 0.148\n",
            "2713/2810 (epoch 9), train_loss = 1.546, time/batch = 0.147\n",
            "2714/2810 (epoch 9), train_loss = 1.458, time/batch = 0.155\n",
            "2715/2810 (epoch 9), train_loss = 1.521, time/batch = 0.172\n",
            "2716/2810 (epoch 9), train_loss = 1.477, time/batch = 0.143\n",
            "2717/2810 (epoch 9), train_loss = 1.546, time/batch = 0.164\n",
            "2718/2810 (epoch 9), train_loss = 1.480, time/batch = 0.147\n",
            "2719/2810 (epoch 9), train_loss = 1.522, time/batch = 0.149\n",
            "2720/2810 (epoch 9), train_loss = 1.537, time/batch = 0.154\n",
            "2721/2810 (epoch 9), train_loss = 1.568, time/batch = 0.148\n",
            "2722/2810 (epoch 9), train_loss = 1.471, time/batch = 0.162\n",
            "2723/2810 (epoch 9), train_loss = 1.519, time/batch = 0.146\n",
            "2724/2810 (epoch 9), train_loss = 1.458, time/batch = 0.151\n",
            "2725/2810 (epoch 9), train_loss = 1.553, time/batch = 0.152\n",
            "2726/2810 (epoch 9), train_loss = 1.431, time/batch = 0.145\n",
            "2727/2810 (epoch 9), train_loss = 1.541, time/batch = 0.159\n",
            "2728/2810 (epoch 9), train_loss = 1.456, time/batch = 0.157\n",
            "2729/2810 (epoch 9), train_loss = 1.541, time/batch = 0.158\n",
            "2730/2810 (epoch 9), train_loss = 1.491, time/batch = 0.143\n",
            "2731/2810 (epoch 9), train_loss = 1.510, time/batch = 0.148\n",
            "2732/2810 (epoch 9), train_loss = 1.559, time/batch = 0.146\n",
            "2733/2810 (epoch 9), train_loss = 1.492, time/batch = 0.149\n",
            "2734/2810 (epoch 9), train_loss = 1.502, time/batch = 0.147\n",
            "2735/2810 (epoch 9), train_loss = 1.504, time/batch = 0.176\n",
            "2736/2810 (epoch 9), train_loss = 1.419, time/batch = 0.153\n",
            "2737/2810 (epoch 9), train_loss = 1.487, time/batch = 0.150\n",
            "2738/2810 (epoch 9), train_loss = 1.464, time/batch = 0.145\n",
            "2739/2810 (epoch 9), train_loss = 1.554, time/batch = 0.142\n",
            "2740/2810 (epoch 9), train_loss = 1.543, time/batch = 0.156\n",
            "2741/2810 (epoch 9), train_loss = 1.488, time/batch = 0.144\n",
            "2742/2810 (epoch 9), train_loss = 1.518, time/batch = 0.177\n",
            "2743/2810 (epoch 9), train_loss = 1.525, time/batch = 0.156\n",
            "2744/2810 (epoch 9), train_loss = 1.505, time/batch = 0.154\n",
            "2745/2810 (epoch 9), train_loss = 1.469, time/batch = 0.147\n",
            "2746/2810 (epoch 9), train_loss = 1.550, time/batch = 0.161\n",
            "2747/2810 (epoch 9), train_loss = 1.518, time/batch = 0.149\n",
            "2748/2810 (epoch 9), train_loss = 1.525, time/batch = 0.142\n",
            "2749/2810 (epoch 9), train_loss = 1.492, time/batch = 0.174\n",
            "2750/2810 (epoch 9), train_loss = 1.459, time/batch = 0.152\n",
            "2751/2810 (epoch 9), train_loss = 1.505, time/batch = 0.148\n",
            "2752/2810 (epoch 9), train_loss = 1.462, time/batch = 0.151\n",
            "2753/2810 (epoch 9), train_loss = 1.431, time/batch = 0.154\n",
            "2754/2810 (epoch 9), train_loss = 1.509, time/batch = 0.150\n",
            "2755/2810 (epoch 9), train_loss = 1.480, time/batch = 0.152\n",
            "2756/2810 (epoch 9), train_loss = 1.505, time/batch = 0.163\n",
            "2757/2810 (epoch 9), train_loss = 1.480, time/batch = 0.143\n",
            "2758/2810 (epoch 9), train_loss = 1.546, time/batch = 0.145\n",
            "2759/2810 (epoch 9), train_loss = 1.501, time/batch = 0.152\n",
            "2760/2810 (epoch 9), train_loss = 1.524, time/batch = 0.154\n",
            "2761/2810 (epoch 9), train_loss = 1.526, time/batch = 0.155\n",
            "2762/2810 (epoch 9), train_loss = 1.483, time/batch = 0.159\n",
            "2763/2810 (epoch 9), train_loss = 1.548, time/batch = 0.149\n",
            "2764/2810 (epoch 9), train_loss = 1.463, time/batch = 0.144\n",
            "2765/2810 (epoch 9), train_loss = 1.507, time/batch = 0.150\n",
            "2766/2810 (epoch 9), train_loss = 1.531, time/batch = 0.156\n",
            "2767/2810 (epoch 9), train_loss = 1.521, time/batch = 0.228\n",
            "2768/2810 (epoch 9), train_loss = 1.531, time/batch = 0.289\n",
            "2769/2810 (epoch 9), train_loss = 1.508, time/batch = 0.256\n",
            "2770/2810 (epoch 9), train_loss = 1.615, time/batch = 0.272\n",
            "2771/2810 (epoch 9), train_loss = 1.484, time/batch = 0.257\n",
            "2772/2810 (epoch 9), train_loss = 1.562, time/batch = 0.281\n",
            "2773/2810 (epoch 9), train_loss = 1.535, time/batch = 0.272\n",
            "2774/2810 (epoch 9), train_loss = 1.533, time/batch = 0.274\n",
            "2775/2810 (epoch 9), train_loss = 1.456, time/batch = 0.268\n",
            "2776/2810 (epoch 9), train_loss = 1.510, time/batch = 0.301\n",
            "2777/2810 (epoch 9), train_loss = 1.476, time/batch = 0.302\n",
            "2778/2810 (epoch 9), train_loss = 1.529, time/batch = 0.258\n",
            "2779/2810 (epoch 9), train_loss = 1.467, time/batch = 0.293\n",
            "2780/2810 (epoch 9), train_loss = 1.535, time/batch = 0.307\n",
            "2781/2810 (epoch 9), train_loss = 1.543, time/batch = 0.270\n",
            "2782/2810 (epoch 9), train_loss = 1.481, time/batch = 0.297\n",
            "2783/2810 (epoch 9), train_loss = 1.490, time/batch = 0.285\n",
            "2784/2810 (epoch 9), train_loss = 1.495, time/batch = 0.302\n",
            "2785/2810 (epoch 9), train_loss = 1.482, time/batch = 0.248\n",
            "2786/2810 (epoch 9), train_loss = 1.473, time/batch = 0.250\n",
            "2787/2810 (epoch 9), train_loss = 1.484, time/batch = 0.255\n",
            "2788/2810 (epoch 9), train_loss = 1.547, time/batch = 0.279\n",
            "2789/2810 (epoch 9), train_loss = 1.484, time/batch = 0.289\n",
            "2790/2810 (epoch 9), train_loss = 1.485, time/batch = 0.246\n",
            "2791/2810 (epoch 9), train_loss = 1.414, time/batch = 0.165\n",
            "2792/2810 (epoch 9), train_loss = 1.496, time/batch = 0.151\n",
            "2793/2810 (epoch 9), train_loss = 1.545, time/batch = 0.163\n",
            "2794/2810 (epoch 9), train_loss = 1.549, time/batch = 0.144\n",
            "2795/2810 (epoch 9), train_loss = 1.500, time/batch = 0.154\n",
            "2796/2810 (epoch 9), train_loss = 1.530, time/batch = 0.152\n",
            "2797/2810 (epoch 9), train_loss = 1.521, time/batch = 0.150\n",
            "2798/2810 (epoch 9), train_loss = 1.522, time/batch = 0.150\n",
            "2799/2810 (epoch 9), train_loss = 1.523, time/batch = 0.171\n",
            "2800/2810 (epoch 9), train_loss = 1.485, time/batch = 0.145\n",
            "2801/2810 (epoch 9), train_loss = 1.467, time/batch = 0.141\n",
            "2802/2810 (epoch 9), train_loss = 1.513, time/batch = 0.163\n",
            "2803/2810 (epoch 9), train_loss = 1.564, time/batch = 0.152\n",
            "2804/2810 (epoch 9), train_loss = 1.523, time/batch = 0.145\n",
            "2805/2810 (epoch 9), train_loss = 1.535, time/batch = 0.139\n",
            "2806/2810 (epoch 9), train_loss = 1.497, time/batch = 0.171\n",
            "2807/2810 (epoch 9), train_loss = 1.459, time/batch = 0.148\n",
            "2808/2810 (epoch 9), train_loss = 1.504, time/batch = 0.160\n",
            "2809/2810 (epoch 9), train_loss = 1.518, time/batch = 0.156\n",
            "Model saved to ./checkpoints/pg74571/pg74571!\n",
            "Converting model to ml5js: pg74571 pg74571-2809\n",
            "Done! The output model is in ./models\n",
            "Check https://ml5js.org/docs/training-lstm for more information.\n",
            "  adding: models/pg74571/ (stored 0%)\n",
            "  adding: models/pg74571/rnnlm_multi_rnn_cell_cell_1_basic_lstm_cell_bias (deflated 6%)\n",
            "  adding: models/pg74571/rnnlm_softmax_w (deflated 7%)\n",
            "  adding: models/pg74571/Variable (stored 0%)\n",
            "  adding: models/pg74571/manifest.json (deflated 80%)\n",
            "  adding: models/pg74571/rnnlm_multi_rnn_cell_cell_1_basic_lstm_cell_kernel (deflated 7%)\n",
            "  adding: models/pg74571/embedding (deflated 7%)\n",
            "  adding: models/pg74571/rnnlm_multi_rnn_cell_cell_0_basic_lstm_cell_bias (deflated 6%)\n",
            "  adding: models/pg74571/rnnlm_multi_rnn_cell_cell_0_basic_lstm_cell_kernel (deflated 7%)\n",
            "  adding: models/pg74571/rnnlm_softmax_b (stored 0%)\n",
            "  adding: models/pg74571/vocab.json (deflated 67%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}